Node.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v23.11.0 documentation
          
            
            
          
        
        
          
            Node.js v23.11.0
            
            
            
    
      
        
        Other versions
      
      23.x
22.x LTS
21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v23.11.0 documentation
          
            
            
          
        
        
          
            Node.js v23.11.0
            
            
            
    
      
        
        Other versions
      
      23.x
22.x LTS
21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nJSConfGeneral Admission Tickets are on sale now!Run JavaScript EverywhereNode.js® is a free, open-source, cross-platform JavaScript runtime environment
that lets developers create servers, web apps, command line tools and scripts.Download Node.js (LTS)Download Node.js (LTS)Downloads Node.js v22.15.01 with long-term support. Node.js can also be installed via version managers.Want new features sooner? Get Node.js v23.11.01 instead.
Create an HTTP ServerWrite TestsRead and Hash a FileStreams PipelineWork with Threads// server.mjs
import { createServer } from 'node:http';

const server = createServer((req, res) => {
  res.writeHead(200, { 'Content-Type': 'text/plain' });
  res.end('Hello World!\n');
});

// starts a simple http server locally on port 3000
server.listen(3000, '127.0.0.1', () => {
  console.log('Listening on 127.0.0.1:3000');
});

// run with `node server.mjs`
JavaScriptCopy to clipboardLearn more what Node.js is able to offer with our Learning materials.\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\nJSConfGeneral Admission Tickets are on sale now!Run JavaScript EverywhereNode.js® is a free, open-source, cross-platform JavaScript runtime environment
that lets developers create servers, web apps, command line tools and scripts.Download Node.js (LTS)Download Node.js (LTS)Downloads Node.js v22.15.01 with long-term support. Node.js can also be installed via version managers.Want new features sooner? Get Node.js v23.11.01 instead.
Create an HTTP ServerWrite TestsRead and Hash a FileStreams PipelineWork with Threads// server.mjs
import { createServer } from 'node:http';

const server = createServer((req, res) => {
  res.writeHead(200, { 'Content-Type': 'text/plain' });
  res.end('Hello World!\n');
});

// starts a simple http server locally on port 3000
server.listen(3000, '127.0.0.1', () => {
  console.log('Listening on 127.0.0.1:3000');
});

// run with `node server.mjs`
JavaScriptCopy to clipboardLearn more what Node.js is able to offer with our Learning materials.\n\n\n\nIntroduction to Node.js
Node.js is an open-source and cross-platform JavaScript runtime environment. It is a popular tool for almost any kind of project!
Node.js runs the V8 JavaScript engine, the core of Google Chrome, outside of the browser. This allows Node.js to be very performant.
A Node.js app runs in a single process, without creating a new thread for every request. Node.js provides a set of asynchronous I/O primitives in its standard library that prevent JavaScript code from blocking and generally, libraries in Node.js are written using non-blocking paradigms, making blocking behavior the exception rather than the norm.
When Node.js performs an I/O operation, like reading from the network, accessing a database or the filesystem, instead of blocking the thread and wasting CPU cycles waiting, Node.js will resume the operations when the response comes back.
This allows Node.js to handle thousands of concurrent connections with a single server without introducing the burden of managing thread concurrency, which could be a significant source of bugs.
Node.js has a unique advantage because millions of frontend developers that write JavaScript for the browser are now able to write the server-side code in addition to the client-side code without the need to learn a completely different language.
In Node.js the new ECMAScript standards can be used without problems, as you don't have to wait for all your users to update their browsers - you are in charge of deciding which ECMAScript version to use by changing the Node.js version, and you can also enable specific experimental features by running Node.js with flags.
An Example Node.js Application
The most common example Hello World of Node.js is a web server:
CJSMJSconst { createServer } = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello World');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
});
JavaScriptCopy to clipboardTo run this snippet, save it as a server.js file and run node server.js in your terminal.
If you use mjs version of the code, you should save it as a server.mjs file and run node server.mjs in your terminal.
This code first includes the Node.js http module.
Node.js has a fantastic standard library, including first-class support for networking.
The createServer() method of http creates a new HTTP server and returns it.
The server is set to listen on the specified port and host name. When the server is ready, the callback function is called, in this case informing us that the server is running.
Whenever a new request is received, the request event is called, providing two objects: a request (an http.IncomingMessage object) and a response (an http.ServerResponse object).
Those 2 objects are essential to handle the HTTP call.
The first provides the request details. In this simple example, this is not used, but you could access the request headers and request data.
The second is used to return data to the caller.
In this case with:
res.statusCode = 200;
JavaScriptCopy to clipboard
we set the statusCode property to 200, to indicate a successful response.
We set the Content-Type header:
res.setHeader('Content-Type', 'text/plain');
JavaScriptCopy to clipboard
and we close the response, adding the content as an argument to end():
res.end('Hello World\n');
JavaScriptCopy to clipboard
If you haven't already done so, download Node.js.NextHow much JavaScript do you need to know to use Node.js?\n\n\n\nAbout Node.js®
As an asynchronous event-driven JavaScript runtime, Node.js is designed to build
scalable network applications. In the following "hello world" example, many
connections can be handled concurrently. Upon each connection, the callback is
fired, but if there is no work to be done, Node.js will sleep.
CJSMJSconst { createServer } = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello World');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
});
JavaScriptCopy to clipboardThis is in contrast to today's more common concurrency model, in which OS threads
are employed. Thread-based networking is relatively inefficient and very
difficult to use. Furthermore, users of Node.js are free from worries of
dead-locking the process, since there are no locks. Almost no function in
Node.js directly performs I/O, so the process never blocks except when the I/O is performed using
synchronous methods of Node.js standard library. Because nothing blocks, scalable systems are very
reasonable to develop in Node.js.
If some of this language is unfamiliar, there is a full article on
Blocking vs. Non-Blocking.

Node.js is similar in design to, and influenced by, systems like Ruby's
Event Machine and Python's Twisted. Node.js takes the event model a bit
further. It presents an event loop as a runtime construct instead of as a library. In other systems,
there is always a blocking call to start the event-loop.
Typically, behavior is defined through callbacks at the beginning of a script, and
at the end a server is started through a blocking call like EventMachine::run().
In Node.js, there is no such start-the-event-loop call. Node.js simply enters the event loop after executing the input script. Node.js
exits the event loop when there are no more callbacks to perform. This behavior
is like browser JavaScript — the event loop is hidden from the user.
HTTP is a first-class citizen in Node.js, designed with streaming and low
latency in mind. This makes Node.js well suited for the foundation of a web
library or framework.
Node.js being designed without threads doesn't mean you can't take
advantage of multiple cores in your environment. Child processes can be spawned
by using our child_process.fork() API, and are designed to be easy to
communicate with. Built upon that same interface is the cluster module,
which allows you to share sockets between processes to enable load balancing
over your cores.
Official Node.js Resources
To ensure authenticity and security when working with Node.js, always use official sources. Avoid trusting emails,
binaries, or downloads from unofficial sources.
Official Node.js Domains
For downloading Node.js binaries and accessing official documentation, use only these domains:

nodejs.org
nodejs.dev (Redirects to https://nodejs.org)
iojs.org (Redirects to https://nodejs.org)

Official npm Packages
The Node.js team maintains the following official npm package scopes:

@node-core
@pkgjs

Additionally, the Node.js team maintains packages published by the nodejs-foundation npm account,
though other Node.js-related packages (like undici) may also be maintained by contributors closely
tied to the project.
Using packages from the Node.js team guarantees that you are working with officially supported Node.js components.
Official GitHub Organizations
Node.js and related projects are maintained under these official GitHub organizations:

nodejs
pkgjs

Official Communication Channels
Node.js and the OpenJS Foundation communicate through various official and community-supported channels. You can find details on
how to get involved on the Get Involved page.
Reporting Website Issues & Downtime
If you encounter issues with the Node.js website, report them at the Node.js website repository.
For real-time updates on outages, visit the Node.js Status Page.\n\n\n\nDownload Node.js®Get Node.js® v22.15.0 (LTS) for Unknown using  with npmBashCopy to clipboard and their installation scripts are not maintained by the Node.js project. If you encounter any issues please visit 's websiteOr get a prebuilt Node.js® for Unknown running a Unknown architecture.N/A Installer (.gz)Standalone Binary (.gz)
Read the changelog or blog post for this version.Learn more about Node.js releases, including the release schedule and LTS status.Learn how to verify signed SHASUMS.Looking for Node.js source? Download a signed Node.js source tarball.Check out our nightly binaries or
all previous releases
or the unofficial binaries for other platforms.\n\n\n\nNode.js Test CI Security IncidentVulnerabilitiesNode.js Test CI Security IncidentNode.js Technical Steering CommitteeApr 23, 2025Node v22.15.0 (LTS)ReleasesNode v22.15.0 (LTS)Ulises GascónApr 23, 2025Node v20.19.1 (LTS)ReleasesNode v20.19.1 (LTS)Ulises GascónApr 22, 2025Making Node.js Downloads ReliableAnnouncementsMaking Node.js Downloads Reliableflakey5Apr 05, 2025Node v23.11.0 (Current)ReleasesNode v23.11.0 (Current)Antoine du HamelApr 01, 2025Node v18.20.8 (LTS)ReleasesNode v18.20.8 (LTS)Richard LauMar 27, 2025\n\nBlogThe latest Node.js news, case studies, tutorials, and resources.EverythingAnnouncementsReleasesVulnerabilitiesEventsCategoriesEverythingNode.js Test CI Security IncidentVulnerabilitiesNode.js Test CI Security IncidentNode.js Technical Steering CommitteeApr 23, 2025Node v22.15.0 (LTS)ReleasesNode v22.15.0 (LTS)Ulises GascónApr 23, 2025Node v20.19.1 (LTS)ReleasesNode v20.19.1 (LTS)Ulises GascónApr 22, 2025Making Node.js Downloads ReliableAnnouncementsMaking Node.js Downloads Reliableflakey5Apr 05, 2025Node v23.11.0 (Current)ReleasesNode v23.11.0 (Current)Antoine du HamelApr 01, 2025Node v18.20.8 (LTS)ReleasesNode v18.20.8 (LTS)Richard LauMar 27, 2025Previous12345...158Next\n\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v23.11.0 documentation
          
            
            
          
        
        
          
            Node.js v23.11.0
            
            
            
    
      
        
        Other versions
      
      23.x
22.x LTS
21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\n\n\nBranding of Node.js
Please review the trademark policy for information about permissible use of Node.js® logos and marks.
Node.js® Mascot
Credit to Angela Angelini for designing and contributing the Rocket Turtle.

Node.js® Logo
Node.js® Horizontal Logo

Node.js® Stacked Logo

JS Icons\n\n\n\nProject Governance
Consensus Seeking Process
The Node.js project follows a Consensus Seeking decision making model.
Collaborators
The nodejs/node core GitHub repository is maintained by the Collaborators
who are nominated by other existing Collaborators on an ongoing basis.
Individuals making significant and valuable contributions are made Collaborators
and given commit-access to the project. These individuals are identified by other
Collaborators and their nomination is discussed with the existing Collaborators.
For the current list of Collaborators, see the project's README.md.
A guide for Collaborators is maintained at collaborator-guide.md.
Technical Steering Committee
The project is governed by the Technical Steering Committee (TSC)
which is responsible for high-level guidance of the project. TSC is a
subset of active Collaborators who are nominated by other existing TSC
members.\n\n\n\nSecurity Reporting
For more details on active Security Policies, checkout this page.
Reporting a bug in Node.js
Report security bugs in Node.js via HackerOne.
Your report will be acknowledged within 5 days, and you'll receive a more
detailed response to your report within 10 days indicating the next steps in
handling your submission.
After the initial reply to your report, the security team will endeavor to keep
you informed of the progress being made towards a fix and full announcement,
and may ask for additional information or guidance surrounding the reported
issue.
Node.js bug bounty program
The Node.js project engages in an official bug bounty program for security
researchers and responsible public disclosures. The program is managed through
the HackerOne platform. See https://hackerone.com/nodejs for further details.
Reporting a bug in a third party module
Security bugs in third party modules should be reported to their respective
maintainers.
Disclosure policy
Here is the security disclosure policy for Node.js


The security report is received and is assigned a primary handler. This
person will coordinate the fix and release process. The problem is confirmed
and a list of all affected versions is determined. Code is audited to find
any potential similar problems. Fixes are prepared for all releases which are
still under maintenance. These fixes are not committed to the public
repository but rather held locally pending the announcement.


A suggested embargo date for this vulnerability is chosen and a CVE (Common
Vulnerabilities and Exposures (CVE®)) is requested for the vulnerability.


On the embargo date, the Node.js security mailing list is sent a copy of the
announcement. The changes are pushed to the public repository and new builds
are deployed to nodejs.org. Within 6 hours of the mailing list being
notified, a copy of the advisory will be published on the Node.js blog.


Typically the embargo date will be set 72 hours from the time the CVE is
issued. However, this may vary depending on the severity of the bug or
difficulty in applying a fix.


This process can take some time, especially when coordination is required
with maintainers of other projects. Every effort will be made to handle the
bug in as timely a manner as possible; however, it's important that we follow
the release process above to ensure that the disclosure is handled in a
consistent manner.


Receiving security updates
Security notifications will be distributed via the following methods.

Google Group
Node.js Blog

Comments on this policy
If you have suggestions on how this process could be improved please submit a
pull request or
file an issue to discuss.
OpenSSF Best Practices

The Open Source Security Foundation (OpenSSF) Best Practices badge is a way for Free/Libre and Open Source Software (FLOSS) projects to show that they follow best practices. Projects can voluntarily self-certify how they follow each best practice. Consumers of the badge can quickly assess which FLOSS projects are following best practices and as a result are more likely to produce higher-quality secure software.\n\n\n\nGet Involved
If you are interested in getting involved with the Node.js community, there are many ways to do so. The Node.js project is a large and diverse community with many ways to contribute beyond just writing code.
Community Discussion

The nodejs/node GitHub repository is the place to discuss Node.js core features and reporting issues.
The nodejs/help GitHub repository is the official place to ask questions about Node.js.
Node.js's official Discord server is a place to chat with other Node.js developers and get official news from the Node.js project.
Node.js's project calendar with all public Node.js team meetings.

Learning Materials
If you are looking to learn more about Node.js, there are many resources available to you.

Node.js's official learning materials.
Node.js's official API reference documentation.
NodeSchool.io teaches Node.js concepts via interactive command-line games.
StackOverflow's Node.js tag contains a large number of threads with helpful resources.
The DEV Community Node.js's tag contains articles and content related to Node.js.

Unofficial Discussion Areas
There are several unofficial discussion areas if you are looking for a more informal place to discuss Node.js.
Please note that the Node.js project does not officially endorse these. Please follow their respective codes of conduct/rules.

Node Slackers is a Node.js-focused Slack community.
OpenJSF Slack is a Slack workspace for the OpenJS Foundation. There are several channels related to Node.js. (channels prefixed by #nodejs- are related to the project)
irc.libera.chat in the #node.js channel with an IRC client or connect in your web browser to the channel using a web client.\n\n\n\nCollaboration Summit
Node.js's Collaboration Summit is an un-conference for bringing current and
potential contributors together to discuss Node.js with lively collaboration,
education, and knowledge sharing. Teams, working groups and contributors
from the community come together twice per year to have discussions that
help decision-making while also working on some exciting efforts they
want to push forward in-person.
Who attends?
The Collaboration Summit is primarily attended by existing contributors and
community members, but it also welcomes those who are not yet a contributor
and want to get onboard. If you are new to contributing to Node.js, the
Collaboration Summit can be a good opportunity to help you learn what is
happening within the community and contribute with the skills you have
and would like to hone.
Prior to the summit, contributors and community members send session proposals to
create a schedule. Attendees can familiarize themselves with the session before
getting onsite, having the general collaborator discussions, and then diving
into sessions. There will also be plenty of opportunities for hallway tracks
and brainstorms.
For information about upcoming and past Collaboration Summits, check out the
Summit repo. Have a look at the
issues filed that share what
contributors and community members are proposing to discuss in-person.\n\n\n\nUpcoming Events
Node.js events are open and available to the public. Anyone is welcome to join and participate.
Upcoming Node.js® Meetings
The Node.js project holds numerous meetings throughout the year to discuss and plan aspects of the project.
The following meetings are upcoming in the next 7 days.
April 302:00 PM-3:00 PM(UTC)Node.js Next 10 years10:00 AM-11:00 AM(UTC)Node.js TSC MeetingMay 23:00 PM-4:00 PM(UTC)Node API team meeting\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\nIndex of /download/release/v23.11.0/\nnode-v23.11.0-aix-ppc64.tar.gz\nnode-v23.11.0-arm64.msi\nnode-v23.11.0-darwin-arm64.tar.gz\nnode-v23.11.0-darwin-arm64.tar.xz\nnode-v23.11.0-darwin-x64.tar.gz\nnode-v23.11.0-darwin-x64.tar.xz\nnode-v23.11.0-headers.tar.gz\nnode-v23.11.0-headers.tar.xz\nnode-v23.11.0-linux-arm64.tar.gz\nnode-v23.11.0-linux-arm64.tar.xz\nnode-v23.11.0-linux-armv7l.tar.gz\nnode-v23.11.0-linux-armv7l.tar.xz\nnode-v23.11.0-linux-ppc64le.tar.gz\nnode-v23.11.0-linux-ppc64le.tar.xz\nnode-v23.11.0-linux-s390x.tar.gz\nnode-v23.11.0-linux-s390x.tar.xz\nnode-v23.11.0-linux-x64.tar.gz\nnode-v23.11.0-linux-x64.tar.xz\nnode-v23.11.0-win-arm64.7z\nnode-v23.11.0-win-arm64.zip\nnode-v23.11.0-win-x64.7z\nnode-v23.11.0-win-x64.zip\nnode-v23.11.0-x64.msi\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v23.11.0 documentation
          
            
            
          
        
        
          
            Node.js v23.11.0
            
            
            
    
      
        
        Other versions
      
      23.x
22.x LTS
21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
QUIC
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/latest-v22.x/\nnode-v22.15.0-aix-ppc64.tar.gz\nnode-v22.15.0-arm64.msi\nnode-v22.15.0-darwin-arm64.tar.gz\nnode-v22.15.0-darwin-arm64.tar.xz\nnode-v22.15.0-darwin-x64.tar.gz\nnode-v22.15.0-darwin-x64.tar.xz\nnode-v22.15.0-headers.tar.gz\nnode-v22.15.0-headers.tar.xz\nnode-v22.15.0-linux-arm64.tar.gz\nnode-v22.15.0-linux-arm64.tar.xz\nnode-v22.15.0-linux-armv7l.tar.gz\nnode-v22.15.0-linux-armv7l.tar.xz\nnode-v22.15.0-linux-ppc64le.tar.gz\nnode-v22.15.0-linux-ppc64le.tar.xz\nnode-v22.15.0-linux-s390x.tar.gz\nnode-v22.15.0-linux-s390x.tar.xz\nnode-v22.15.0-linux-x64.tar.gz\nnode-v22.15.0-linux-x64.tar.xz\nnode-v22.15.0-win-arm64.7z\nnode-v22.15.0-win-arm64.zip\nnode-v22.15.0-win-x64.7z\nnode-v22.15.0-win-x64.zip\nnode-v22.15.0-win-x86.7z\nnode-v22.15.0-win-x86.zip\nnode-v22.15.0-x64.msi\nnode-v22.15.0-x86.msi\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v22.15.0 documentation
          
            
            
          
        
        
          
            Node.js v22.15.0
            
            
            
    
      
        
        Other versions
      
      23.x
22.x LTS
21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Modules: TypeScript
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
SQLite
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/latest-v21.x/\nnode-v21.7.3-aix-ppc64.tar.gz\nnode-v21.7.3-arm64.msi\nnode-v21.7.3-darwin-arm64.tar.gz\nnode-v21.7.3-darwin-arm64.tar.xz\nnode-v21.7.3-darwin-x64.tar.gz\nnode-v21.7.3-darwin-x64.tar.xz\nnode-v21.7.3-headers.tar.gz\nnode-v21.7.3-headers.tar.xz\nnode-v21.7.3-linux-arm64.tar.gz\nnode-v21.7.3-linux-arm64.tar.xz\nnode-v21.7.3-linux-armv7l.tar.gz\nnode-v21.7.3-linux-armv7l.tar.xz\nnode-v21.7.3-linux-ppc64le.tar.gz\nnode-v21.7.3-linux-ppc64le.tar.xz\nnode-v21.7.3-linux-s390x.tar.gz\nnode-v21.7.3-linux-s390x.tar.xz\nnode-v21.7.3-linux-x64.tar.gz\nnode-v21.7.3-linux-x64.tar.xz\nnode-v21.7.3-win-arm64.7z\nnode-v21.7.3-win-arm64.zip\nnode-v21.7.3-win-x64.7z\nnode-v21.7.3-win-x64.zip\nnode-v21.7.3-win-x86.7z\nnode-v21.7.3-win-x86.zip\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v21.7.3 documentation
          
            
            
          
        
        
          
            Node.js v21.7.3
            
            
            
    
      
        ►▼
        Other versions
      
      21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                ►▼
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/latest-v20.x/\nnode-v20.19.1-aix-ppc64.tar.gz\nnode-v20.19.1-arm64.msi\nnode-v20.19.1-darwin-arm64.tar.gz\nnode-v20.19.1-darwin-arm64.tar.xz\nnode-v20.19.1-darwin-x64.tar.gz\nnode-v20.19.1-darwin-x64.tar.xz\nnode-v20.19.1-headers.tar.gz\nnode-v20.19.1-headers.tar.xz\nnode-v20.19.1-linux-arm64.tar.gz\nnode-v20.19.1-linux-arm64.tar.xz\nnode-v20.19.1-linux-armv7l.tar.gz\nnode-v20.19.1-linux-armv7l.tar.xz\nnode-v20.19.1-linux-ppc64le.tar.gz\nnode-v20.19.1-linux-ppc64le.tar.xz\nnode-v20.19.1-linux-s390x.tar.gz\nnode-v20.19.1-linux-s390x.tar.xz\nnode-v20.19.1-linux-x64.tar.gz\nnode-v20.19.1-linux-x64.tar.xz\nnode-v20.19.1-win-arm64.7z\nnode-v20.19.1-win-arm64.zip\nnode-v20.19.1-win-x64.7z\nnode-v20.19.1-win-x64.zip\nnode-v20.19.1-win-x86.7z\nnode-v20.19.1-win-x86.zip\nnode-v20.19.1-x64.msi\nnode-v20.19.1-x86.msi\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v20.19.1 documentation
          
            
            
          
        
        
          
            Node.js v20.19.1
            
            
            
    
      
        
        Other versions
      
      23.x
22.x LTS
21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/v19.9.0/\nnode-v19.9.0-aix-ppc64.tar.gz\nnode-v19.9.0-arm64.msi\nnode-v19.9.0-darwin-arm64.tar.gz\nnode-v19.9.0-darwin-arm64.tar.xz\nnode-v19.9.0-darwin-x64.tar.gz\nnode-v19.9.0-darwin-x64.tar.xz\nnode-v19.9.0-headers.tar.gz\nnode-v19.9.0-headers.tar.xz\nnode-v19.9.0-linux-arm64.tar.gz\nnode-v19.9.0-linux-arm64.tar.xz\nnode-v19.9.0-linux-armv7l.tar.gz\nnode-v19.9.0-linux-armv7l.tar.xz\nnode-v19.9.0-linux-ppc64le.tar.gz\nnode-v19.9.0-linux-ppc64le.tar.xz\nnode-v19.9.0-linux-s390x.tar.gz\nnode-v19.9.0-linux-s390x.tar.xz\nnode-v19.9.0-linux-x64.tar.gz\nnode-v19.9.0-linux-x64.tar.xz\nnode-v19.9.0-win-arm64.7z\nnode-v19.9.0-win-arm64.zip\nnode-v19.9.0-win-x64.7z\nnode-v19.9.0-win-x64.zip\nnode-v19.9.0-win-x86.7z\nnode-v19.9.0-win-x86.zip\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v19.9.0 documentation
          
            
            
          
        
        
          
            Node.js v19.9.0
            
            
            
    
      
        ►▼
        Other versions
      
      19.x
18.x LTS
17.x
16.x LTS
15.x
14.x LTS
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                ►▼
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/v18.20.8/\nnode-v18.20.8-aix-ppc64.tar.gz\nnode-v18.20.8-darwin-arm64.tar.gz\nnode-v18.20.8-darwin-arm64.tar.xz\nnode-v18.20.8-darwin-x64.tar.gz\nnode-v18.20.8-darwin-x64.tar.xz\nnode-v18.20.8-headers.tar.gz\nnode-v18.20.8-headers.tar.xz\nnode-v18.20.8-linux-arm64.tar.gz\nnode-v18.20.8-linux-arm64.tar.xz\nnode-v18.20.8-linux-armv7l.tar.gz\nnode-v18.20.8-linux-armv7l.tar.xz\nnode-v18.20.8-linux-ppc64le.tar.gz\nnode-v18.20.8-linux-ppc64le.tar.xz\nnode-v18.20.8-linux-s390x.tar.gz\nnode-v18.20.8-linux-s390x.tar.xz\nnode-v18.20.8-linux-x64.tar.gz\nnode-v18.20.8-linux-x64.tar.xz\nnode-v18.20.8-win-x64.7z\nnode-v18.20.8-win-x64.zip\nnode-v18.20.8-win-x86.7z\nnode-v18.20.8-win-x86.zip\nnode-v18.20.8-x64.msi\nnode-v18.20.8-x86.msi\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v18.20.8 documentation
          
            
            
          
        
        
          
            Node.js v18.20.8
            
            
            
    
      
        
        Other versions
      
      23.x
22.x LTS
21.x
20.x LTS
19.x
18.x LTS
17.x
16.x
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Single executable applications
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/v17.9.1/\nnode-v17.9.1-aix-ppc64.tar.gz\nnode-v17.9.1-darwin-arm64.tar.gz\nnode-v17.9.1-darwin-arm64.tar.xz\nnode-v17.9.1-darwin-x64.tar.gz\nnode-v17.9.1-darwin-x64.tar.xz\nnode-v17.9.1-headers.tar.gz\nnode-v17.9.1-headers.tar.xz\nnode-v17.9.1-linux-arm64.tar.gz\nnode-v17.9.1-linux-arm64.tar.xz\nnode-v17.9.1-linux-armv7l.tar.gz\nnode-v17.9.1-linux-armv7l.tar.xz\nnode-v17.9.1-linux-ppc64le.tar.gz\nnode-v17.9.1-linux-ppc64le.tar.xz\nnode-v17.9.1-linux-s390x.tar.gz\nnode-v17.9.1-linux-s390x.tar.xz\nnode-v17.9.1-linux-x64.tar.gz\nnode-v17.9.1-linux-x64.tar.xz\nnode-v17.9.1-win-x64.7z\nnode-v17.9.1-win-x64.zip\nnode-v17.9.1-win-x86.7z\nnode-v17.9.1-win-x86.zip\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v17.9.1 documentation
          
            
            
          
        
        
          
            Node.js v17.9.1
            
            
            
    
      
        ►▼
        Other versions
      
      18.x
17.x
16.x LTS
15.x
14.x LTS
13.x
12.x LTS
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                ►▼
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/v16.20.2/\nnode-v16.20.2-aix-ppc64.tar.gz\nnode-v16.20.2-darwin-arm64.tar.gz\nnode-v16.20.2-darwin-arm64.tar.xz\nnode-v16.20.2-darwin-x64.tar.gz\nnode-v16.20.2-darwin-x64.tar.xz\nnode-v16.20.2-headers.tar.gz\nnode-v16.20.2-headers.tar.xz\nnode-v16.20.2-linux-arm64.tar.gz\nnode-v16.20.2-linux-arm64.tar.xz\nnode-v16.20.2-linux-armv7l.tar.gz\nnode-v16.20.2-linux-armv7l.tar.xz\nnode-v16.20.2-linux-ppc64le.tar.gz\nnode-v16.20.2-linux-ppc64le.tar.xz\nnode-v16.20.2-linux-s390x.tar.gz\nnode-v16.20.2-linux-s390x.tar.xz\nnode-v16.20.2-linux-x64.tar.gz\nnode-v16.20.2-linux-x64.tar.xz\nnode-v16.20.2-win-x64.7z\nnode-v16.20.2-win-x64.zip\nnode-v16.20.2-win-x86.7z\nnode-v16.20.2-win-x86.zip\nnode-v16.20.2-x64.msi\nnode-v16.20.2-x86.msi\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v16.20.2 documentation
          
            
            
          
        
        
          
            Node.js v16.20.2
            
            
            
    
      
        ►▼
        Other versions
      
      20.x
19.x
18.x LTS
17.x
16.x LTS
15.x
14.x
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            
              
                ►▼
                Options
              
        
              
                
                  
                    View on single page
                  
                  
                    View as JSON
                  
                  Edit on GitHub    
                
              
            
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Asynchronous context tracking
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: node:module API
Modules: Packages
Net
OS
Path
Performance hooks
Permissions
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Test runner
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Web Streams API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/latest-v15.x/\nnode-v15.14.0-aix-ppc64.tar.gz\nnode-v15.14.0-darwin-x64.tar.gz\nnode-v15.14.0-darwin-x64.tar.xz\nnode-v15.14.0-headers.tar.gz\nnode-v15.14.0-headers.tar.xz\nnode-v15.14.0-linux-arm64.tar.gz\nnode-v15.14.0-linux-arm64.tar.xz\nnode-v15.14.0-linux-armv7l.tar.gz\nnode-v15.14.0-linux-armv7l.tar.xz\nnode-v15.14.0-linux-ppc64le.tar.gz\nnode-v15.14.0-linux-ppc64le.tar.xz\nnode-v15.14.0-linux-s390x.tar.gz\nnode-v15.14.0-linux-s390x.tar.xz\nnode-v15.14.0-linux-x64.tar.gz\nnode-v15.14.0-linux-x64.tar.xz\nnode-v15.14.0-win-x64.7z\nnode-v15.14.0-win-x64.zip\nnode-v15.14.0-win-x86.7z\nnode-v15.14.0-win-x86.zip\nnode-v15.14.0-x64.msi\nnode-v15.14.0-x86.msi\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v15.14.0 documentation
          
            
            
          
        
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
    
      View another version ▼
      15.x
14.x LTS
13.x
12.x LTS
11.x
10.x LTS
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            Edit on GitHub
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Web Crypto API
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/latest-v14.x/\nnode-v14.21.3-aix-ppc64.tar.gz\nnode-v14.21.3-darwin-x64.tar.gz\nnode-v14.21.3-darwin-x64.tar.xz\nnode-v14.21.3-headers.tar.gz\nnode-v14.21.3-headers.tar.xz\nnode-v14.21.3-linux-arm64.tar.gz\nnode-v14.21.3-linux-arm64.tar.xz\nnode-v14.21.3-linux-armv7l.tar.gz\nnode-v14.21.3-linux-armv7l.tar.xz\nnode-v14.21.3-linux-ppc64le.tar.gz\nnode-v14.21.3-linux-ppc64le.tar.xz\nnode-v14.21.3-linux-s390x.tar.gz\nnode-v14.21.3-linux-s390x.tar.xz\nnode-v14.21.3-linux-x64.tar.gz\nnode-v14.21.3-linux-x64.tar.xz\nnode-v14.21.3-win-x64.7z\nnode-v14.21.3-win-x64.zip\nnode-v14.21.3-win-x86.7z\nnode-v14.21.3-win-x86.zip\nnode-v14.21.3-x64.msi\nnode-v14.21.3-x86.msi\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        
          Node.js v14.21.3 documentation
          
            
            
          
        
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
    
      View another version ▼
      19.x
18.x LTS
17.x
16.x LTS
15.x
14.x LTS
13.x
12.x
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            Edit on GitHub
          
        
        
      

      

      
        


About this documentation
Usage and example



Assertion testing
Async hooks
Buffer
C++ addons
C/C++ addons with Node-API
C++ embedder API
Child processes
Cluster
Command-line options
Console
Corepack
Crypto
Debugger
Deprecated APIs
Diagnostics Channel
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/v13.14.0/\nnode-v13.14.0-aix-ppc64.tar.gz\nnode-v13.14.0-darwin-x64.tar.gz\nnode-v13.14.0-darwin-x64.tar.xz\nnode-v13.14.0-headers.tar.gz\nnode-v13.14.0-headers.tar.xz\nnode-v13.14.0-linux-arm64.tar.gz\nnode-v13.14.0-linux-arm64.tar.xz\nnode-v13.14.0-linux-armv7l.tar.gz\nnode-v13.14.0-linux-armv7l.tar.xz\nnode-v13.14.0-linux-ppc64le.tar.gz\nnode-v13.14.0-linux-ppc64le.tar.xz\nnode-v13.14.0-linux-s390x.tar.gz\nnode-v13.14.0-linux-s390x.tar.xz\nnode-v13.14.0-linux-x64.tar.gz\nnode-v13.14.0-linux-x64.tar.xz\nnode-v13.14.0-sunos-x64.tar.gz\nnode-v13.14.0-sunos-x64.tar.xz\nnode-v13.14.0-win-x64.7z\nnode-v13.14.0-win-x64.zip\nnode-v13.14.0-win-x86.7z\nnode-v13.14.0-win-x86.zip\nnode-v13.14.0-x64.msi\nnode-v13.14.0-x86.msi\n\n\nNode.js
        
      
      
About these Docs
Usage & Example



Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons with N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Policies
Process
Punycode
Query Strings
Readline
REPL
Report
Stream
String Decoder
Timers
TLS/SSL
Trace Events
TTY
UDP/Datagram
URL
Utilities
V8
VM
WASI
Worker Threads
Zlib



GitHub Repo & Issue Tracker

    

    
      
        Node.js v13.14.0 Documentation
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
    
      View another version ▼
      14.x
13.x
12.x LTS
11.x
10.x LTS
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            Edit on GitHub
          
        
        
      

      
        Table of Contents
        
      

      
        


About these Docs
Usage & Example



Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons with N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Policies
Process
Punycode
Query Strings
Readline
REPL
Report
Stream
String Decoder
Timers
TLS/SSL
Trace Events
TTY
UDP/Datagram
URL
Utilities
V8
VM
WASI
Worker Threads
Zlib



GitHub Repo & Issue Tracker\n\n\n\nIndex of /download/release/latest-v12.x/\nnode-v12.22.12-aix-ppc64.tar.gz\nnode-v12.22.12-darwin-x64.tar.gz\nnode-v12.22.12-darwin-x64.tar.xz\nnode-v12.22.12-headers.tar.gz\nnode-v12.22.12-headers.tar.xz\nnode-v12.22.12-linux-arm64.tar.gz\nnode-v12.22.12-linux-arm64.tar.xz\nnode-v12.22.12-linux-armv7l.tar.gz\nnode-v12.22.12-linux-armv7l.tar.xz\nnode-v12.22.12-linux-ppc64le.tar.gz\nnode-v12.22.12-linux-ppc64le.tar.xz\nnode-v12.22.12-linux-s390x.tar.gz\nnode-v12.22.12-linux-s390x.tar.xz\nnode-v12.22.12-linux-x64.tar.gz\nnode-v12.22.12-linux-x64.tar.xz\nnode-v12.22.12-sunos-x64.tar.gz\nnode-v12.22.12-sunos-x64.tar.xz\nnode-v12.22.12-win-x64.7z\nnode-v12.22.12-win-x64.zip\nnode-v12.22.12-win-x86.7z\nnode-v12.22.12-win-x86.zip\nnode-v12.22.12-x64.msi\nnode-v12.22.12-x86.msi\nnode-v12.22.12.tar.gz\nnode-v12.22.12.tar.xz\n\n\nNode.js
        
      
      
About this documentation
Usage and example



Assertion testing
Async hooks
Buffer
C++ Addons
C/C++ Addons with N-API
C++ Embedder API
Child Processes
Cluster
Command line options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Worker threads
Zlib



Code repository and issue tracker

    

    
      
        Node.js v12.22.12 Documentation
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
    
      View another version ▼
      17.x
16.x LTS
15.x
14.x LTS
13.x
12.x LTS
11.x
10.x
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            Edit on GitHub
          
        
        
      

      
        Table of Contents
        
      

      
        


About this documentation
Usage and example



Assertion testing
Async hooks
Buffer
C++ Addons
C/C++ Addons with N-API
C++ Embedder API
Child Processes
Cluster
Command line options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
Errors
Events
File system
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules: CommonJS modules
Modules: ECMAScript modules
Modules: module API
Modules: Packages
Net
OS
Path
Performance hooks
Policies
Process
Punycode
Query strings
Readline
REPL
Report
Stream
String decoder
Timers
TLS/SSL
Trace events
TTY
UDP/datagram
URL
Utilities
V8
VM
WASI
Worker threads
Zlib



Code repository and issue tracker\n\n\n\nIndex of /download/release/v11.15.0/\nnode-v11.15.0-aix-ppc64.tar.gz\nnode-v11.15.0-darwin-x64.tar.gz\nnode-v11.15.0-darwin-x64.tar.xz\nnode-v11.15.0-headers.tar.gz\nnode-v11.15.0-headers.tar.xz\nnode-v11.15.0-linux-arm64.tar.gz\nnode-v11.15.0-linux-arm64.tar.xz\nnode-v11.15.0-linux-armv6l.tar.gz\nnode-v11.15.0-linux-armv6l.tar.xz\nnode-v11.15.0-linux-armv7l.tar.gz\nnode-v11.15.0-linux-armv7l.tar.xz\nnode-v11.15.0-linux-ppc64le.tar.gz\nnode-v11.15.0-linux-ppc64le.tar.xz\nnode-v11.15.0-linux-s390x.tar.gz\nnode-v11.15.0-linux-s390x.tar.xz\nnode-v11.15.0-linux-x64.tar.gz\nnode-v11.15.0-linux-x64.tar.xz\nnode-v11.15.0-sunos-x64.tar.gz\nnode-v11.15.0-sunos-x64.tar.xz\nnode-v11.15.0-win-x64.7z\nnode-v11.15.0-win-x64.zip\nnode-v11.15.0-win-x86.7z\nnode-v11.15.0-win-x86.zip\nnode-v11.15.0-x64.msi\nnode-v11.15.0-x86.msi\n\n\nNode.js
        
      
      
About these Docs
Usage & Example



Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Policies
Process
Punycode
Query Strings
Readline
REPL
Report
Stream
String Decoder
Timers
TLS/SSL
Trace Events
TTY
UDP/Datagram
URL
Utilities
V8
VM
Worker Threads
Zlib



GitHub Repo & Issue Tracker

    

    
      
        Node.js v11.15.0 Documentation
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
    
      View another version ▼
      11.x
10.x LTS
9.x
8.x LTS
7.x
6.x LTS
5.x
4.x
0.12.x
0.10.x
    
  
            Edit on GitHub
          
        
        
      

      
        Table of Contents
        
      

      
        


About these Docs
Usage & Example



Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Policies
Process
Punycode
Query Strings
Readline
REPL
Report
Stream
String Decoder
Timers
TLS/SSL
Trace Events
TTY
UDP/Datagram
URL
Utilities
V8
VM
Worker Threads
Zlib



GitHub Repo & Issue Tracker\n\n\n\nIndex of /download/release/v10.24.1/\nnode-v10.24.1-aix-ppc64.tar.gz\nnode-v10.24.1-darwin-x64.tar.gz\nnode-v10.24.1-darwin-x64.tar.xz\nnode-v10.24.1-headers.tar.gz\nnode-v10.24.1-headers.tar.xz\nnode-v10.24.1-linux-arm64.tar.gz\nnode-v10.24.1-linux-arm64.tar.xz\nnode-v10.24.1-linux-armv6l.tar.gz\nnode-v10.24.1-linux-armv6l.tar.xz\nnode-v10.24.1-linux-armv7l.tar.gz\nnode-v10.24.1-linux-armv7l.tar.xz\nnode-v10.24.1-linux-ppc64le.tar.gz\nnode-v10.24.1-linux-ppc64le.tar.xz\nnode-v10.24.1-linux-s390x.tar.gz\nnode-v10.24.1-linux-s390x.tar.xz\nnode-v10.24.1-linux-x64.tar.gz\nnode-v10.24.1-linux-x64.tar.xz\nnode-v10.24.1-sunos-x64.tar.gz\nnode-v10.24.1-sunos-x64.tar.xz\nnode-v10.24.1-win-x64.7z\nnode-v10.24.1-win-x64.zip\nnode-v10.24.1-win-x86.7z\nnode-v10.24.1-win-x86.zip\nnode-v10.24.1-x64.msi\nnode-v10.24.1-x86.msi\n\n\nNode.js
        
      
      
About these Docs
Usage & Example



Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Trace Events
TTY
UDP/Datagram
URL
Utilities
V8
VM
Worker Threads
Zlib



GitHub Repo & Issue Tracker

    

    
      
        Node.js v10.24.1 Documentation
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
    
      View another version ▼
      15.x
14.x LTS
13.x
12.x LTS
11.x
10.x LTS
9.x
8.x
7.x
6.x
5.x
4.x
0.12.x
0.10.x
    
  
            Edit on GitHub
          
        
        
      

      
        Table of Contents
        
      

      
        


About these Docs
Usage & Example



Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Trace Events
TTY
UDP/Datagram
URL
Utilities
V8
VM
Worker Threads
Zlib



GitHub Repo & Issue Tracker\n\n\n\nIndex of /download/release/v9.11.2/\nnode-v9.11.2-aix-ppc64.tar.gz\nnode-v9.11.2-darwin-x64.tar.gz\nnode-v9.11.2-darwin-x64.tar.xz\nnode-v9.11.2-headers.tar.gz\nnode-v9.11.2-headers.tar.xz\nnode-v9.11.2-linux-arm64.tar.gz\nnode-v9.11.2-linux-arm64.tar.xz\nnode-v9.11.2-linux-armv6l.tar.gz\nnode-v9.11.2-linux-armv6l.tar.xz\nnode-v9.11.2-linux-armv7l.tar.gz\nnode-v9.11.2-linux-armv7l.tar.xz\nnode-v9.11.2-linux-ppc64le.tar.gz\nnode-v9.11.2-linux-ppc64le.tar.xz\nnode-v9.11.2-linux-s390x.tar.gz\nnode-v9.11.2-linux-s390x.tar.xz\nnode-v9.11.2-linux-x64.tar.gz\nnode-v9.11.2-linux-x64.tar.xz\nnode-v9.11.2-linux-x86.tar.gz\nnode-v9.11.2-linux-x86.tar.xz\nnode-v9.11.2-sunos-x64.tar.gz\nnode-v9.11.2-sunos-x64.tar.xz\nnode-v9.11.2-sunos-x86.tar.gz\nnode-v9.11.2-sunos-x86.tar.xz\nnode-v9.11.2-win-x64.7z\nnode-v9.11.2-win-x64.zip\nnode-v9.11.2-win-x86.7z\nnode-v9.11.2-win-x86.zip\n\n\nNode.js
        
      
      

About these Docs
Usage & Example




Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Tracing
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List


    

    
      
        Node.js v9.11.2 Documentation
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
    
      View another version ▼
      9.x
8.x LTS
7.x
6.x LTS
5.x
4.x LTS
0.12.x
0.10.x
    
  
          
        
        
      

      
        Table of Contents
        
      

      
        


About these Docs
Usage & Example




Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Tracing
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List\n\n\n\nIndex of /download/release/v8.17.0/\nnode-v8.17.0-aix-ppc64.tar.gz\nnode-v8.17.0-darwin-x64.tar.gz\nnode-v8.17.0-darwin-x64.tar.xz\nnode-v8.17.0-headers.tar.gz\nnode-v8.17.0-headers.tar.xz\nnode-v8.17.0-linux-arm64.tar.gz\nnode-v8.17.0-linux-arm64.tar.xz\nnode-v8.17.0-linux-armv6l.tar.gz\nnode-v8.17.0-linux-armv6l.tar.xz\nnode-v8.17.0-linux-armv7l.tar.gz\nnode-v8.17.0-linux-armv7l.tar.xz\nnode-v8.17.0-linux-ppc64le.tar.gz\nnode-v8.17.0-linux-ppc64le.tar.xz\nnode-v8.17.0-linux-s390x.tar.gz\nnode-v8.17.0-linux-s390x.tar.xz\nnode-v8.17.0-linux-x64.tar.gz\nnode-v8.17.0-linux-x64.tar.xz\nnode-v8.17.0-linux-x86.tar.gz\nnode-v8.17.0-linux-x86.tar.xz\nnode-v8.17.0-sunos-x64.tar.gz\nnode-v8.17.0-sunos-x64.tar.xz\nnode-v8.17.0-sunos-x86.tar.gz\nnode-v8.17.0-sunos-x86.tar.xz\nnode-v8.17.0-win-x64.7z\nnode-v8.17.0-win-x64.zip\nnode-v8.17.0-win-x86.7z\nnode-v8.17.0-win-x86.zip\n\n\nNode.js
        
      
      
About these Docs
Usage & Example




Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Tracing
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker


    

    
      
        Node.js v8.17.0 Documentation
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
          
        
        
      

      
        Table of Contents
        
      

      
        

About these Docs
Usage & Example




Assertion Testing
Async Hooks
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
ECMAScript Modules
Errors
Events
File System
Globals
HTTP
HTTP/2
HTTPS
Inspector
Internationalization
Modules
Net
OS
Path
Performance Hooks
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Tracing
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker\n\n\n\nIndex of /download/release/latest-v7.x/\nnode-v7.10.1-aix-ppc64.tar.gz\nnode-v7.10.1-darwin-x64.tar.gz\nnode-v7.10.1-darwin-x64.tar.xz\nnode-v7.10.1-headers.tar.gz\nnode-v7.10.1-headers.tar.xz\nnode-v7.10.1-linux-arm64.tar.gz\nnode-v7.10.1-linux-arm64.tar.xz\nnode-v7.10.1-linux-armv6l.tar.gz\nnode-v7.10.1-linux-armv6l.tar.xz\nnode-v7.10.1-linux-armv7l.tar.gz\nnode-v7.10.1-linux-armv7l.tar.xz\nnode-v7.10.1-linux-ppc64.tar.gz\nnode-v7.10.1-linux-ppc64.tar.xz\nnode-v7.10.1-linux-ppc64le.tar.gz\nnode-v7.10.1-linux-ppc64le.tar.xz\nnode-v7.10.1-linux-s390x.tar.gz\nnode-v7.10.1-linux-s390x.tar.xz\nnode-v7.10.1-linux-x64.tar.gz\nnode-v7.10.1-linux-x64.tar.xz\nnode-v7.10.1-linux-x86.tar.gz\nnode-v7.10.1-linux-x86.tar.xz\nnode-v7.10.1-sunos-x64.tar.gz\nnode-v7.10.1-sunos-x64.tar.xz\nnode-v7.10.1-sunos-x86.tar.gz\nnode-v7.10.1-sunos-x86.tar.xz\nnode-v7.10.1-win-x64.7z\nnode-v7.10.1-win-x64.zip\nnode-v7.10.1-win-x86.7z\nnode-v7.10.1-win-x86.zip\n\n\nNode.js
        
      
      
About these Docs
Usage & Example




Assertion Testing
Buffer
C/C++ Addons
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Tracing
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List


    

    
      
        Node.js v7.10.1 Documentation
        
          
            Index |
            View on single page |
            View as JSON
          
        
        
      

      
        Table of Contents
        
      

      
        

About these Docs
Usage & Example




Assertion Testing
Buffer
C/C++ Addons
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
Deprecated APIs
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
Tracing
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List\n\n\n\nIndex of /download/release/v6.17.1/\nnode-v6.17.1-aix-ppc64.tar.gz\nnode-v6.17.1-darwin-x64.tar.gz\nnode-v6.17.1-darwin-x64.tar.xz\nnode-v6.17.1-headers.tar.gz\nnode-v6.17.1-headers.tar.xz\nnode-v6.17.1-linux-arm64.tar.gz\nnode-v6.17.1-linux-arm64.tar.xz\nnode-v6.17.1-linux-armv6l.tar.gz\nnode-v6.17.1-linux-armv6l.tar.xz\nnode-v6.17.1-linux-armv7l.tar.gz\nnode-v6.17.1-linux-armv7l.tar.xz\nnode-v6.17.1-linux-ppc64.tar.gz\nnode-v6.17.1-linux-ppc64.tar.xz\nnode-v6.17.1-linux-ppc64le.tar.gz\nnode-v6.17.1-linux-ppc64le.tar.xz\nnode-v6.17.1-linux-s390x.tar.gz\nnode-v6.17.1-linux-s390x.tar.xz\nnode-v6.17.1-linux-x64.tar.gz\nnode-v6.17.1-linux-x64.tar.xz\nnode-v6.17.1-linux-x86.tar.gz\nnode-v6.17.1-linux-x86.tar.xz\nnode-v6.17.1-sunos-x64.tar.gz\nnode-v6.17.1-sunos-x64.tar.xz\nnode-v6.17.1-sunos-x86.tar.gz\nnode-v6.17.1-sunos-x86.tar.xz\nnode-v6.17.1-win-x64.7z\nnode-v6.17.1-win-x64.zip\nnode-v6.17.1-win-x86.7z\nnode-v6.17.1-win-x86.zip\n\n\nNode.js
        
      
      
About these Docs
Usage & Example




Assertion Testing
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Internationalization
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List


    

    
      
        Node.js v6.17.1 Documentation
        
          
            
              Index
            
            
              View on single page
            
            
              View as JSON
            
            
          
        
        
      

      
        Table of Contents
        
      

      
        

About these Docs
Usage & Example




Assertion Testing
Buffer
C++ Addons
C/C++ Addons - N-API
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Internationalization
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List\n\n\n\nIndex of /download/release/v5.12.0/\nnode-v5.12.0-darwin-x64.tar.gz\nnode-v5.12.0-darwin-x64.tar.xz\nnode-v5.12.0-headers.tar.gz\nnode-v5.12.0-headers.tar.xz\nnode-v5.12.0-linux-arm64.tar.gz\nnode-v5.12.0-linux-arm64.tar.xz\nnode-v5.12.0-linux-armv6l.tar.gz\nnode-v5.12.0-linux-armv6l.tar.xz\nnode-v5.12.0-linux-armv7l.tar.gz\nnode-v5.12.0-linux-armv7l.tar.xz\nnode-v5.12.0-linux-ppc64.tar.gz\nnode-v5.12.0-linux-ppc64.tar.xz\nnode-v5.12.0-linux-ppc64le.tar.gz\nnode-v5.12.0-linux-ppc64le.tar.xz\nnode-v5.12.0-linux-x64.tar.gz\nnode-v5.12.0-linux-x64.tar.xz\nnode-v5.12.0-linux-x86.tar.gz\nnode-v5.12.0-linux-x86.tar.xz\nnode-v5.12.0-sunos-x64.tar.gz\nnode-v5.12.0-sunos-x64.tar.xz\nnode-v5.12.0-sunos-x86.tar.gz\nnode-v5.12.0-sunos-x86.tar.xz\n\n\nNode.js (1)
        
      
      
About these Docs
Synopsis
Assertion Testing
Buffer
C/C++ Addons
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB


    

    
      
        Node.js v5.12.0 Documentation
        
          
            Index |
            View on single page |
            View as JSON
          
        
        
      

      
        Table of Contents
        
      

      
        
About these Docs
Synopsis
Assertion Testing
Buffer
C/C++ Addons
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB\n\n\n\nIndex of /download/release/v4.9.1/\nnode-v4.9.1-darwin-x64.tar.gz\nnode-v4.9.1-darwin-x64.tar.xz\nnode-v4.9.1-headers.tar.gz\nnode-v4.9.1-headers.tar.xz\nnode-v4.9.1-linux-arm64.tar.gz\nnode-v4.9.1-linux-arm64.tar.xz\nnode-v4.9.1-linux-armv6l.tar.gz\nnode-v4.9.1-linux-armv6l.tar.xz\nnode-v4.9.1-linux-armv7l.tar.gz\nnode-v4.9.1-linux-armv7l.tar.xz\nnode-v4.9.1-linux-ppc64.tar.gz\nnode-v4.9.1-linux-ppc64.tar.xz\nnode-v4.9.1-linux-ppc64le.tar.gz\nnode-v4.9.1-linux-ppc64le.tar.xz\nnode-v4.9.1-linux-x64.tar.gz\nnode-v4.9.1-linux-x64.tar.xz\nnode-v4.9.1-linux-x86.tar.gz\nnode-v4.9.1-linux-x86.tar.xz\nnode-v4.9.1-sunos-x64.tar.gz\nnode-v4.9.1-sunos-x64.tar.xz\nnode-v4.9.1-sunos-x86.tar.gz\nnode-v4.9.1-sunos-x86.tar.xz\nnode-v4.9.1-win-x64.7z\nnode-v4.9.1-win-x64.zip\nnode-v4.9.1-win-x86.7z\nnode-v4.9.1-win-x86.zip\n\n\nNode.js
        
      
      
About these Docs
Usage & Example




Assertion Testing
Buffer
C/C++ Addons
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List


    

    
      
        Node.js v4.9.1 Documentation
        
          
            Index |
            View on single page |
            View as JSON
          
        
        
      

      
        Table of Contents
        
      

      
        

About these Docs
Usage & Example




Assertion Testing
Buffer
C/C++ Addons
Child Processes
Cluster
Command Line Options
Console
Crypto
Debugger
DNS
Domain
Errors
Events
File System
Globals
HTTP
HTTPS
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Stream
String Decoder
Timers
TLS/SSL
TTY
UDP/Datagram
URL
Utilities
V8
VM
ZLIB




GitHub Repo & Issue Tracker
Mailing List\n\n\n\nIndex of /download/release/v0.12.18/\nnode-v0.12.18-darwin-x64.tar.gz\nnode-v0.12.18-darwin-x64.tar.xz\nnode-v0.12.18-darwin-x86.tar.gz\nnode-v0.12.18-darwin-x86.tar.xz\nnode-v0.12.18-headers.tar.gz\nnode-v0.12.18-headers.tar.xz\nnode-v0.12.18-linux-x64.tar.gz\nnode-v0.12.18-linux-x64.tar.xz\nnode-v0.12.18-linux-x86.tar.gz\nnode-v0.12.18-linux-x86.tar.xz\nnode-v0.12.18-sunos-x86.tar.gz\nnode-v0.12.18-sunos-x86.tar.xz\nnode-v0.12.18-x86.msi\n\n\nAbout Docs
          Tutorials
          Contributing
          Workflow
          Localization
          API Docs
        
      
        
          
            Node.js v0.12.18 Manual & Documentation
            
              
                Index |
                View on single page |
                View as JSON
              
            
            
          

          
            Table of Contents
            
          

          
            
About these Docs
Synopsis
Assertion Testing
Buffer
C/C++ Addons
Child Processes
Cluster
Console
Crypto
Debugger
DNS
Domain
Events
File System
Globals
HTTP
HTTPS
Modules
Net
OS
Path
Process
Punycode
Query Strings
Readline
REPL
Smalloc
Stream
String Decoder
Timers
TLS/SSL
TTY
UDP/Datagram
URL
Utilities
VM
ZLIB\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\nNode.js Releases
Major Node.js versions enter Current release status for six months, which gives library authors time to add support for them.
After six months, odd-numbered releases (9, 11, etc.) become unsupported, and even-numbered releases (10, 12, etc.) move to Active LTS status and are ready for general use.
LTS release status is "long-term support", which typically guarantees that critical bugs will be fixed for a total of 30 months.
Production applications should only use Active LTS or Maintenance LTS releases.
Release Schedule

Full details regarding the Node.js release schedule are available on GitHub.
Commercial Support
Commercial support for versions past the Maintenance phase is available through our OpenJS Ecosystem Sustainability Program partner HeroDevs.
Looking for the latest release of a version branch?
Node.jsN-APICodenameReleased atnpmv23.11.0v131-2025-04-01v10.9.2ReleasesChangelogDocsv22.15.0v127Jod2025-04-22v10.9.2ReleasesChangelogDocsv21.7.3v120-2024-04-10v10.5.0ReleasesChangelogDocsv20.19.1v115Iron2025-04-22v10.8.2ReleasesChangelogDocsv19.9.0v111-2023-04-10v9.6.3ReleasesChangelogDocsv18.20.8v108Hydrogen2025-03-27v10.8.2ReleasesChangelogDocsv17.9.1v102-2022-06-01v8.11.0ReleasesChangelogDocsv16.20.2v93Gallium2023-08-08v8.19.4ReleasesChangelogDocsv15.14.0v88-2021-04-06v7.7.6ReleasesChangelogDocsv14.21.3v83Fermium2023-02-16v6.14.18ReleasesChangelogDocsv13.14.0v79-2020-04-29v6.14.4ReleasesChangelogDocsv12.22.12v72Erbium2022-04-05v6.14.16ReleasesChangelogDocsv11.15.0v67-2019-04-30v6.7.0ReleasesChangelogDocsv10.24.1v64Dubnium2021-04-06v6.14.12ReleasesChangelogDocsv9.11.2v59-2018-06-12v5.6.0ReleasesChangelogDocsv8.17.0v57Carbon2019-12-17v6.13.4ReleasesChangelogDocsv7.10.1v51-2017-07-11v4.2.0ReleasesChangelogDocsv6.17.1v48Boron2019-04-03v3.10.10ReleasesChangelogDocsv5.12.0v47-2016-06-23v3.8.6ReleasesChangelogDocsv4.9.1v46Argon2018-03-29v2.15.11ReleasesChangelogDocsv0.12.18v14-2017-02-22v2.15.11ReleasesChangelogDocs
Official vs. Community Installation Methods
The Node.js website provides several non-interactive installation methods, including command-line interfaces (CLIs), operating system (OS) package managers (e.g., brew), and Node.js version managers (e.g., nvm).
To highlight and promote community contributions, the Node.js project introduced a revised Downloads page categorizing installation methods as either “Official” or “Community.” This provides users with increased flexibility and choice. To ensure clarity, we’ve defined criteria for each category.
Official Installation Methods
Installation methods designated as “Official” must meet the following requirements:
Requirements (Official Installation Methods)New Node.js releases must be available simultaneously with the official release.Project maintainers must have a close relationship with the Node.js project, including direct communication channels.Installation method must download official binaries bundled by the Node.js project.Installation method must not build from source when pre-built binaries are available, nor should it alter the official binaries.
Community Installation Methods
Community installation methods included on the self-service download page (/download) must also adhere to a minimum set of criteria:

Version Support: Must support all currently supported, non-End-of-Life (EOL) Node.js versions.
OS Compatibility: Must function on at least one officially supported Operating System (OS).
Broad OS Support: Cannot be limited to a subset of OS distributions or versions.

For example, an installation method claiming compatibility with “Windows” must function on “Windows 10”, “Windows 11”, and all their editions (including server versions).
Similarly, an installation method claiming compatibility with “Linux” must be installable on all major Linux distributions, not just a specific subset. It cannot rely on distribution-specific package managers like apt or dnf.


Free and Open Source: Must be free to use and open source, must not be sold as a commercial product, and must not be a paid service.\n\n\n\nIntroduction to Node.js
Node.js is an open-source and cross-platform JavaScript runtime environment. It is a popular tool for almost any kind of project!
Node.js runs the V8 JavaScript engine, the core of Google Chrome, outside of the browser. This allows Node.js to be very performant.
A Node.js app runs in a single process, without creating a new thread for every request. Node.js provides a set of asynchronous I/O primitives in its standard library that prevent JavaScript code from blocking and generally, libraries in Node.js are written using non-blocking paradigms, making blocking behavior the exception rather than the norm.
When Node.js performs an I/O operation, like reading from the network, accessing a database or the filesystem, instead of blocking the thread and wasting CPU cycles waiting, Node.js will resume the operations when the response comes back.
This allows Node.js to handle thousands of concurrent connections with a single server without introducing the burden of managing thread concurrency, which could be a significant source of bugs.
Node.js has a unique advantage because millions of frontend developers that write JavaScript for the browser are now able to write the server-side code in addition to the client-side code without the need to learn a completely different language.
In Node.js the new ECMAScript standards can be used without problems, as you don't have to wait for all your users to update their browsers - you are in charge of deciding which ECMAScript version to use by changing the Node.js version, and you can also enable specific experimental features by running Node.js with flags.
An Example Node.js Application
The most common example Hello World of Node.js is a web server:
CJSMJSconst { createServer } = require('node:http');

const hostname = '127.0.0.1';
const port = 3000;

const server = createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello World');
});

server.listen(port, hostname, () => {
  console.log(`Server running at http://${hostname}:${port}/`);
});
JavaScriptCopy to clipboardTo run this snippet, save it as a server.js file and run node server.js in your terminal.
If you use mjs version of the code, you should save it as a server.mjs file and run node server.mjs in your terminal.
This code first includes the Node.js http module.
Node.js has a fantastic standard library, including first-class support for networking.
The createServer() method of http creates a new HTTP server and returns it.
The server is set to listen on the specified port and host name. When the server is ready, the callback function is called, in this case informing us that the server is running.
Whenever a new request is received, the request event is called, providing two objects: a request (an http.IncomingMessage object) and a response (an http.ServerResponse object).
Those 2 objects are essential to handle the HTTP call.
The first provides the request details. In this simple example, this is not used, but you could access the request headers and request data.
The second is used to return data to the caller.
In this case with:
res.statusCode = 200;
JavaScriptCopy to clipboard
we set the statusCode property to 200, to indicate a successful response.
We set the Content-Type header:
res.setHeader('Content-Type', 'text/plain');
JavaScriptCopy to clipboard
and we close the response, adding the content as an argument to end():
res.end('Hello World\n');
JavaScriptCopy to clipboard
If you haven't already done so, download Node.js.NextHow much JavaScript do you need to know to use Node.js?\n\n\n\nHow much JavaScript do you need to know to use Node.js?
As a beginner, it's hard to get to a point where you are confident enough in your programming abilities. While learning to code, you might also be confused at where does JavaScript end, and where Node.js begins, and vice versa.
What is recommended to learn before diving deep with Node.js?

Lexical Structure
Expressions
Data Types
Classes
Variables
Functions
this operator
Arrow Functions
Loops
Scopes
Arrays
Template Literals
Strict Mode
ECMAScript 2015 (ES6) and beyond
Asynchronous JavaScript

With those concepts in mind, you are well on your road to become a proficient JavaScript developer, in both the browser and in Node.js.
Asynchronous Programming
The following concepts are also key to understand asynchronous programming, which is one of the fundamental parts of Node.js:

Asynchronous programming and callbacks
Timers
Promises
Async and Await
Closures
The Event Loop
PrevIntroduction to Node.jsNextDifferences between Node.js and the Browser\n\n\n\nDifferences between Node.js and the Browser
Both the browser and Node.js use JavaScript as their programming language. Building apps that run in the browser is completely different from building a Node.js application. Despite the fact that it's always JavaScript, there are some key differences that make the experience radically different.
From the perspective of a frontend developer who extensively uses JavaScript, Node.js apps bring with them a huge advantage: the comfort of programming everything - the frontend and the backend - in a single language.
You have a huge opportunity because we know how hard it is to fully, deeply learn a programming language, and by using the same language to perform all your work on the web - both on the client and on the server, you're in a unique position of advantage.

What changes is the ecosystem.

In the browser, most of the time what you are doing is interacting with the DOM, or other Web Platform APIs like Cookies. Those do not exist in Node.js, of course. You don't have the document, window and all the other objects that are provided by the browser.
And in the browser, we don't have all the nice APIs that Node.js provides through its modules, like the filesystem access functionality.
Another big difference is that in Node.js you control the environment. Unless you are building an open source application that anyone can deploy anywhere, you know which version of Node.js you will run the application on. Compared to the browser environment, where you don't get the luxury to choose what browser your visitors will use, this is very convenient.
This means that you can write all the modern ES2015+ JavaScript that your Node.js version supports. Since JavaScript moves so fast, but browsers can be a bit slow to upgrade, sometimes on the web you are stuck with using older JavaScript / ECMAScript releases. You can use Babel to transform your code to be ES5-compatible before shipping it to the browser, but in Node.js, you won't need that.
Another difference is that Node.js supports both the CommonJS and ES module systems (since Node.js v12), while in the browser, we are starting to see the ES Modules standard being implemented.
In practice, this means that you can use both require() and import in Node.js, while you are limited to import in the browser.PrevHow much JavaScript do you need to know to use Node.js?NextThe V8 JavaScript Engine\n\n\n\nThe V8 JavaScript Engine
V8 is the name of the JavaScript engine that powers Google Chrome. It's the thing that takes our JavaScript and executes it while browsing with Chrome.
V8 is the JavaScript engine i.e. it parses and executes JavaScript code. The DOM, and the other Web Platform APIs (they all makeup runtime environment) are provided by the browser.
The cool thing is that the JavaScript engine is independent of the browser in which it's hosted. This key feature enabled the rise of Node.js. V8 was chosen to be the engine that powered Node.js back in 2009, and as the popularity of Node.js exploded, V8 became the engine that now powers an incredible amount of server-side code written in JavaScript.
The Node.js ecosystem is huge and thanks to V8 which also powers desktop apps, with projects like Electron.
Other JS engines
Other browsers have their own JavaScript engine:

Firefox has SpiderMonkey
Safari has JavaScriptCore (also called Nitro)
Edge was originally based on Chakra but has more recently been rebuilt using Chromium and the V8 engine.

and many others exist as well.
All those engines implement the ECMA ES-262 standard, also called ECMAScript, the standard used by JavaScript.
The quest for performance
V8 is written in C++, and it's continuously improved. It is portable and runs on Mac, Windows, Linux and several other systems.
In this V8 introduction, we will ignore the implementation details of V8: they can be found on more authoritative sites (e.g. the V8 official site), and they change over time, often radically.
V8 is always evolving, just like the other JavaScript engines around, to speed up the Web and the Node.js ecosystem.
On the web, there is a race for performance that's been going on for years, and we (as users and developers) benefit a lot from this competition because we get faster and more optimized machines year after year.
Compilation
JavaScript is generally considered an interpreted language, but modern JavaScript engines no longer just interpret JavaScript, they compile it.
This has been happening since 2009, when the SpiderMonkey JavaScript compiler was added to Firefox 3.5, and everyone followed this idea.
JavaScript is internally compiled by V8 with just-in-time (JIT) compilation to speed up the execution.
This might seem counter-intuitive, but since the introduction of Google Maps in 2004, JavaScript has evolved from a language that was generally executing a few dozens of lines of code to complete applications with thousands to hundreds of thousands of lines running in the browser.
Our applications can now run for hours inside a browser, rather than being just a few form validation rules or simple scripts.
In this new world, compiling JavaScript makes perfect sense because while it might take a little bit more to have the JavaScript ready, once done it's going to be much more performant than purely interpreted code.PrevDifferences between Node.js and the BrowserNextAn introduction to the npm package manager\n\n\n\nAn introduction to the npm package manager
Introduction to npm
npm is the standard package manager for Node.js.
In September 2022 over 2.1 million packages were reported being listed in the npm registry, making it the biggest single language code repository on Earth, and you can be sure there is a package for (almost!) everything.
It started as a way to download and manage dependencies of Node.js packages, but it has since become a tool used also in frontend JavaScript.

Yarn and pnpm are alternatives to npm cli. You can check them out as well.

Packages
npm installs, updates and manages downloads of dependencies of your project. Dependencies are pre-built pieces of code, such as libraries and packages, that your Node.js application needs to work.
Installing all dependencies
If a project has a package.json file, by running
npm install
ShellCopy to clipboard
it will install everything the project needs, in the node_modules folder, creating it if it's not existing already.
Installing a single package
You can also install a specific package by running
npm install <package-name>
ShellCopy to clipboard
Furthermore, since npm 5, this command adds <package-name> to the package.json file dependencies. Before version 5, you needed to add the flag --save.
Often you'll see more flags added to this command:

--save-dev installs and adds the entry to the package.json file devDependencies
--no-save installs but does not add the entry to the package.json file dependencies
--save-optional installs and adds the entry to the package.json file optionalDependencies
--no-optional will prevent optional dependencies from being installed

Shorthands of the flags can also be used:

-S: --save
-D: --save-dev
-O: --save-optional

The difference between devDependencies and dependencies is that the former contains development tools, like a testing library, while the latter is bundled with the app in production.
As for the optionalDependencies the difference is that build failure of the dependency will not cause installation to fail. But it is your program's responsibility to handle the lack of the dependency. Read more about optional dependencies.
Updating packages
Updating is also made easy, by running
npm update
ShellCopy to clipboard
npm will check all packages for a newer version that satisfies your versioning constraints.
You can specify a single package to update as well:
npm update <package-name>
ShellCopy to clipboard
Versioning
In addition to plain downloads, npm also manages versioning, so you can specify any specific version of a package, or require a version higher or lower than what you need.
Many times you'll find that a library is only compatible with a major release of another library.
Or a bug in the latest release of a lib, still unfixed, is causing an issue.
Specifying an explicit version of a library also helps to keep everyone on the same exact version of a package, so that the whole team runs the same version until the package.json file is updated.
In all those cases, versioning helps a lot, and npm follows the semantic versioning (semver) standard.
You can install a specific version of a package, by running
npm install <package-name>@<version>
ShellCopy to clipboard
Running Tasks
The package.json file supports a format for specifying command line tasks that can be run by using
npm run <task-name>
ShellCopy to clipboard
For example:
{
  "scripts": {
    "start-dev": "node lib/server-development",
    "start": "node lib/server-production"
  }
}
JSONCopy to clipboard
It's very common to use this feature to run Webpack:
{
  "scripts": {
    "watch": "webpack --watch --progress --colors --config webpack.conf.js",
    "dev": "webpack --progress --colors --config webpack.conf.js",
    "prod": "NODE_ENV=production webpack -p --config webpack.conf.js"
  }
}
JSONCopy to clipboard
So instead of typing those long commands, which are easy to forget or mistype, you can run
$ npm run watch
$ npm run dev
$ npm run prod
Shell SessionCopy to clipboardPrevThe V8 JavaScript EngineNextECMAScript 2015 (ES6) and beyond\n\n\n\nECMAScript 2015 (ES6) and beyond
Node.js is built against modern versions of V8. By keeping up-to-date with the latest releases of this engine, we ensure new features from the JavaScript ECMA-262 specification are brought to Node.js developers in a timely manner, as well as continued performance and stability improvements.
All ECMAScript 2015 (ES6) features are split into three groups for shipping, staged, and in progress features:

All shipping features, which V8 considers stable, are turned on by default on Node.js and do NOT require any kind of runtime flag.
Staged features, which are almost-completed features that are not considered stable by the V8 team, require a runtime flag: --harmony.
In progress features can be activated individually by their respective harmony flag, although this is highly discouraged unless for testing purposes. Note: these flags are exposed by V8 and will potentially change without any deprecation notice.

Which features ship with which Node.js version by default?
The website node.green provides an excellent overview over supported ECMAScript features in various versions of Node.js, based on kangax's compat-table.
Which features are in progress?
New features are constantly being added to the V8 engine. Generally speaking, expect them to land on a future Node.js release, although timing is unknown.
You may list all the in progress features available on each Node.js release by grepping through the --v8-options argument. Please note that these are incomplete and possibly broken features of V8, so use them at your own risk:
node --v8-options | grep "in progress"
ShellCopy to clipboard
I have my infrastructure set up to leverage the --harmony flag. Should I remove it?
The current behavior of the --harmony flag on Node.js is to enable staged features only. After all, it is now a synonym of --es_staging. As mentioned above, these are completed features that have not been considered stable yet. If you want to play safe, especially on production environments, consider removing this runtime flag until it ships by default on V8 and, consequently, on Node.js. If you keep this enabled, you should be prepared for further Node.js upgrades to break your code if V8 changes their semantics to more closely follow the standard.
How do I find which version of V8 ships with a particular version of Node.js?
Node.js provides a simple way to list all dependencies and respective versions that ship with a specific binary through the process global object. In case of the V8 engine, type the following in your terminal to retrieve its version:
node -p process.versions.v8
ShellCopy to clipboardPrevAn introduction to the npm package managerNextNode.js, the difference between development and production\n\n\n\nNode.js, the difference between development and production
There is no difference between development and production in Node.js, i.e., there are no specific settings you need to apply to make Node.js work in a production configuration.
However, a few libraries in the npm registry recognize using the NODE_ENV variable and default it to a development setting.
Always run your Node.js with the NODE_ENV=production set.
A popular way of configuring your application is by using the twelve factor methodology.
Why is NODE_ENV considered an antipattern?
An environment is a digital platform or a system where engineers can build, test, deploy, and manage software products. Conventionally, there are four stages or types of environments where our application is run:

Development
Testing
Staging
Production

The fundamental problem of NODE_ENV stems from developers combining optimizations and software behavior with the environment their software is running on. The result is code like the following:
if (process.env.NODE_ENV === 'development') {
  // ...
}

if (process.env.NODE_ENV === 'production') {
  // ...
}

if (['production', 'staging'].includes(process.env.NODE_ENV)) {
  // ...
}
JavaScriptCopy to clipboard
While this might look harmless, it makes the production and staging environments different, thus making reliable testing impossible. For example a test and thus a functionality of your product could pass when NODE_ENV is set to development but fail when setting NODE_ENV to production.
Therefore, setting NODE_ENV to anything but production is considered an antipattern.PrevECMAScript 2015 (ES6) and beyondNextNode.js with WebAssembly\n\n\n\nNode.js with WebAssembly
WebAssembly is a high-performance assembly-like language that can be compiled from various languages, including C/C++, Rust, and AssemblyScript. Currently, it is supported by Chrome, Firefox, Safari, Edge, and Node.js!
The WebAssembly specification details two file formats, a binary format called a WebAssembly Module with a .wasm extension and corresponding text representation called WebAssembly Text format with a .wat extension.
Key Concepts

Module - A compiled WebAssembly binary, ie a .wasm file.
Memory - A resizable ArrayBuffer.
Table - A resizable typed array of references not stored in Memory.
Instance - An instantiation of a Module with its Memory, Table, and variables.

In order to use WebAssembly, you need a .wasm binary file and a set of APIs to communicate with WebAssembly. Node.js provides the necessary APIs via the global WebAssembly object.
console.log(WebAssembly);
/*
Object [WebAssembly] {
  compile: [Function: compile],
  validate: [Function: validate],
  instantiate: [Function: instantiate]
}
*/
JavaScriptCopy to clipboard
Generating WebAssembly Modules
There are multiple methods available to generate WebAssembly binary files including:

Writing WebAssembly (.wat) by hand and converting to binary format using tools such as wabt
Using emscripten with a C/C++ application
Using wasm-pack with a Rust application
Using AssemblyScript if you prefer a TypeScript-like experience


Some of these tools generate not only the binary file, but the JavaScript "glue" code and corresponding HTML files to run in the browser.

How to use it
Once you have a WebAssembly module, you can use the Node.js WebAssembly object to instantiate it.
JSMJS// Assume add.wasm file exists that contains a single function adding 2 provided arguments
const fs = require('node:fs');

// Use the readFileSync function to read the contents of the "add.wasm" file
const wasmBuffer = fs.readFileSync('/path/to/add.wasm');

// Use the WebAssembly.instantiate method to instantiate the WebAssembly module
WebAssembly.instantiate(wasmBuffer).then(wasmModule => {
  // Exported function lives under instance.exports object
  const { add } = wasmModule.instance.exports;
  const sum = add(5, 6);
  console.log(sum); // Outputs: 11
});
JavaScriptCopy to clipboardInteracting with the OS
WebAssembly modules cannot directly access OS functionality on its own. A third-party tool Wasmtime can be used to access this functionality. Wasmtime utilizes the WASI API to access the OS functionality.
Resources

General WebAssembly Information
MDN Docs
Write WebAssembly by hand
PrevNode.js, the difference between development and productionNextDebugging Node.js\n\n\n\nDebugging Node.js
This guide will help you get started debugging your Node.js apps and scripts.
Enable Inspector
When started with the --inspect switch, a Node.js process listens for a
debugging client. By default, it will listen at host and port 127.0.0.1:9229.
Each process is also assigned a unique UUID.
Inspector clients must know and specify host address, port, and UUID to connect.
A full URL will look something like
ws://127.0.0.1:9229/0f2c936f-b1cd-4ac9-aab3-f63b0f33d55e.
Node.js will also start listening for debugging messages if it receives a
SIGUSR1 signal. (SIGUSR1 is not available on Windows.) In Node.js 7 and
earlier, this activates the legacy Debugger API. In Node.js 8 and later, it will
activate the Inspector API.
Security Implications
Since the debugger has full access to the Node.js execution environment, a
malicious actor able to connect to this port may be able to execute arbitrary
code on behalf of the Node.js process. It is important to understand the security
implications of exposing the debugger port on public and private networks.
Exposing the debug port publicly is unsafe
If the debugger is bound to a public IP address, or to 0.0.0.0, any clients that
can reach your IP address will be able to connect to the debugger without any
restriction and will be able to run arbitrary code.
By default node --inspect binds to 127.0.0.1. You explicitly need to provide a
public IP address or 0.0.0.0, etc., if you intend to allow external connections
to the debugger. Doing so may expose you to a potentially significant security
threat. We suggest you ensure appropriate firewalls and access controls in place
to prevent a security exposure.
See the section on 'Enabling remote debugging scenarios' on some advice on how
to safely allow remote debugger clients to connect.
Local applications have full access to the inspector
Even if you bind the inspector port to 127.0.0.1 (the default), any applications
running locally on your machine will have unrestricted access. This is by design
to allow local debuggers to be able to attach conveniently.
Browsers, WebSockets and same-origin policy
Websites open in a web-browser can make WebSocket and HTTP requests under the
browser security model. An initial HTTP connection is necessary to obtain a
unique debugger session id. The same-origin-policy prevents websites from being
able to make this HTTP connection. For additional security against
DNS rebinding attacks, Node.js
verifies that the 'Host' headers for the connection either
specify an IP address or localhost precisely.
These security policies disallow connecting to a remote debug server by
specifying the hostname. You can work-around this restriction by specifying
either the IP address or by using ssh tunnels as described below.
Inspector Clients
A minimal CLI debugger is available with node inspect myscript.js.
Several commercial and open source tools can also connect to the Node.js Inspector.
Chrome DevTools 55+, Microsoft Edge

Option 1: Open chrome://inspect in a Chromium-based
browser or edge://inspect in Edge. Click the Configure button and ensure your target host and port
are listed.
Option 2: Copy the devtoolsFrontendUrl from the output of /json/list
(see above) or the --inspect hint text and paste into Chrome.

See https://github.com/ChromeDevTools/devtools-frontend, https://www.microsoftedgeinsider.com for more information.
Visual Studio Code 1.10+

In the Debug panel, click the settings icon to open .vscode/launch.json.
Select "Node.js" for initial setup.

See https://github.com/microsoft/vscode for more information.
Visual Studio 2017+

Choose "Debug > Start Debugging" from the menu or hit F5.
Detailed instructions.

JetBrains WebStorm and other JetBrains IDEs

Create a new Node.js debug configuration and hit Debug. --inspect will be used
by default for Node.js 7+. To disable uncheck js.debugger.node.use.inspect in
the IDE Registry. To learn more about running and debugging Node.js in WebStorm and other JetBrains IDEs,
check out WebStorm online help.

chrome-remote-interface

Library to ease connections to Inspector Protocol endpoints.

See https://github.com/cyrus-and/chrome-remote-interface for more information.
Gitpod

Start a Node.js debug configuration from the Debug view or hit F5. Detailed instructions

See https://www.gitpod.io for more information.
Eclipse IDE with Eclipse Wild Web Developer extension

From a .js file, choose "Debug As... > Node program", or
Create a Debug Configuration to attach debugger to running Node.js application (already started with --inspect).

See https://eclipse.org/eclipseide for more information.
Command-line options
The following table lists the impact of various runtime flags on debugging:
FlagMeaning--inspectEnable inspector agent; Listen on default address and port (127.0.0.1:9229)--inspect=[host:port]Enable inspector agent; Bind to address or hostname host (default: 127.0.0.1); Listen on port port (default: 9229)--inspect-brkEnable inspector agent; Listen on default address and port (127.0.0.1:9229); Break before user code starts--inspect-brk=[host:port]Enable inspector agent; Bind to address or hostname host (default: 127.0.0.1); Listen on port port (default: 9229); Break before user code starts--inspect-waitEnable inspector agent; Listen on default address and port (127.0.0.1:9229); Wait for debugger to be attached.--inspect-wait=[host:port]Enable inspector agent; Bind to address or hostname host (default: 127.0.0.1); Listen on port port (default: 9229); Wait for debugger to be attached.node inspect script.jsSpawn child process to run user's script under --inspect flag; and use main process to run CLI debugger.node inspect --port=xxxx script.jsSpawn child process to run user's script under --inspect flag; and use main process to run CLI debugger. Listen on port port (default: 9229)
Enabling remote debugging scenarios
We recommend that you never have the debugger listen on a public IP address. If
you need to allow remote debugging connections we recommend the use of ssh
tunnels instead. We provide the following example for illustrative purposes only.
Please understand the security risk of allowing remote access to a privileged
service before proceeding.
Let's say you are running Node.js on a remote machine, remote.example.com, that
you want to be able to debug. On that machine, you should start the node process
with the inspector listening only to localhost (the default).
node --inspect server.js
ShellCopy to clipboard
Now, on your local machine from where you want to initiate a debug client
connection, you can setup an ssh tunnel:
ssh -L 9221:localhost:9229 [email protected]
ShellCopy to clipboard
This starts a ssh tunnel session where a connection to port 9221 on your local
machine will be forwarded to port 9229 on remote.example.com. You can now attach
a debugger such as Chrome DevTools or Visual Studio Code to localhost:9221,
which should be able to debug as if the Node.js application was running locally.
Legacy Debugger
The legacy debugger has been deprecated as of Node.js 7.7.0. Please use
--inspect and Inspector instead.
When started with the --debug or --debug-brk switches in version 7 and
earlier, Node.js listens for debugging commands defined by the discontinued
V8 Debugging Protocol on a TCP port, by default 5858. Any debugger client
which speaks this protocol can connect to and debug the running process; a
couple popular ones are listed below.
The V8 Debugging Protocol is no longer maintained or documented.
Built-in Debugger
Start node debug script_name.js to start your script under the builtin
command-line debugger. Your script starts in another Node.js process started with
the --debug-brk option, and the initial Node.js process runs the _debugger.js
script and connects to your target. See docs for more information.
node-inspector
Debug your Node.js app with Chrome DevTools by using an intermediary process
which translates the Inspector Protocol used in Chromium to the V8 Debugger
protocol used in Node.js. See https://github.com/node-inspector/node-inspector for more information.PrevNode.js with WebAssemblyNextProfiling Node.js Applications\n\n\n\nProfiling Node.js Applications
Profiling a Node.js application involves measuring its performance by analyzing
the CPU, memory, and other runtime metrics while the application is running.
This helps in identifying bottlenecks, high CPU usage, memory leaks, or slow
function calls that may impact the application's efficiency, responsiveness
and scalability.
There are many third party tools available for profiling Node.js applications
but, in many cases, the easiest option is to use the Node.js built-in profiler.
The built-in profiler uses the profiler inside V8 which samples the stack at
regular intervals during program execution. It records the results of these
samples, along with important optimization events such as jit compiles, as a
series of ticks:
code-creation,LazyCompile,0,0x2d5000a337a0,396,"bp native array.js:1153:16",0x289f644df68,~
code-creation,LazyCompile,0,0x2d5000a33940,716,"hasOwnProperty native v8natives.js:198:30",0x289f64438d0,~
code-creation,LazyCompile,0,0x2d5000a33c20,284,"ToName native runtime.js:549:16",0x289f643bb28,~
code-creation,Stub,2,0x2d5000a33d40,182,"DoubleToIStub"
code-creation,Stub,2,0x2d5000a33e00,507,"NumberToStringStub"

In the past, you needed the V8 source code to be able to interpret the ticks.
Luckily, tools have been introduced since Node.js 4.4.0 that facilitate the
consumption of this information without separately building V8 from source.
Let's see how the built-in profiler can help provide insight into application
performance.
To illustrate the use of the tick profiler, we will work with a simple Express
application. Our application will have two handlers, one for adding new users to
our system:
app.get('/newUser', (req, res) => {
  let username = req.query.username || '';
  const password = req.query.password || '';

  username = username.replace(/[!@#$%^&*]/g, '');

  if (!username || !password || users[username]) {
    return res.sendStatus(400);
  }

  const salt = crypto.randomBytes(128).toString('base64');
  const hash = crypto.pbkdf2Sync(password, salt, 10000, 512, 'sha512');

  users[username] = { salt, hash };

  res.sendStatus(200);
});
JavaScriptCopy to clipboard
and another for validating user authentication attempts:
app.get('/auth', (req, res) => {
  let username = req.query.username || '';
  const password = req.query.password || '';

  username = username.replace(/[!@#$%^&*]/g, '');

  if (!username || !password || !users[username]) {
    return res.sendStatus(400);
  }

  const { salt, hash } = users[username];
  const encryptHash = crypto.pbkdf2Sync(password, salt, 10000, 512, 'sha512');

  if (crypto.timingSafeEqual(hash, encryptHash)) {
    res.sendStatus(200);
  } else {
    res.sendStatus(401);
  }
});
JavaScriptCopy to clipboard
Please note that these are NOT recommended handlers for authenticating users in
your Node.js applications and are used purely for illustration purposes. You
should not be trying to design your own cryptographic authentication mechanisms
in general. It is much better to use existing, proven authentication solutions.
Now assume that we've deployed our application and users are complaining about
high latency on requests. We can easily run the app with the built-in profiler:
NODE_ENV=production node --prof app.js

and put some load on the server using ab (ApacheBench):
curl -X GET "http://localhost:8080/newUser?username=matt&password=password"
ab -k -c 20 -n 250 "http://localhost:8080/auth?username=matt&password=password"

and get an ab output of:
Concurrency Level:      20
Time taken for tests:   46.932 seconds
Complete requests:      250
Failed requests:        0
Keep-Alive requests:    250
Total transferred:      50250 bytes
HTML transferred:       500 bytes
Requests per second:    5.33 [#/sec] (mean)
Time per request:       3754.556 [ms] (mean)
Time per request:       187.728 [ms] (mean, across all concurrent requests)
Transfer rate:          1.05 [Kbytes/sec] received

...

Percentage of the requests served within a certain time (ms)
  50%   3755
  66%   3804
  75%   3818
  80%   3825
  90%   3845
  95%   3858
  98%   3874
  99%   3875
 100%   4225 (longest request)

From this output, we see that we're only managing to serve about 5 requests per
second and that the average request takes just under 4 seconds round trip. In a
real-world example, we could be doing lots of work in many functions on behalf
of a user request but even in our simple example, time could be lost compiling
regular expressions, generating random salts, generating unique hashes from user
passwords, or inside the Express framework itself.
Since we ran our application using the --prof option, a tick file was generated
in the same directory as your local run of the application. It should have the
form isolate-0xnnnnnnnnnnnn-v8.log (where n is a digit).
In order to make sense of this file, we need to use the tick processor bundled
with the Node.js binary. To run the processor, use the --prof-process flag:
node --prof-process isolate-0xnnnnnnnnnnnn-v8.log > processed.txt

Opening processed.txt in your favorite text editor will give you a few different
types of information. The file is broken up into sections which are again broken
up by language. First, we look at the summary section and see:
 [Summary]:
   ticks  total  nonlib   name
     79    0.2%    0.2%  JavaScript
  36703   97.2%   99.2%  C++
      7    0.0%    0.0%  GC
    767    2.0%          Shared libraries
    215    0.6%          Unaccounted

This tells us that 97% of all samples gathered occurred in C++ code and that
when viewing other sections of the processed output we should pay most attention
to work being done in C++ (as opposed to JavaScript). With this in mind, we next
find the [C++] section which contains information about which C++ functions are
taking the most CPU time and see:
 [C++]:
   ticks  total  nonlib   name
  19557   51.8%   52.9%  node::crypto::PBKDF2(v8::FunctionCallbackInfo<v8::Value> const&)
   4510   11.9%   12.2%  _sha1_block_data_order
   3165    8.4%    8.6%  _malloc_zone_malloc

We see that the top 3 entries account for 72.1% of CPU time taken by the
program. From this output, we immediately see that at least 51.8% of CPU time is
taken up by a function called PBKDF2 which corresponds to our hash generation
from a user's password. However, it may not be immediately obvious how the lower
two entries factor into our application (or if it is we will pretend otherwise
for the sake of example). To better understand the relationship between these
functions, we will next look at the [Bottom up (heavy) profile] section which
provides information about the primary callers of each function. Examining this
section, we find:
   ticks parent  name
  19557   51.8%  node::crypto::PBKDF2(v8::FunctionCallbackInfo<v8::Value> const&)
  19557  100.0%    v8::internal::Builtins::~Builtins()
  19557  100.0%      LazyCompile: ~pbkdf2 crypto.js:557:16

   4510   11.9%  _sha1_block_data_order
   4510  100.0%    LazyCompile: *pbkdf2 crypto.js:557:16
   4510  100.0%      LazyCompile: *exports.pbkdf2Sync crypto.js:552:30

   3165    8.4%  _malloc_zone_malloc
   3161   99.9%    LazyCompile: *pbkdf2 crypto.js:557:16
   3161  100.0%      LazyCompile: *exports.pbkdf2Sync crypto.js:552:30

Parsing this section takes a little more work than the raw tick counts above.
Within each of the "call stacks" above, the percentage in the parent column
tells you the percentage of samples for which the function in the row above was
called by the function in the current row. For example, in the middle "call
stack" above for _sha1_block_data_order, we see that _sha1_block_data_order occurred
in 11.9% of samples, which we knew from the raw counts above. However, here, we
can also tell that it was always called by the pbkdf2 function inside the
Node.js crypto module. We see that similarly, _malloc_zone_malloc was called
almost exclusively by the same pbkdf2 function. Thus, using the information in
this view, we can tell that our hash computation from the user's password
accounts not only for the 51.8% from above but also for all CPU time in the top
3 most sampled functions since the calls to _sha1_block_data_order and
_malloc_zone_malloc were made on behalf of the pbkdf2 function.
At this point, it is very clear that the password-based hash generation should
be the target of our optimization. Thankfully, you've fully internalized the
benefits of asynchronous programming and you realize that the work to
generate a hash from the user's password is being done in a synchronous way and
thus tying down the event loop. This prevents us from working on other incoming
requests while computing a hash.
To remedy this issue, you make a small modification to the above handlers to use
the asynchronous version of the pbkdf2 function:
app.get('/auth', (req, res) => {
  let username = req.query.username || '';
  const password = req.query.password || '';

  username = username.replace(/[!@#$%^&*]/g, '');

  if (!username || !password || !users[username]) {
    return res.sendStatus(400);
  }

  crypto.pbkdf2(
    password,
    users[username].salt,
    10000,
    512,
    'sha512',
    (err, hash) => {
      if (users[username].hash.toString() === hash.toString()) {
        res.sendStatus(200);
      } else {
        res.sendStatus(401);
      }
    }
  );
});
JavaScriptCopy to clipboard
A new run of the ab benchmark above with the asynchronous version of your app
yields:
Concurrency Level:      20
Time taken for tests:   12.846 seconds
Complete requests:      250
Failed requests:        0
Keep-Alive requests:    250
Total transferred:      50250 bytes
HTML transferred:       500 bytes
Requests per second:    19.46 [#/sec] (mean)
Time per request:       1027.689 [ms] (mean)
Time per request:       51.384 [ms] (mean, across all concurrent requests)
Transfer rate:          3.82 [Kbytes/sec] received

...

Percentage of the requests served within a certain time (ms)
  50%   1018
  66%   1035
  75%   1041
  80%   1043
  90%   1049
  95%   1063
  98%   1070
  99%   1071
 100%   1079 (longest request)

Yay! Your app is now serving about 20 requests per second, roughly 4 times more
than it was with the synchronous hash generation. Additionally, the average
latency is down from the 4 seconds before to just over 1 second.
Hopefully, through the performance investigation of this (admittedly contrived)
example, you've seen how the V8 tick processor can help you gain a better
understanding of the performance of your Node.js applications.
You may also find how to create a flame graph helpful.PrevDebugging Node.jsNextFetching data with Node.js\n\n\n\nUsing the Fetch API with Undici in Node.js
Introduction
Undici is an HTTP client library that powers the fetch API in Node.js. It was written from scratch and does not rely on the built-in HTTP client in Node.js. It includes a number of features that make it a good choice for high-performance applications.
For information on Undici's specification compliance, see the Undici documentation.
Basic GET Usage
async function main() {
  // Like the browser fetch API, the default method is GET
  const response = await fetch('https://jsonplaceholder.typicode.com/posts');
  const data = await response.json();
  console.log(data);
  // returns something like:
  //   {
  //   userId: 1,
  //   id: 1,
  //   title: 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit',
  //   body: 'quia et suscipit\n' +
  //     'suscipit recusandae consequuntur expedita et cum\n' +
  //     'reprehenderit molestiae ut ut quas totam\n' +
  //     'nostrum rerum est autem sunt rem eveniet architecto'
  // }
}

main().catch(console.error);
JavaScriptCopy to clipboard
Basic POST Usage
// Data sent from the client to the server
const body = {
  title: 'foo',
  body: 'bar',
  userId: 1,
};

async function main() {
  const response = await fetch('https://jsonplaceholder.typicode.com/posts', {
    method: 'POST',
    headers: {
      'User-Agent': 'undici-stream-example',
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(body),
  });
  const data = await response.json();
  console.log(data);
  // returns something like:
  // { title: 'foo', body: 'bar', userId: 1, id: 101 }
}

main().catch(console.error);
JavaScriptCopy to clipboard
Customizing the Fetch API with Undici
Undici allows you to customize the Fetch API by providing options to the fetch function. For example, you can set custom headers, set the request method, and set the request body. Here is an example of how you can customize the Fetch API with Undici:
The fetch function takes two arguments: the URL to fetch and an options object. The options object is the Request object that you can use to customize the request. The function returns a Promises that resolves to a Response object.
In the following example, we are sending a POST request to the Ollama API with a JSON payload. Ollama is a cli tool that allows you to run LLM's (Large Language Models) on your local machine. You can download it here
ollama run mistral
ShellCopy to clipboard
This will download the mistral model and run it on your local machine.
With a pool, you can reuse connections to the same server, which can improve performance. Here is an example of how you can use a pool with Undici:
import { Pool } from 'undici';

const ollamaPool = new Pool('http://localhost:11434', {
  connections: 10,
});

/**
 * Stream the completion of a prompt using the Ollama API.
 * @param {string} prompt - The prompt to complete.
 * @link https://github.com/ollama/ollama/blob/main/docs/api.md
 **/
async function streamOllamaCompletion(prompt) {
  const { statusCode, body } = await ollamaPool.request({
    path: '/api/generate',
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({ prompt, model: 'mistral' }),
  });

  // You can read about HTTP status codes here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status
  // 200 means the request was successful.
  if (statusCode !== 200) {
    throw new Error(`Ollama request failed with status ${statusCode}`);
  }

  let partial = '';

  const decoder = new TextDecoder();
  for await (const chunk of body) {
    partial += decoder.decode(chunk, { stream: true });
    console.log(partial);
  }

  console.log('Streaming complete.');
}

try {
  await streamOllamaCompletion('What is recursion?');
} catch (error) {
  console.error('Error calling Ollama:', error);
} finally {
  console.log('Closing Ollama pool.');
  ollamaPool.close();
}
JavaScriptCopy to clipboard
Streaming Responses with Undici
Streams is a feature in Node.js that allows you to read and write chunks of data.
import { stream } from 'undici';
import { Writable } from 'stream';

async function fetchGitHubRepos() {
  const url = 'https://api.github.com/users/nodejs/repos';

  const { statusCode } = await stream(
    url,
    {
      method: 'GET',
      headers: {
        'User-Agent': 'undici-stream-example',
        Accept: 'application/json',
      },
    },
    () => {
      let buffer = '';

      return new Writable({
        write(chunk, encoding, callback) {
          buffer += chunk.toString();

          try {
            const json = JSON.parse(buffer);
            console.log(
              'Repository Names:',
              json.map(repo => repo.name)
            );
            buffer = '';
          } catch (error) {
            console.error('Error parsing JSON:', error);
          }

          callback();
        },
        final(callback) {
          console.log('Stream processing completed.');
          callback();
        },
      });
    }
  );

  console.log(`Response status: ${statusCode}`);
}

fetchGitHubRepos().catch(console.error);
JavaScriptCopy to clipboardPrevProfiling Node.js ApplicationsNextWebSocket client with Node.js\n\n\n\nNative WebSocket Client in Node.js
Introduction
Since Node.js v21, the WebSocket API has been enhanced using the Undici library, introducing a built-in WebSocket client. This simplifies real-time communication for Node.js applications. In Node.js v22.4.0 release, the WebSocket API was marked as stable, indicating it's ready for production use.
What is a WebSocket
WebSocket is a standardized communication protocol that enables simultaneous two-way communication over a single TCP connection. It has full-duplex or bi-directional capabilities that distinguishes it from HTTP. WebSocket achieves HTTP compatibility by using the HTTP Upgrade header to transition protocols. It allows servers to push content to clients without initial requests and maintains open connections for continuous message exchange, making it ideal for real-time data transfer with lower overhead than alternatives like HTTP polling. WebSocket communications typically occur over TCP ports 443 (secured) or 80 (unsecured), helping bypass firewall restrictions on non-web connections. The protocol defines its own URI schemes (ws:// and wss://) for unencrypted and encrypted connections respectively and supported by all major browsers.
Native WebSocket Client
Node.js can now act as a WebSocket client without relying on external libraries like ws or socket.io for client connections. This allows Node.js applications to initiate and manage outgoing WebSocket connections directly, streamlining tasks such as connecting to real-time data feeds or interacting with other WebSocket servers. Users can now create a websocket client connection with the standard new WebSocket() constructor.
Building on the above, let's add more practical examples to demonstrate the new WebSocket client functionality that demonstrates basic use-cases.
Basic Connection and Message Handling
// Creates a new WebSocket connection to the specified URL.
const socket = new WebSocket('ws://localhost:8080');

// Executes when the connection is successfully established.
socket.addEventListener('open', event => {
  console.log('WebSocket connection established!');
  // Sends a message to the WebSocket server.
  socket.send('Hello Server!');
});

// Listen for messages and executes when a message is received from the server.
socket.addEventListener('message', event => {
  console.log('Message from server: ', event.data);
});

// Executes when the connection is closed, providing the close code and reason.
socket.addEventListener('close', event => {
  console.log('WebSocket connection closed:', event.code, event.reason);
});

// Executes if an error occurs during the WebSocket communication.
socket.addEventListener('error', error => {
  console.error('WebSocket error:', error);
});
JavaScriptCopy to clipboard
Sending and Receiving JSON Data
const socket = new WebSocket('ws://localhost:8080');

socket.addEventListener('open', () => {
  const data = { type: 'message', content: 'Hello from Node.js!' };
  socket.send(JSON.stringify(data));
});

socket.addEventListener('message', event => {
  try {
    const receivedData = JSON.parse(event.data);
    console.log('Received JSON:', receivedData);
  } catch (error) {
    console.error('Error parsing JSON:', error);
    console.log('Received data was:', event.data);
  }
});
JavaScriptCopy to clipboard
The json code above demonstrates sending and receiving JSON data, which is common in WebSocket applications. It uses JSON.stringify() to convert JavaScript objects to JSON strings before sending. And converts the received string back to a JavaScript object with JSON.parse(). Finally, it includes error handling for JSON parsing.
This offers reduced dependency management and improved compatibility. Developers can avoid installing and maintaining additional WebSocket client libraries. The built-in implementation aligns with modern web standards, ensuring better interoperability. The enhancement focuses on the client-side of WebSocket communication, enabling Node.js to act as a WebSocket client.
Important to Understand
Node.js v22 does not provide a built-in native WebSocket server implementation. To create a WebSocket server that accepts incoming connections from web browsers or other clients, one still need to use libraries like ws or socket.io. This means that while Node.js can now easily connect to WebSocket servers, it still requires external tools to become a WebSocket server.
In Summary
Node.js v22 empowers applications to seamlessly interact with WebSocket servers as clients, but the creation of WebSocket servers within Node.js remains dependent on established libraries. This distinction is crucial for developers to understand when implementing real-time communication in their Node.js projects.PrevFetching data with Node.jsNextSecurity Best Practices\n\n\n\nSecurity Best Practices
Intent
This document intends to extend the current threat model and provide extensive
guidelines on how to secure a Node.js application.
Document Content

Best practices: A simplified condensed way to see the best practices. We can
use this issue or this guideline
as the starting point. It is important to note that this document is specific
to Node.js, if you are looking for something broad, consider
OSSF Best Practices.
Attacks explained: illustrate and document in plain English with some code
examples (if possible) of the attacks that we are mentioning in the threat model.
Third-Party Libraries: define threats
(typosquatting attacks, malicious packages...) and best practices regarding
node modules dependencies, etc...

Threat List
Denial of Service of HTTP server (CWE-400)
This is an attack where the application becomes unavailable for the purpose it
was designed due to the way it processes incoming HTTP requests. These requests
need not be deliberately crafted by a malicious actor: a misconfigured or buggy
client can also send a pattern of requests to the server that result in a denial
of service.
HTTP requests are received by the Node.js HTTP server and handed over to the
application code via the registered request handler. The server does not parse
the content of the request body. Therefore any DoS caused by the contents of the
body after they are handed over to the request handler is not a vulnerability in
Node.js itself, since it's the responsibility of the application code to handle
it correctly.
Ensure that the WebServer handles socket errors properly, for instance, when a
server is created without an error handler, it will be vulnerable to DoS
CJSMJSconst net = require('node:net');

const server = net.createServer(function (socket) {
  // socket.on('error', console.error) // this prevents the server to crash
  socket.write('Echo server\r\n');
  socket.pipe(socket);
});

server.listen(5000, '0.0.0.0');
JavaScriptCopy to clipboardIf a bad request is performed the server could crash.
An example of a DoS attack that is not caused by the request's contents is
Slowloris. In this attack, HTTP requests are sent slowly and fragmented,
one fragment at a time. Until the full request is delivered, the server will
keep resources dedicated to the ongoing request. If enough of these requests
are sent at the same time, the amount of concurrent connections will soon reach
its maximum resulting in a denial of service. This is how the attack depends
not on the request's contents but on the timing and pattern of the requests
being sent to the server.
Mitigations

Use a reverse proxy to receive and forward requests to the Node.js application.
Reverse proxies can provide caching, load balancing, IP blacklisting, etc. which
reduce the probability of a DoS attack being effective.
Correctly configure the server timeouts, so that connections that are idle or
where requests are arriving too slowly can be dropped. See the different timeouts
in http.Server, particularly headersTimeout, requestTimeout, timeout,
and keepAliveTimeout.
Limit the number of open sockets per host and in total. See the http docs,
particularly agent.maxSockets, agent.maxTotalSockets, agent.maxFreeSockets
and server.maxRequestsPerSocket.

DNS Rebinding (CWE-346)
This is an attack that can target Node.js applications being run with the
debugging inspector enabled using the --inspect switch.
Since websites opened in a web browser can make WebSocket and HTTP requests,
they can target the debugging inspector running locally.
This is usually prevented by the same-origin policy implemented by modern
browsers, which forbids scripts from reaching resources from different origins
(meaning a malicious website cannot read data requested from a local IP address).
However, through DNS rebinding, an attacker can temporarily control the origin
for their requests so that they seem to originate from a local IP address.
This is done by controlling both a website and the DNS server used to resolve
its IP address. See DNS Rebinding wiki for more details.
Mitigations

Disable inspector on SIGUSR1 signal by attaching a process.on(‘SIGUSR1’, …)
listener to it.
Do not run the inspector protocol in production.

Exposure of Sensitive Information to an Unauthorized Actor (CWE-552)
All the files and folders included in the current directory are pushed to the
npm registry during the package publication.
There are some mechanisms to control this behavior by defining a blocklist with
.npmignore and .gitignore or by defining an allowlist in the package.json
Mitigations

Using npm publish --dry-run to list all the files to publish. Ensure to review the
content before publishing the package.
It’s also important to create and maintain ignore files such as .gitignore and
.npmignore.
Throughout these files, you can specify which files/folders should not be published.
The files property in package.json allows the inverse operation
-- allowed list.
In case of an exposure, make sure to unpublish the package.

HTTP Request Smuggling (CWE-444)
This is an attack that involves two HTTP servers (usually a proxy and a Node.js
application). A client sends an HTTP request that goes first through the
front-end server (the proxy) and then is redirected to the back-end server (the application).
When the front-end and back-end interpret ambiguous HTTP requests differently,
there is potential for an attacker to send a malicious message that won't be
seen by the front-end but will be seen by the back-end, effectively "smuggling"
it past the proxy server.
See the CWE-444 for a more detailed description and examples.
Since this attack depends on Node.js interpreting HTTP requests
differently from an (arbitrary) HTTP server, a successful attack can be due to
a vulnerability in Node.js, the front-end server, or both.
If the way the request is interpreted by Node.js is consistent with the
HTTP specification (see RFC7230), then it is not considered a vulnerability
in Node.js.
Mitigations

Do not use the insecureHTTPParser option when creating a HTTP Server.
Configure the front-end server to normalize ambiguous requests.
Continuously monitor for new HTTP request smuggling vulnerabilities in both
Node.js and the front-end server of choice.
Use HTTP/2 end to end and disable HTTP downgrading if possible.

Information Exposure through Timing Attacks (CWE-208)
This is an attack that allows the attacker to learn potentially sensitive information by, for example, measuring how long
it takes for the application to respond to a request. This attack is not specific to Node.js and can target almost all runtimes.
The attack is possible whenever the application uses a secret in a timing-sensitive operation (e.g., branch). Consider handling authentication in a typical application. Here, a basic authentication method includes email and password as credentials.
User information is retrieved from the input the user has supplied from ideally a
DBMS.
Upon retrieving user information, the password is compared with the user
information retrieved from the database. Using the built-in string comparison takes a longer
time for the same-length values.
This comparison, when run for an acceptable amount unwillingly increases the
response time of the request. By comparing the request response times, an
attacker can guess the length and the value of the password in a large quantity
of requests.
Mitigations


The crypto API exposes a function timingSafeEqual to compare actual and
expected sensitive values using a constant-time algorithm.


For password comparison, you can use the scrypt available also on the
native crypto module.


More generally, avoid using secrets in variable-time operations. This includes branching on secrets and, when the attacker could be co-located on the same infrastructure (e.g., same cloud machine), using a secret as an index into memory. Writing constant-time code in JavaScript is hard (partly because of the JIT). For crypto applications, use the built-in crypto APIs or WebAssembly (for algorithms not implemented in natively).


Malicious Third-Party Modules (CWE-1357)
Currently, in Node.js, any package can access powerful resources such as
network access.
Furthermore, because they also have access to the file system, they can send
any data anywhere.
All code running into a node process has the ability to load and run additional
arbitrary code by using eval()(or its equivalents).
All code with file system write access may achieve the same thing by writing to
new or existing files that are loaded.
Node.js has an experimental¹
policy mechanism to declare the loaded resource as untrusted or trusted.
However, this policy is not enabled by default.
Be sure to pin dependency versions and run automatic checks for vulnerabilities
using common workflows or npm scripts.
Before installing a package make sure that this package is maintained and
includes all the content you expected.
Be careful, the GitHub source code is not always the same as the published one,
validate it in the node_modules.
Supply chain attacks
A supply chain attack on a Node.js application happens when one of its
dependencies (either direct or transitive) are compromised.
This can happen either due to the application being too lax on the specification
of the dependencies (allowing for unwanted updates) and/or common typos in the
specification (vulnerable to typosquatting).
An attacker who takes control of an upstream package can publish a new version
with malicious code in it. If a Node.js application depends on that package
without being strict on which version is safe to use, the package can be
automatically updated to the latest malicious version, compromising the application.
Dependencies specified in the package.json file can have an exact version number
or a range. However, when pinning a dependency to an exact version, its
transitive dependencies are not themselves pinned.
This still leaves the application vulnerable to unwanted/unexpected updates.
Possible attack vectors:

Typosquatting attacks
Lockfile poisoning
Compromised maintainers
Malicious Packages
Dependency Confusions

Mitigations

Prevent npm from executing arbitrary scripts with --ignore-scripts

Additionally, you can disable it globally with npm config set ignore-scripts true


Pin dependency versions to a specific immutable version,
not a version that is a range or from a mutable source.
Use lockfiles, which pin every dependency (direct and transitive).

Use Mitigations for lockfile poisoning.


Automate checks for new vulnerabilities using CI, with tools like npm-audit.

Tools such as Socket can be used to analyze packages with static analysis
to find risky behaviors such as network or filesystem access.


Use npm ci instead of npm install.
This enforces the lockfile so that inconsistencies between it and the
package.json file causes an error (instead of silently ignoring the lockfile
in favor of package.json).
Carefully check the package.json file for errors/typos in the names of the
dependencies.

Memory Access Violation (CWE-284)
Memory-based or heap-based attacks depend on a combination of memory management
errors and an exploitable memory allocator.
Like all runtimes, Node.js is vulnerable to these attacks if your projects run
on a shared machine.
Using a secure heap is useful for preventing sensitive information from leaking
due to pointer overruns and underruns.
Unfortunately, a secure heap is not available on Windows.
More information can be found on Node.js secure-heap documentation.
Mitigations

Use --secure-heap=n depending on your application where n is the allocated
maximum byte size.
Do not run your production app on a shared machine.

Monkey Patching (CWE-349)
Monkey patching refers to the modification of properties in runtime aiming to
change the existing behavior. Example:
// eslint-disable-next-line no-extend-native
Array.prototype.push = function (item) {
  // overriding the global [].push
};
JavaScriptCopy to clipboard
Mitigations
The --frozen-intrinsics flag enables experimental¹
frozen intrinsics, which means all the built-in JavaScript objects and functions
are recursively frozen.
Therefore, the following snippet will not override the default behavior of
Array.prototype.push
// eslint-disable-next-line no-extend-native
Array.prototype.push = function (item) {
  // overriding the global [].push
};

// Uncaught:
// TypeError <Object <Object <[Object: null prototype] {}>>>:
// Cannot assign to read only property 'push' of object ''
JavaScriptCopy to clipboard
However, it’s important to mention you can still define new globals and replace
existing globals using globalThis
> globalThis.foo = 3; foo; // you can still define new globals
3
> globalThis.Array = 4; Array; // However, you can also replace existing globals
4
Shell SessionCopy to clipboard
Therefore, Object.freeze(globalThis) can be used to guarantee no globals will
be replaced.
Prototype Pollution Attacks (CWE-1321)
Prototype pollution refers to the possibility of modifying or injecting properties
into Javascript language items by abusing the usage of __proto_,
_constructor, prototype, and other properties inherited from built-in
prototypes.

const a = { a: 1, b: 2 };
const data = JSON.parse('{"__proto__": { "polluted": true}}');

const c = Object.assign({}, a, data);
console.log(c.polluted); // true

// Potential DoS
const data2 = JSON.parse('{"__proto__": null}');
const d = Object.assign(a, data2);
d.hasOwnProperty('b'); // Uncaught TypeError: d.hasOwnProperty is not a function
JavaScriptCopy to clipboard
This is a potential vulnerability inherited from the JavaScript
language.
Examples:

CVE-2022-21824 (Node.js)
CVE-2018-3721 (3rd Party library: Lodash)

Mitigations

Avoid insecure recursive merges, see CVE-2018-16487.
Implement JSON Schema validations for external/untrusted requests.
Create Objects without prototype by using Object.create(null).
Freezing the prototype: Object.freeze(MyObject.prototype).
Disable the Object.prototype.__proto__ property using --disable-proto flag.
Check that the property exists directly on the object, not from the prototype
using Object.hasOwn(obj, keyFromObj).
Avoid using methods from Object.prototype.

Uncontrolled Search Path Element (CWE-427)
Node.js loads modules following the Module Resolution Algorithm.
Therefore, it assumes the directory in which a module is requested
(require) is trusted.
By that, it means the following application behavior is expected.
Assuming the following directory structure:

app/

server.js
auth.js
auth



If server.js uses require('./auth') it will follow the module resolution
algorithm and load auth instead of auth.js.
Mitigations
Using the experimental¹
policy mechanism with integrity checking can avoid the above threat.
For the directory described above, one can use the following policy.json
{
  "resources": {
    "./app/auth.js": {
      "integrity": "sha256-iuGZ6SFVFpMuHUcJciQTIKpIyaQVigMZlvg9Lx66HV8="
    },
    "./app/server.js": {
      "dependencies": {
        "./auth": "./app/auth.js"
      },
      "integrity": "sha256-NPtLCQ0ntPPWgfVEgX46ryTNpdvTWdQPoZO3kHo0bKI="
    }
  }
}
JSONCopy to clipboard
Therefore, when requiring the auth module, the system will validate the
integrity and throw an error if doesn’t match the expected one.
» node --experimental-policy=policy.json app/server.js
node:internal/policy/sri:65
      throw new ERR_SRI_PARSE(str, str[prevIndex], prevIndex);
      ^

SyntaxError [ERR_SRI_PARSE]: Subresource Integrity string "sha256-iuGZ6SFVFpMuHUcJciQTIKpIyaQVigMZlvg9Lx66HV8=%" had an unexpected "%" at position 51
    at new NodeError (node:internal/errors:393:5)
    at Object.parse (node:internal/policy/sri:65:13)
    at processEntry (node:internal/policy/manifest:581:38)
    at Manifest.assertIntegrity (node:internal/policy/manifest:588:32)
    at Module._compile (node:internal/modules/cjs/loader:1119:21)
    at Module._extensions..js (node:internal/modules/cjs/loader:1213:10)
    at Module.load (node:internal/modules/cjs/loader:1037:32)
    at Module._load (node:internal/modules/cjs/loader:878:12)
    at Module.require (node:internal/modules/cjs/loader:1061:19)
    at require (node:internal/modules/cjs/helpers:99:18) {
  code: 'ERR_SRI_PARSE'
}
Shell SessionCopy to clipboard
Note, it's always recommended the use of --policy-integrity to avoid policy mutations.
Experimental Features in Production
The use of experimental features in production isn't recommended.
Experimental features can suffer breaking changes if needed, and their
functionality isn't securely stable. Although, feedback is highly appreciated.
OpenSSF Tools
The OpenSSF is leading several initiatives that can be very useful, especially if you plan to publish an npm package. These initiatives include:

OpenSSF Scorecard Scorecard evaluates open source projects using a series of automated security risk checks. You can use it to proactively assess vulnerabilities and dependencies in your code base and make informed decisions about accepting vulnerabilities.
OpenSSF Best Practices Badge Program Projects can voluntarily self-certify by describing how they comply with each best practice. This will generate a badge that can be added to the project.
PrevWebSocket client with Node.jsNextIntroduction to TypeScript\n\n\n\nIntroduction to TypeScript
What is TypeScript
TypeScript is an open-source language maintained and developed by Microsoft.
Basically, TypeScript adds additional syntax to JavaScript to support a tighter integration with your editor. Catch errors early in your editor or in your CI/CD pipeline, and write more maintainable code.
We can talk about other TypeScript benefits later, let's see some examples now!
First TypeScript code
Take a look at this code snippet and then we can unpack it together:

type User = {
  name: string;
  age: number;
};

function isAdult(user: User): boolean {
  return user.age >= 18;
}

const justine = {
  name: 'Justine',
  age: 23,
} satisfies User;

const isJustineAnAdult = isAdult(justine);
TypeScriptCopy to clipboard
The first part (with the type keyword) is responsible for declaring our custom object type representing users. Later we utilize this newly created type to create the function isAdult that accepts one argument of type User and returns a boolean. After this, we create justine, our example data that can be used for calling the previously defined function. Finally, we create a new variable with information on whether justine is an adult.
There are additional things about this example that you should know. Firstly, if we do not comply with the declared types, TypeScript will inform us that something is wrong and prevent misuse. Secondly, not everything must be typed explicitly—TypeScript infers types for us. For example, the variable isJustineAnAdult is of type boolean even if we didn't type it explicitly, and justine would be a valid argument for our function even though we didn't declare this variable as of User type.
What does TypeScript consist of?
TypeScript consists of two main components: the code itself and type definitions.
TypeScript Code
The code part is regular JavaScript with additional TypeScript-specific syntax for type annotations. When TypeScript code is compiled, all the TypeScript-specific parts are removed, resulting in clean JavaScript that can run in any environment. For example:
function greet(name: string) {
  console.log(`Hello, ${name}!`);
}
TypeScriptCopy to clipboard
Type Definitions
Type definitions describe the shape of existing JavaScript code. They are usually stored in .d.ts files and don't contain any actual implementation—they only describe the types. These definitions are essential for interoperability with JavaScript: code is not usually distributed as TypeScript, but instead transpiled to JavaScript that includes sidecar type definition files.
For example, when you use Node.js with TypeScript, you'll need type definitions for Node.js APIs. This is available via @types/node. Install it using:
npm add --save-dev @types/node
ShellCopy to clipboard
These type definitions allow TypeScript to understand Node.js APIs and provide proper type checking and autocompletion when you use functions like fs.readFile or http.createServer. For example:
import * as fs from 'fs';

fs.readFile('example.txt', 'foo', (err, data) => {
  //                          ^^^ Argument of type '"foo"' is not assignable to parameter of type …
  if (err) throw err;
  console.log(data);
});
JavaScriptCopy to clipboard
Many popular JavaScript libraries have their type definitions available under the @types namespace, maintained by the DefinitelyTyped community. This enables seamless integration of existing JavaScript libraries with TypeScript projects.
Transform Capabilities
TypeScript also includes powerful transformation capabilities, particularly for JSX (used in React and similar frameworks). The TypeScript compiler can transform JSX syntax into regular JavaScript, similar to how Babel works. While we won't cover these transformation features in these articles, it's worth noting that TypeScript isn't only a tool for type checking—it's also a build tool for transforming modern JavaScript syntax into compatible versions for different environments.
How to run TypeScript code
Okay, so we have some TypeScript code. Now how do we run it?
There are few possible ways to run TypeScript code, we will cover all of them in the next articles.PrevSecurity Best PracticesNextRunning TypeScript Natively\n\n\n\nRunning TypeScript Natively
Since v23.6.0, Node.js enables "type stripping" by default. If you are using v23.6.0 or later and your source code contains only erasable typescript syntax, you do not need this article.
Running TypeScript code with Node.js
Since V22.6.0, Node.js has experimental support for some TypeScript syntax via "type stripping". You can write code that's valid TypeScript directly in Node.js without the need to transpile it first.
The --experimental-strip-types flag tells Node.js to strip the type annotations from the TypeScript code before running it.
node --experimental-strip-types example.ts
ShellCopy to clipboard
And that's it! You can now run TypeScript code directly in Node.js without the need to transpile it first, and use TypeScript to catch type-related errors.
In V22.7.0 this experimental support was extended to transform TypeScript-only syntax, like enums and namespace, with the addition of the --experimental-transform-types flag. Enabling --experimental-transform-types automatically implies that --experimental-strip-types is enabled, so there's no need to use both flags in the same command:
node --experimental-transform-types another-example.ts
ShellCopy to clipboard
From v23.6.0 onwards, type stripping is enabled by default (you can disable it via --no-experimental-strip-types), enabling you to run any supported syntax, so running files like the one below with node file.ts is supported:
function foo(bar: number): string {
  return 'hello';
}
TypeScriptCopy to clipboard
However, running any code that requires transformations, like the code below still needs the use of --experimental-transform-types:
enum MyEnum {
  A,
  B,
}

console.log(MyEnum.A);
TypeScriptCopy to clipboard
Future versions of Node.js will include support for TypeScript without the need for a command line flag.
Limitations
At the time of writing, the experimental support for TypeScript in Node.js has some limitations.
You can get more information on the API docs.
Configuration
The Node.js TypeScript loader (Amaro) does not need or use tsconfig.json to run TypeScript code.
We recommend configuring your editor and tsc to reflect Node.js behavior by creating a tsconfig.json using the compilerOptions listed here, as well as using TypeScript version 5.7 or higher.
Important notes
Thanks to all the contributors who have made this feature possible. We hope that this feature will be stable and available in the LTS version of Node.js soon.
We can understand that this feature is experimental and has some limitations; if that doesn't suit your use-case, please use something else, or contribute a fix. Bug reports are also welcome, please keep in mind the project is run by volunteers, without warranty of any kind, so please be patient if you can't contribute the fix yourself.PrevIntroduction to TypeScriptNextRunning TypeScript with a runner\n\n\n\nRunning TypeScript with a runner
If you want more advanced processing of TypeScript than the built-in support (or you're using Node.js prior to v22.7.0), you have 2 options: use a runner (which handles much of the complexity for you), or handle it all yourself via transpilation.
Running TypeScript code with ts-node
ts-node is a TypeScript execution environment for Node.js. It allows you to run TypeScript code directly in Node.js without the need to compile it first. By default, ts-node performs type checking unless transpileOnly is enabled. While ts-node can catch type errors at runtime, we still recommend type-checking your code first with tsc before shipping it.
To use ts-node, you need to install it first:
npm i -D ts-node
ShellCopy to clipboard
Then you can run your TypeScript code like this:
npx ts-node example.ts
ShellCopy to clipboard
Running TypeScript code with tsx
tsx is another TypeScript execution environment for Node.js. It allows you to run TypeScript code directly in Node.js without the need to compile it first. Note, however, that it does not type check your code. So we recommend to type check your code first with tsc and then run it with tsx before shipping it.
To use tsx, you need to install it first:
npm i -D tsx
ShellCopy to clipboard
Then you can run your TypeScript code like this:
npx tsx example.ts
ShellCopy to clipboard
Registering tsx via node
If you want to use tsx via node, you can register tsx via --import:
node --import=tsx example.ts
ShellCopy to clipboardPrevRunning TypeScript NativelyNextRunning TypeScript code using transpilation\n\n\n\nRunning TypeScript code using transpilation
Transpilation is the process of converting source code from one language to another. In the case of TypeScript, it's the process of converting TypeScript code to JavaScript code. This is necessary because browsers and Node.js don't run TypeScript code directly.
Compiling TypeScript to JavaScript
The most common way to run TypeScript code is to compile it to JavaScript first. You can do this using the TypeScript compiler tsc.
Step 1: Write your TypeScript code in a file, for example example.ts.

type User = {
  name: string;
  age: number;
};

function isAdult(user: User): boolean {
  return user.age >= 18;
}

const justine = {
  name: 'Justine',
  age: 23,
} satisfies User;

const isJustineAnAdult = isAdult(justine);
TypeScriptCopy to clipboard
Step 2: Install TypeScript locally using a package manager:
In this example we're going to use npm, you can check our introduction to the npm package manager for more information.
npm i -D typescript # -D is a shorthand for --save-dev
ShellCopy to clipboard
Step 3: Compile your TypeScript code to JavaScript using the tsc command:
npx tsc example.ts
ShellCopy to clipboard

NOTE: npx is a tool that allows you to run Node.js packages without installing them globally.

tsc is the TypeScript compiler which will take our TypeScript code and compile it to JavaScript.
This command will result in a new file named example.js that we can run using Node.js.
Now when we know how to compile and run TypeScript code let's see TypeScript bug-preventing capabilities in action!
Step 4: Run your JavaScript code using Node.js:
node example.js
ShellCopy to clipboard
You should see the output of your TypeScript code in the terminal
If there are type errors
If you have type errors in your TypeScript code, the TypeScript compiler will catch them and prevent you from running the code. For example, if you change the age property of justine to a string, TypeScript will throw an error:
We will modify our code like this, to voluntarily introduce a type error:
type User = {
  name: string;
  age: number;
};

function isAdult(user: User): boolean {
  return user.age >= 18;
}

const justine: User = {
  name: 'Justine',
  age: 'Secret!',
};

const isJustineAnAdult: string = isAdult(justine, "I shouldn't be here!");
TypeScriptCopy to clipboard
And this is what TypeScript has to say about this:
example.ts:12:5 - error TS2322: Type 'string' is not assignable to type 'number'.

12     age: 'Secret!',
       ~~~

  example.ts:3:5
    3     age: number;
          ~~~
    The expected type comes from property 'age' which is declared here on type 'User'

example.ts:15:7 - error TS2322: Type 'boolean' is not assignable to type 'string'.

15 const isJustineAnAdult: string = isAdult(justine, "I shouldn't be here!");
         ~~~~~~~~~~~~~~~~

example.ts:15:51 - error TS2554: Expected 1 arguments, but got 2.

15 const isJustineAnAdult: string = isAdult(justine, "I shouldn't be here!");
                                                     ~~~~~~~~~~~~~~~~~~~~~~


Found 3 errors in the same file, starting at: example.ts:12
Shell SessionCopy to clipboard
As you can see, TypeScript is very helpful in catching bugs before they even happen. This is one of the reasons why TypeScript is so popular among developers.PrevRunning TypeScript with a runnerNextPublishing a TypeScript package\n\n\n\nPublishing a TypeScript package
This article covers items regarding TypeScript publishing specifically. Publishing means distributed as a package via npm (or other package manager); this is not about compiling an app / server to be run in production (such as a PWA and/or endpoint server).
Some important things to note:


Everything from Publishing a package applies here.


Fields like main operate on published content, so when TypeScript source-code is transpiled to JavaScript, JavaScript is the published content and main would point to a JavaScript file with a JavaScript file extension (ex main.ts → "main": "main.js").


Fields like scripts.test operate on source-code, so they would use the file extensions of the source code (ex "test": "node --test './src/**/*.test.ts').




Node runs TypeScript code via a process called "type stripping", wherein node (via Amaro) removes TypeScript-specific syntax, leaving behind vanilla JavaScript (which node already understands). This behaviour is enabled by default as of node version 23.6.0.

Node does not strip types in node_modules because it can cause significant performance issues for the official TypeScript compiler (tsc) and parts of VS Code, so the TypeScript maintainers would like to discourage people publishing raw TypeScript, at least for now.



Consuming TypeScript-specific features like enum in node still requires a flag (--experimental-transform-types). There are often better alternatives for these anyway.

To ensure TypeScript-specific features are not present (so your code can just run in node), set the erasableSyntaxOnly config option in TypeScript version 5.8+.



Use dependabot to keep your dependencies current, including those in github actions. It's a very easy set-and-forget configuration.


.nvmrc comes from nvm, a multi-version manager for node. It allows you to specify the version of node the project should generally use.


A directory overview of a repository would look something like:
Files co-locatedFiles co-located but segregated'src' and 'test' fully segregatedexample-ts-pkg/
├ .github/
│ ├ workflows/
│ │ ├ ci.yml
│ │ └ publish.yml
│ └ dependabot.yml
├ src/
│ ├ foo.fixture.js
│ ├ main.ts
│ ├ main.test.ts
│ ├ some-util.ts
│ └ some-util.test.ts
├ LICENSE
├ package.json
├ README.md
└ tsconfig.json
textCopy to clipboardAnd a directory overview of its published package would look something like:
Fully flatWith 'dist'example-ts-pkg/
├ LICENSE
├ main.d.ts
├ main.d.ts.map
├ main.js
├ package.json
├ README.md
├ some-util.d.ts
├ some-util.d.ts.map
└ some-util.js
textCopy to clipboardA note about directory organisation: There are a few common practices for placing tests. Principle of least knowledge says to co-locate them (put them adjacent to implementation). Sometimes, that's in the same directory, or within a drawer like a __test__ (also adjacent to the implementation, "Files co-located but segregated"). Alternatively, some opt to create a test/ sibling to src/ ("'src' and 'test' fully segregated"), either with a mirrored structure or a "junk drawer".
What to do with your types
Treat types like a test
The purpose of types is to warn an implementation will not work:
const foo = 'a';
const bar: number = 1 + foo;
//    ^^^ Type 'string' is not assignable to type 'number'.
TypeScriptCopy to clipboard
TypeScript has warned that the above code will not behave as intended, just like a unit test warns that code does not behave as intended. They are complementary and verify different things—you should have both.
Your editor (eg VS Code) likely has built-in support for TypeScript, displaying errors as you work. If not, and/or you missed those, CI will have your back.
The following GitHub Action sets up a CI task to automatically check (and require) types pass inspection for a PR into the main branch.
.github/workflows/ci.ymlpackage.jsontsconfig.json (flat output)tsconfig.json ('dist' output)# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json

name: Tests

on:
  pull_request:
    branches: ['*']

jobs:
  check-types:
    # Separate these from tests because
    # they are platform and node-version independent
    # and need be run only once.

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
      - name: npm clean install
        run: npm ci
      # You may want to run a lint check here too
      - run: node --run types:check

  get-matrix:
    # Automatically pick active LTS versions
    runs-on: ubuntu-latest
    outputs:
      latest: ${{ steps.set-matrix.outputs.requireds }}
    steps:
      - uses: ljharb/actions/node/matrix@main
        id: set-matrix
        with:
          versionsAsRoot: true
          type: majors
          preset: '>= 22' # glob is not backported below 22.x

  test:
    needs: [get-matrix]
    runs-on: ${{ matrix.os }}

    strategy:
      fail-fast: false
      matrix:
        node-version: ${{ fromJson(needs.get-matrix.outputs.latest) }}
        os:
          - macos-latest
          - ubuntu-latest
          - windows-latest

    steps:
      - uses: actions/checkout@v4
      - name: Use node ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      - name: npm clean install
        run: npm ci
      - run: node --run test
YAMLCopy to clipboardNote that test files may well have a different tsconfig.json applied (hence why they are excluded in the above sample).
Generate type declarations
Type declarations (.d.ts and friends) provide type information as a sidecar file, allowing the execution code to be vanilla JavaScript whilst still having types.
Since these are generated based on source code, they can be built as part of your publication process and do not need to be checked into your repository.
Take the following example, where the type declarations are generated just before publishing to the npm registry.
.github/workflows/publish.ymlpackage.json.npmignore.npmignore ('dist' output)# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json

# This is mostly boilerplate.

name: Publish to npm
on:
  push:
    tags:
      - '**@*'

jobs:
  build:
    runs-on: ubuntu-latest

    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'
          registry-url: 'https://registry.npmjs.org'
      - run: npm ci

      # - name: Publish to npm
      #   run: … npm publish …
YAMLCopy to clipboardYou'll want to publish a package compiled to support all Node.js LTS versions since you don't know which version the consumer will be running; the tsconfigs in this article support node 18.x and later.
npm publish will automatically run prepack beforehand. npm will also run prepack automatically before npm pack --dry-run (so you can easily see what your published package will be without actually publishing it). Beware, node --run does not do that. You can't use node --run for this step, so that caveat does not apply here, but it can for other steps.
The steps to actually publish to npm will be included in a separate article (there are several pros and cons beyond the scope of this article).
Breaking this down
Generating type declarations is deterministic: you'll get the same output from the same input, every time. So there is no need to commit these to git.
npm publish grabs everything applicable and available at the moment the command is run; so generating type declarations immediately before means those are available and will get picked up.
By default, npm publish grabs (almost) everything (see Files included in package). In order to keep your published package minimal (see the "Heaviest Objects in the Universe" meme about node_modules), you want to exclude certain files (like tests and test fixtures) from from packaging. Add these to the opt-out list specified in .npmignore; ensure the !*.d.ts exception is listed, or the generated type declartions will not be published! Alternatively, you can use package.json "files" to create an opt-in (if a mistake is made accidentally omitting a file, your package may be broken for downstream users, so this is a less safe option).PrevRunning TypeScript code using transpilationNextAsynchronous flow control\n\n\n\nAsynchronous flow control

The material in this post is heavily inspired by Mixu's Node.js Book.

At its core, JavaScript is designed to be non-blocking on the "main" thread, this is where views are rendered. You can imagine the importance of this in the browser. When the main thread becomes blocked it results in the infamous "freezing" that end users dread, and no other events can be dispatched resulting in the loss of data acquisition, for example.
This creates some unique constraints that only a functional style of programming can cure. This is where callbacks come in to the picture.
However, callbacks can become challenging to handle in more complicated procedures. This often results in "callback hell" where multiple nested functions with callbacks make the code more challenging to read, debug, organize, etc.
async1(function (input, result1) {
  async2(function (result2) {
    async3(function (result3) {
      async4(function (result4) {
        async5(function (output) {
          // do something with output
        });
      });
    });
  });
});
JavaScriptCopy to clipboard
Of course, in real life there would most likely be additional lines of code to handle result1, result2, etc., thus, the length and complexity of this issue usually results in code that looks much more messy than the example above.
This is where functions come in to great use. More complex operations are made up of many functions:

initiator style / input
middleware
terminator

The "initiator style / input" is the first function in the sequence. This function will accept the original input, if any, for the operation. The operation is an executable series of functions, and the original input will primarily be:

variables in a global environment
direct invocation with or without arguments
values obtained by file system or network requests

Network requests can be incoming requests initiated by a foreign network, by another application on the same network, or by the app itself on the same or foreign network.
A middleware function will return another function, and a terminator function will invoke the callback. The following illustrates the flow to network or file system requests. Here the latency is 0 because all these values are available in memory.
function final(someInput, callback) {
  callback(`${someInput} and terminated by executing callback `);
}

function middleware(someInput, callback) {
  return final(`${someInput} touched by middleware `, callback);
}

function initiate() {
  const someInput = 'hello this is a function ';
  middleware(someInput, function (result) {
    console.log(result);
    // requires callback to `return` result
  });
}

initiate();
JavaScriptCopy to clipboard
State management
Functions may or may not be state dependent. State dependency arises when the input or other variable of a function relies on an outside function.
In this way there are two primary strategies for state management:

passing in variables directly to a function, and
acquiring a variable value from a cache, session, file, database, network, or other outside source.

Note, I did not mention global variable. Managing state with global variables is often a sloppy anti-pattern that makes it difficult or impossible to guarantee state. Global variables in complex programs should be avoided when possible.
Control flow
If an object is available in memory, iteration is possible, and there will not be a change to control flow:
function getSong() {
  let _song = '';
  let i = 100;
  for (i; i > 0; i -= 1) {
    _song += `${i} beers on the wall, you take one down and pass it around, ${
      i - 1
    } bottles of beer on the wall\n`;
    if (i === 1) {
      _song += "Hey let's get some more beer";
    }
  }

  return _song;
}

function singSong(_song) {
  if (!_song) throw new Error("song is '' empty, FEED ME A SONG!");
  console.log(_song);
}

const song = getSong();
// this will work
singSong(song);
JavaScriptCopy to clipboard
However, if the data exists outside of memory the iteration will no longer work:
function getSong() {
  let _song = '';
  let i = 100;
  for (i; i > 0; i -= 1) {
    /* eslint-disable no-loop-func */
    setTimeout(function () {
      _song += `${i} beers on the wall, you take one down and pass it around, ${
        i - 1
      } bottles of beer on the wall\n`;
      if (i === 1) {
        _song += "Hey let's get some more beer";
      }
    }, 0);
    /* eslint-enable no-loop-func */
  }

  return _song;
}

function singSong(_song) {
  if (!_song) throw new Error("song is '' empty, FEED ME A SONG!");
  console.log(_song);
}

const song = getSong('beer');
// this will not work
singSong(song);
// Uncaught Error: song is '' empty, FEED ME A SONG!
JavaScriptCopy to clipboard
Why did this happen? setTimeout instructs the CPU to store the instructions elsewhere on the bus, and instructs that the data is scheduled for pickup at a later time. Thousands of CPU cycles pass before the function hits again at the 0 millisecond mark, the CPU fetches the instructions from the bus and executes them. The only problem is that song ('') was returned thousands of cycles prior.
The same situation arises in dealing with file systems and network requests. The main thread simply cannot be blocked for an indeterminate period of time-- therefore, we use callbacks to schedule the execution of code in time in a controlled manner.
You will be able to perform almost all of your operations with the following 3 patterns:

In series: functions will be executed in a strict sequential order, this one is most similar to for loops.

// operations defined elsewhere and ready to execute
const operations = [
  { func: function1, args: args1 },
  { func: function2, args: args2 },
  { func: function3, args: args3 },
];

function executeFunctionWithArgs(operation, callback) {
  // executes function
  const { args, func } = operation;
  func(args, callback);
}

function serialProcedure(operation) {
  if (!operation) process.exit(0); // finished
  executeFunctionWithArgs(operation, function (result) {
    // continue AFTER callback
    serialProcedure(operations.shift());
  });
}

serialProcedure(operations.shift());
JavaScriptCopy to clipboard

Limited in series: functions will be executed in a strict sequential order, but with a limit on the number of executions. Useful when you need to process a large list but with a cap on the number of items successfully processed.

let successCount = 0;

function final() {
  console.log(`dispatched ${successCount} emails`);
  console.log('finished');
}

function dispatch(recipient, callback) {
  // `sendEmail` is a hypothetical SMTP client
  sendMail(
    {
      subject: 'Dinner tonight',
      message: 'We have lots of cabbage on the plate. You coming?',
      smtp: recipient.email,
    },
    callback
  );
}

function sendOneMillionEmailsOnly() {
  getListOfTenMillionGreatEmails(function (err, bigList) {
    if (err) throw err;

    function serial(recipient) {
      if (!recipient || successCount >= 1000000) return final();
      dispatch(recipient, function (_err) {
        if (!_err) successCount += 1;
        serial(bigList.pop());
      });
    }

    serial(bigList.pop());
  });
}

sendOneMillionEmailsOnly();
JavaScriptCopy to clipboard

Full parallel: when ordering is not an issue, such as emailing a list of 1,000,000 email recipients.

let count = 0;
let success = 0;
const failed = [];
const recipients = [
  { name: 'Bart', email: 'bart@tld' },
  { name: 'Marge', email: 'marge@tld' },
  { name: 'Homer', email: 'homer@tld' },
  { name: 'Lisa', email: 'lisa@tld' },
  { name: 'Maggie', email: 'maggie@tld' },
];

function dispatch(recipient, callback) {
  // `sendEmail` is a hypothetical SMTP client
  sendMail(
    {
      subject: 'Dinner tonight',
      message: 'We have lots of cabbage on the plate. You coming?',
      smtp: recipient.email,
    },
    callback
  );
}

function final(result) {
  console.log(`Result: ${result.count} attempts \
      & ${result.success} succeeded emails`);
  if (result.failed.length)
    console.log(`Failed to send to: \
        \n${result.failed.join('\n')}\n`);
}

recipients.forEach(function (recipient) {
  dispatch(recipient, function (err) {
    if (!err) {
      success += 1;
    } else {
      failed.push(recipient.name);
    }
    count += 1;

    if (count === recipients.length) {
      final({
        count,
        success,
        failed,
      });
    }
  });
});
JavaScriptCopy to clipboard
Each has its own use cases, benefits, and issues you can experiment and read about in more detail. Most importantly, remember to modularize your operations and use callbacks! If you feel any doubt, treat everything as if it were middleware!PrevPublishing a TypeScript packageNextOverview of Blocking vs Non-Blocking\n\n\n\nOverview of Blocking vs Non-Blocking
This overview covers the difference between blocking and non-blocking
calls in Node.js. This overview will refer to the event loop and libuv but no
prior knowledge of those topics is required. Readers are assumed to have a
basic understanding of the JavaScript language and Node.js callback pattern.

"I/O" refers primarily to interaction with the system's disk and
network supported by libuv.

Blocking
Blocking is when the execution of additional JavaScript in the Node.js
process must wait until a non-JavaScript operation completes. This happens
because the event loop is unable to continue running JavaScript while a
blocking operation is occurring.
In Node.js, JavaScript that exhibits poor performance due to being CPU intensive
rather than waiting on a non-JavaScript operation, such as I/O, isn't typically
referred to as blocking. Synchronous methods in the Node.js standard library
that use libuv are the most commonly used blocking operations. Native
modules may also have blocking methods.
All of the I/O methods in the Node.js standard library provide asynchronous
versions, which are non-blocking, and accept callback functions. Some
methods also have blocking counterparts, which have names that end with
Sync.
Comparing Code
Blocking methods execute synchronously and non-blocking methods
execute asynchronously.
Using the File System module as an example, this is a synchronous file read:
const fs = require('node:fs');

const data = fs.readFileSync('/file.md'); // blocks here until file is read
JavaScriptCopy to clipboard
And here is an equivalent asynchronous example:
const fs = require('node:fs');

fs.readFile('/file.md', (err, data) => {
  if (err) throw err;
});
JavaScriptCopy to clipboard
The first example appears simpler than the second but has the disadvantage of
the second line blocking the execution of any additional JavaScript until
the entire file is read. Note that in the synchronous version if an error is
thrown it will need to be caught or the process will crash. In the asynchronous
version, it is up to the author to decide whether an error should throw as
shown.
Let's expand our example a little bit:
const fs = require('node:fs');

const data = fs.readFileSync('/file.md'); // blocks here until file is read
console.log(data);
moreWork(); // will run after console.log
JavaScriptCopy to clipboard
And here is a similar, but not equivalent asynchronous example:
const fs = require('node:fs');

fs.readFile('/file.md', (err, data) => {
  if (err) throw err;
  console.log(data);
});
moreWork(); // will run before console.log
JavaScriptCopy to clipboard
In the first example above, console.log will be called before moreWork(). In
the second example fs.readFile() is non-blocking so JavaScript execution
can continue and moreWork() will be called first. The ability to run
moreWork() without waiting for the file read to complete is a key design
choice that allows for higher throughput.
Concurrency and Throughput
JavaScript execution in Node.js is single threaded, so concurrency refers to the
event loop's capacity to execute JavaScript callback functions after completing
other work. Any code that is expected to run in a concurrent manner must allow
the event loop to continue running as non-JavaScript operations, like I/O, are
occurring.
As an example, let's consider a case where each request to a web server takes
50ms to complete and 45ms of that 50ms is database I/O that can be done
asynchronously. Choosing non-blocking asynchronous operations frees up that
45ms per request to handle other requests. This is a significant difference in
capacity just by choosing to use non-blocking methods instead of
blocking methods.
The event loop is different than models in many other languages where additional
threads may be created to handle concurrent work.
Dangers of Mixing Blocking and Non-Blocking Code
There are some patterns that should be avoided when dealing with I/O. Let's look
at an example:
const fs = require('node:fs');

fs.readFile('/file.md', (err, data) => {
  if (err) throw err;
  console.log(data);
});
fs.unlinkSync('/file.md');
JavaScriptCopy to clipboard
In the above example, fs.unlinkSync() is likely to be run before
fs.readFile(), which would delete file.md before it is actually read. A
better way to write this, which is completely non-blocking and guaranteed to
execute in the correct order is:
const fs = require('node:fs');

fs.readFile('/file.md', (readFileErr, data) => {
  if (readFileErr) throw readFileErr;
  console.log(data);
  fs.unlink('/file.md', unlinkErr => {
    if (unlinkErr) throw unlinkErr;
  });
});
JavaScriptCopy to clipboard
The above places a non-blocking call to fs.unlink() within the callback of
fs.readFile() which guarantees the correct order of operations.
Additional Resources

libuv
PrevAsynchronous flow controlNextJavaScript Asynchronous Programming and Callbacks\n\n\n\nJavaScript Asynchronous Programming and Callbacks
Asynchronicity in Programming Languages
Computers are asynchronous by design.
Asynchronous means that things can happen independently of the main program flow.
In the current consumer computers, every program runs for a specific time slot and then it stops its execution to let another program continue their execution. This thing runs in a cycle so fast that it's impossible to notice. We think our computers run many programs simultaneously, but this is an illusion (except on multiprocessor machines).
Programs internally use interrupts, a signal that's emitted to the processor to gain the attention of the system.
Let's not go into the internals of this now, but just keep in mind that it's normal for programs to be asynchronous and halt their execution until they need attention, allowing the computer to execute other things in the meantime. When a program is waiting for a response from the network, it cannot halt the processor until the request finishes.
Normally, programming languages are synchronous and some provide a way to manage asynchronicity in the language or through libraries. C, Java, C#, PHP, Go, Ruby, Swift, and Python are all synchronous by default. Some of them handle async operations by using threads, spawning a new process.
JavaScript
JavaScript is synchronous by default and is single threaded. This means that code cannot create new threads and run in parallel.
Lines of code are executed in series, one after another, for example:
const a = 1;
const b = 2;
const c = a * b;
console.log(c);
doSomething();
JavaScriptCopy to clipboard
But JavaScript was born inside the browser, its main job, in the beginning, was to respond to user actions, like onClick, onMouseOver, onChange, onSubmit and so on. How could it do this with a synchronous programming model?
The answer was in its environment. The browser provides a way to do it by providing a set of APIs that can handle this kind of functionality.
More recently, Node.js introduced a non-blocking I/O environment to extend this concept to file access, network calls and so on.
Callbacks
You can't know when a user is going to click a button. So, you define an event handler for the click event. This event handler accepts a function, which will be called when the event is triggered:
document.getElementById('button').addEventListener('click', () => {
  // item clicked
});
JavaScriptCopy to clipboard
This is the so-called callback.
A callback is a simple function that's passed as a value to another function, and will only be executed when the event happens. We can do this because JavaScript has first-class functions, which can be assigned to variables and passed around to other functions (called higher-order functions)
It's common to wrap all your client code in a load event listener on the window object, which runs the callback function only when the page is ready:
window.addEventListener('load', () => {
  // window loaded
  // do what you want
});
JavaScriptCopy to clipboard
Callbacks are used everywhere, not just in DOM events.
One common example is by using timers:
setTimeout(() => {
  // runs after 2 seconds
}, 2000);
JavaScriptCopy to clipboard
XHR requests also accept a callback, in this example by assigning a function to a property that will be called when a particular event occurs (in this case, the state of the request changes):
const xhr = new XMLHttpRequest();
xhr.onreadystatechange = () => {
  if (xhr.readyState === 4) {
    xhr.status === 200 ? console.log(xhr.responseText) : console.error('error');
  }
};
xhr.open('GET', 'https://yoursite.com');
xhr.send();
JavaScriptCopy to clipboard
Handling errors in callbacks
How do you handle errors with callbacks? One very common strategy is to use what Node.js adopted: the first parameter in any callback function is the error object: error-first callbacks
If there is no error, the object is null. If there is an error, it contains some description of the error and other information.
const fs = require('node:fs');

fs.readFile('/file.json', (err, data) => {
  if (err) {
    // handle error
    console.log(err);
    return;
  }

  // no errors, process data
  console.log(data);
});
JavaScriptCopy to clipboard
The problem with callbacks
Callbacks are great for simple cases!
However every callback adds a level of nesting, and when you have lots of callbacks, the code starts to be complicated very quickly:
window.addEventListener('load', () => {
  document.getElementById('button').addEventListener('click', () => {
    setTimeout(() => {
      items.forEach(item => {
        // your code here
      });
    }, 2000);
  });
});
JavaScriptCopy to clipboard
This is just a simple 4-levels code, but I've seen much more levels of nesting and it's not fun.
How do we solve this?
Alternatives to callbacks
Starting with ES6, JavaScript introduced several features that help us with asynchronous code that do not involve using callbacks: Promises (ES6) and Async/Await (ES2017).PrevOverview of Blocking vs Non-BlockingNextDiscover Promises in Node.js\n\n\n\nDiscover Promises in Node.js
A Promise is a special object in JavaScript that represents the eventual completion (or failure) of an asynchronous operation and its resulting value. Essentially, a Promise is a placeholder for a value that is not yet available but will be in the future.
Think of a Promise like ordering a pizza: you don't get it right away, but the delivery person promises to bring it to you later. You don't know exactly when, but you know the outcome will either be "pizza delivered" or "something went wrong."
Promise States
A Promise can be in one of three states:

Pending: The initial state, where the asynchronous operation is still running.
Fulfilled: The operation completed successfully, and the Promise is now resolved with a value.
Rejected: The operation failed, and the Promise is settled with a reason (usually an error).

When you order the pizza, You're in the pending state, hungry and hopeful. If the pizza arrives hot and cheesy, you've entered the fulfilled state. But if the restaurant calls to say they've dropped your pizza on floor, you're in the rejected state.
Regardless of whether your dinner ends in joy or disappointment, once there's a final outcome, the Promise is considered settled.
Basic Syntax of a Promise
One of the most common ways to create a Promise is using the new Promise() constructor. The constructor takes a function with two parameters: resolve and reject. These functions are used to transition the Promise from the pending state to either fulfilled or rejected.
If an error is thrown inside the executor function, the Promise will be rejected with that error.
The return value of the executor function is ignored: only resolve or reject should be used to settle the Promise.
const myPromise = new Promise((resolve, reject) => {
  let success = true;

  if (success) {
    resolve('Operation was successful!');
  } else {
    reject('Something went wrong.');
  }
});
JavaScriptCopy to clipboard
In the above example:

If the success condition is true, the Promise is fulfilled and the value 'Operation was successful!' is passed to the resolve function.
If the success condition is false, the Promise is rejected and the error 'Something went wrong.' is passed to the reject function.

Handling Promises with .then(), .catch(), and .finally()
Once a Promise is created, you can handle the outcome by using the .then(), .catch(), and .finally() methods.

.then() is used to handle a fulfilled Promise and access its result.
.catch() is used to handle a rejected Promise and catch any errors that may occur.
.finally() is used to handle a settled Promise, regardless of whether the Promise resolved or rejected.

const myPromise = new Promise((resolve, reject) => {
  let success = true;

  if (success) {
    resolve('Operation was successful!');
  } else {
    reject('Something went wrong.');
  }
});

myPromise
  .then(result => {
    console.log(result); // This will run if the Promise is fulfilled
  })
  .catch(error => {
    console.error(error); // This will run if the Promise is rejected
  })
  .finally(() => {
    console.log('The promise has completed'); // This will run when the Promise is settled
  });
JavaScriptCopy to clipboard
Chaining Promises
One of the great features of Promises is that they allow you to chain multiple asynchronous operations together. When you chain Promises, each .then() block waits for the previous one to complete before it runs.
const { setTimeout: delay } = require('node:timers/promises');

const promise = delay(1000).then(() => 'First task completed');

promise
  .then(result => {
    console.log(result); // 'First task completed'
    return delay(1000).then(() => 'Second task completed'); // Return a second Promise
  })
  .then(result => {
    console.log(result); // 'Second task completed'
  })
  .catch(error => {
    console.error(error); // If any Promise is rejected, catch the error
  });
JavaScriptCopy to clipboard
Using Async/Await with Promises
One of the best ways to work with Promises in modern JavaScript is using async/await. This allows you to write asynchronous code that looks synchronous, making it much easier to read and maintain.

async is used to define a function that returns a Promise.
await is used inside an async function to pause execution until a Promise settles.

async function performTasks() {
  try {
    const result1 = await promise1;
    console.log(result1); // 'First task completed'

    const result2 = await promise2;
    console.log(result2); // 'Second task completed'
  } catch (error) {
    console.error(error); // Catches any rejection or error
  }
}

performTasks();
JavaScriptCopy to clipboard
In the performTasks function, the await keyword ensures that each Promise is settled before moving on to the next statement. This leads to a more linear and readable flow of asynchronous code.
Essentially, the code above will execute the same as if the user wrote:
promise1
  .then(function (result1) {
    console.log(result1);
    return promise2;
  })
  .then(function (result2) {
    console.log(result2);
  })
  .catch(function (error) {
    console.log(error);
  });
JavaScriptCopy to clipboard
Top-Level Await
When using ECMAScript Modules, the module itself is treated as a top-level scope that supports asynchronous operations natively. This means that you can use await at the top level without needing an async function.
import { setTimeout as delay } from 'node:timers/promises';

await delay(1000);
JavaScriptCopy to clipboard
Async/await can be much more intricate than the simple examples provided. James Snell, a member of the Node.js Technical Steering Committee, has an in-depth presentation that explores the complexities of Promises and async/await.
Promise-based Node.js APIs
Node.js provides Promise-based versions of many of its core APIs, especially in cases where asynchronous operations were traditionally handled with callbacks. This makes it easier to work with Node.js APIs and Promises, and reduces the risk of "callback hell."
For example, the fs (file system) module has a Promise-based API under fs.promises:
const fs = require('node:fs').promises;
// Or, you can import the promisified version directly:
// const fs = require('node:fs/promises');

async function readFile() {
  try {
    const data = await fs.readFile('example.txt', 'utf8');
    console.log(data);
  } catch (err) {
    console.error('Error reading file:', err);
  }
}

readFile();
JavaScriptCopy to clipboard
In this example, fs.promises.readFile() returns a Promise, which we handle using async/await syntax to read the contents of a file asynchronously.
Advanced Promise Methods
JavaScript's Promise global provides several powerful methods that help manage multiple asynchronous tasks more effectively:
Promise.all()
This method accepts an array of Promises and returns a new Promise that resolves once all the Promises are fulfilled. If any Promise is rejected, Promise.all() will immediately reject. However, even if rejection occurs, the Promises continue to execute. When handling a large number of Promises, especially in batch processing, using this function can strain the system's memory.
const { setTimeout: delay } = require('node:timers/promises');

const fetchData1 = delay(1000).then(() => 'Data from API 1');
const fetchData2 = delay(2000).then(() => 'Data from API 2');

Promise.all([fetchData1, fetchData2])
  .then(results => {
    console.log(results); // ['Data from API 1', 'Data from API 2']
  })
  .catch(error => {
    console.error('Error:', error);
  });
JavaScriptCopy to clipboard
Promise.allSettled()
This method waits for all promises to either resolve or reject and returns an array of objects that describe the outcome of each Promise.
const promise1 = Promise.resolve('Success');
const promise2 = Promise.reject('Failed');

Promise.allSettled([promise1, promise2]).then(results => {
  console.log(results);
  // [ { status: 'fulfilled', value: 'Success' }, { status: 'rejected', reason: 'Failed' } ]
});
JavaScriptCopy to clipboard
Unlike Promise.all(), Promise.allSettled() does not short-circuit on failure. It waits for all promises to settle, even if some reject. This provides better error handling for batch operations, where you may want to know the status of all tasks, regardless of failure.
Promise.race()
This method resolves or rejects as soon as the first Promise settles, whether it resolves or rejects. Regardless of which promise settles first, all promises are fully executed.
const { setTimeout: delay } = require('node:timers/promises');

const task1 = delay(2000).then(() => 'Task 1 done');
const task2 = delay(1000).then(() => 'Task 2 done');

Promise.race([task1, task2]).then(result => {
  console.log(result); // 'Task 2 done' (since task2 finishes first)
});
JavaScriptCopy to clipboard
Promise.any()
This method resolves as soon as one of the Promises resolves. If all promises are rejected, it will reject with an AggregateError.
const { setTimeout: delay } = require('node:timers/promises');

const api1 = delay(2000).then(() => 'API 1 success');
const api2 = delay(1000).then(() => 'API 2 success');
const api3 = delay(1500).then(() => 'API 3 success');

Promise.any([api1, api2, api3])
  .then(result => {
    console.log(result); // 'API 2 success' (since it resolves first)
  })
  .catch(error => {
    console.error('All promises rejected:', error);
  });
JavaScriptCopy to clipboard
Promise.reject() and Promise.resolve()
These methods create a rejected or resolved Promise directly.
Promise.resolve('Resolved immediately').then(result => {
  console.log(result); // 'Resolved immediately'
});
JavaScriptCopy to clipboard
Promise.try()
Promise.try() is a method that executes a given function, whether it's synchronous or asynchronous, and wraps the result in a promise. If the function throws an error or returns a rejected promise, Promise.try() will return a rejected promise. If the function completes successfully, the returned promise will be fulfilled with its value.
This can be particularly useful for starting promise chains in a consistent way, especially when working with code that might throw errors synchronously.
function mightThrow() {
  if (Math.random() > 0.5) {
    throw new Error('Oops, something went wrong!');
  }
  return 'Success!';
}

Promise.try(mightThrow)
  .then(result => {
    console.log('Result:', result);
  })
  .catch(err => {
    console.error('Caught error:', err.message);
  });
JavaScriptCopy to clipboard
In this example, Promise.try() ensures that if mightThrow() throws an error, it will be caught in the .catch() block, making it easier to handle both sync and async errors in one place.
Promise.withResolvers()
This method creates a new promise along with its associated resolve and reject functions, and returns them in a convenient object. This is used, for example, when you need to create a promise but resolve or reject it later from outside the executor function.
const { promise, resolve, reject } = Promise.withResolvers();

setTimeout(() => {
  resolve('Resolved successfully!');
}, 1000);

promise.then(value => {
  console.log('Success:', value);
});
JavaScriptCopy to clipboard
In this example, Promise.withResolvers() gives you full control over when and how the promise is resolved or rejected, without needing to define the executor function inline. This pattern is commonly used in event-driven programming, timeouts, or when integrating with non-promise-based APIs.
Error Handling with Promises
Handling errors in Promises ensures your application behaves correctly in case of unexpected situations.

You can use .catch() to handle any errors or rejections that occur during the execution of Promises.

myPromise
  .then(result => console.log(result))
  .catch(error => console.error(error)) // Handles the rejection
  .finally(error => console.log('Promise completed')); // Runs regardless of promise resolution
JavaScriptCopy to clipboard

Alternatively, when using async/await, you can use a try/catch block to catch and handle errors.

async function performTask() {
  try {
    const result = await myPromise;
    console.log(result);
  } catch (error) {
    console.error(error); // Handles any errors
  } finally {
    // This code is executed regardless of failure
    console.log('performTask() completed');
  }
}

performTask();
JavaScriptCopy to clipboard
Scheduling Tasks in the Event Loop
In addition to Promises, Node.js provides several other mechanisms for scheduling tasks in the event loop.
queueMicrotask()
queueMicrotask() is used to schedule a microtask, which is a lightweight task that runs after the currently executing script but before any other I/O events or timers. Microtasks include tasks like Promise resolutions and other asynchronous operations that are prioritized over regular tasks.
queueMicrotask(() => {
  console.log('Microtask is executed');
});

console.log('Synchronous task is executed');
JavaScriptCopy to clipboard
In the above example, "Microtask is executed" will be logged after "Synchronous task is executed," but before any I/O operations like timers.
process.nextTick()
process.nextTick() is used to schedule a callback to be executed immediately after the current operation completes. This is useful for situations where you want to ensure that a callback is executed as soon as possible, but still after the current execution context.
process.nextTick(() => {
  console.log('Next tick callback');
});

console.log('Synchronous task executed');
JavaScriptCopy to clipboard
setImmediate()
setImmediate() is used to execute a callback after the current event loop cycle finishes and all I/O events have been processed. This means that setImmediate() callbacks run after any I/O callbacks, but before timers.
setImmediate(() => {
  console.log('Immediate callback');
});

console.log('Synchronous task executed');
JavaScriptCopy to clipboard
When to Use Each

Use queueMicrotask() for tasks that need to run immediately after the current script and before any I/O or timer callbacks, typically for Promise resolutions.
Use process.nextTick() for tasks that should execute before any I/O events, often useful for deferring operations or handling errors synchronously.
Use setImmediate() for tasks that should run after I/O events but before timers.

Because these tasks execute outside of the current synchronous flow, uncaught exceptions inside these callbacks won't be caught by surrounding try/catch blocks and may crash the application if not properly managed (e.g., by attaching .catch() to Promises or using global error handlers like process.on('uncaughtException')).
For more information on the Event Loop, and the execution order of various phases, please see the related article, The Node.js Event Loop.PrevJavaScript Asynchronous Programming and CallbacksNextDiscover JavaScript Timers\n\n\n\nDiscover JavaScript Timers
setTimeout()
When writing JavaScript code, you might want to delay the execution of a function.
This is the job of setTimeout. You specify a callback function to execute later, and a value expressing how later you want it to run, in milliseconds:
setTimeout(() => {
  // runs after 2 seconds
}, 2000);

setTimeout(() => {
  // runs after 50 milliseconds
}, 50);
JavaScriptCopy to clipboard
This syntax defines a new function. You can call whatever other function you want in there, or you can pass an existing function name, and a set of parameters:
const myFunction = (firstParam, secondParam) => {
  // do something
};

// runs after 2 seconds
setTimeout(myFunction, 2000, firstParam, secondParam);
JavaScriptCopy to clipboard
setTimeout returns the timer id. This is generally not used, but you can store this id, and clear it if you want to delete this scheduled function execution:
const id = setTimeout(() => {
  // should run after 2 seconds
}, 2000);

// I changed my mind
clearTimeout(id);
JavaScriptCopy to clipboard
Zero delay
If you specify the timeout delay to 0, the callback function will be executed as soon as possible, but after the current function execution:
setTimeout(() => {
  console.log('after ');
}, 0);

console.log(' before ');
JavaScriptCopy to clipboard
This code will print
before
after
ShellCopy to clipboard
This is especially useful to avoid blocking the CPU on intensive tasks and let other functions be executed while performing a heavy calculation, by queuing functions in the scheduler.

Some browsers (IE and Edge) implement a setImmediate() method that does this same exact functionality, but it's not standard and unavailable on other browsers. But it's a standard function in Node.js.

setInterval()
setInterval is a function similar to setTimeout, with a difference: instead of running the callback function once, it will run it forever, at the specific time interval you specify (in milliseconds):
setInterval(() => {
  // runs every 2 seconds
}, 2000);
JavaScriptCopy to clipboard
The function above runs every 2 seconds unless you tell it to stop, using clearInterval, passing it the interval id that setInterval returned:
const id = setInterval(() => {
  // runs every 2 seconds
}, 2000);

clearInterval(id);
JavaScriptCopy to clipboard
It's common to call clearInterval inside the setInterval callback function, to let it auto-determine if it should run again or stop. For example this code runs something unless App.somethingIWait has the value arrived:
const interval = setInterval(() => {
  if (App.somethingIWait === 'arrived') {
    clearInterval(interval);
  }
  // otherwise do things
}, 100);
JavaScriptCopy to clipboard
Recursive setTimeout
setInterval starts a function every n milliseconds, without any consideration about when a function finished its execution.
If a function always takes the same amount of time, it's all fine:

Maybe the function takes different execution times, depending on network conditions for example:

And maybe one long execution overlaps the next one:

To avoid this, you can schedule a recursive setTimeout to be called when the callback function finishes:
const myFunction = () => {
  // do something

  setTimeout(myFunction, 1000);
};

setTimeout(myFunction, 1000);
JavaScriptCopy to clipboard
to achieve this scenario:

setTimeout and setInterval are available in Node.js, through the Timers module.
Node.js also provides setImmediate(), which is equivalent to using setTimeout(() => {}, 0), mostly used to work with the Node.js Event Loop.PrevDiscover Promises in Node.jsNextThe Node.js Event Loop\n\n\n\nThe Node.js Event Loop
What is the Event Loop?
The event loop is what allows Node.js to perform non-blocking I/O
operations — despite the fact that a single JavaScript thread is used by default — by
offloading operations to the system kernel whenever possible.
Since most modern kernels are multi-threaded, they can handle multiple
operations executing in the background. When one of these operations
completes, the kernel tells Node.js so that the appropriate callback
may be added to the poll queue to eventually be executed. We'll explain
this in further detail later in this topic.
Event Loop Explained
When Node.js starts, it initializes the event loop, processes the
provided input script (or drops into the REPL, which is not covered in
this document) which may make async API calls, schedule timers, or call
process.nextTick(), then begins processing the event loop.
The following diagram shows a simplified overview of the event loop's
order of operations.
   ┌───────────────────────────┐
┌─>│           timers          │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │     pending callbacks     │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │       idle, prepare       │
│  └─────────────┬─────────────┘      ┌───────────────┐
│  ┌─────────────┴─────────────┐      │   incoming:   │
│  │           poll            │<─────┤  connections, │
│  └─────────────┬─────────────┘      │   data, etc.  │
│  ┌─────────────┴─────────────┐      └───────────────┘
│  │           check           │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
└──┤      close callbacks      │
   └───────────────────────────┘


Each box will be referred to as a "phase" of the event loop.

Each phase has a FIFO queue of callbacks to execute. While each phase is
special in its own way, generally, when the event loop enters a given
phase, it will perform any operations specific to that phase, then
execute callbacks in that phase's queue until the queue has been
exhausted or the maximum number of callbacks has executed. When the
queue has been exhausted or the callback limit is reached, the event
loop will move to the next phase, and so on.
Since any of these operations may schedule more operations and new
events processed in the poll phase are queued by the kernel, poll
events can be queued while polling events are being processed. As a
result, long running callbacks can allow the poll phase to run much
longer than a timer's threshold. See the timers and
poll sections for more details.

There is a slight discrepancy between the Windows and the
Unix/Linux implementation, but that's not important for this
demonstration. The most important parts are here. There are actually
seven or eight steps, but the ones we care about — ones that Node.js
actually uses - are those above.

Phases Overview

timers: this phase executes callbacks scheduled by setTimeout()
and setInterval().
pending callbacks: executes I/O callbacks deferred to the next loop
iteration.
idle, prepare: only used internally.
poll: retrieve new I/O events; execute I/O related callbacks (almost
all with the exception of close callbacks, the ones scheduled by timers,
and setImmediate()); node will block here when appropriate.
check: setImmediate() callbacks are invoked here.
close callbacks: some close callbacks, e.g. socket.on('close', ...).

Between each run of the event loop, Node.js checks if it is waiting for
any asynchronous I/O or timers and shuts down cleanly if there are not
any.
Phases in Detail
timers
A timer specifies the threshold after which a provided callback
may be executed rather than the exact time a person wants it to
be executed. Timers callbacks will run as early as they can be
scheduled after the specified amount of time has passed; however,
Operating System scheduling or the running of other callbacks may delay
them.

Technically, the poll phase controls when timers are executed.

For example, say you schedule a timeout to execute after a 100 ms
threshold, then your script starts asynchronously reading a file which
takes 95 ms:
const fs = require('node:fs');

function someAsyncOperation(callback) {
  // Assume this takes 95ms to complete
  fs.readFile('/path/to/file', callback);
}

const timeoutScheduled = Date.now();

setTimeout(() => {
  const delay = Date.now() - timeoutScheduled;

  console.log(`${delay}ms have passed since I was scheduled`);
}, 100);

// do someAsyncOperation which takes 95 ms to complete
someAsyncOperation(() => {
  const startCallback = Date.now();

  // do something that will take 10ms...
  while (Date.now() - startCallback < 10) {
    // do nothing
  }
});
JavaScriptCopy to clipboard
When the event loop enters the poll phase, it has an empty queue
(fs.readFile() has not completed), so it will wait for the number of ms
remaining until the soonest timer's threshold is reached. While it is
waiting 95 ms pass, fs.readFile() finishes reading the file and its
callback which takes 10 ms to complete is added to the poll queue and
executed. When the callback finishes, there are no more callbacks in the
queue, so the event loop will see that the threshold of the soonest
timer has been reached then wrap back to the timers phase to execute
the timer's callback. In this example, you will see that the total delay
between the timer being scheduled and its callback being executed will
be 105ms.

To prevent the poll phase from starving the event loop, libuv
(the C library that implements the Node.js
event loop and all of the asynchronous behaviors of the platform)
also has a hard maximum (system dependent) before it stops polling for
more events.

pending callbacks
This phase executes callbacks for some system operations such as types
of TCP errors. For example if a TCP socket receives ECONNREFUSED when
attempting to connect, some *nix systems want to wait to report the
error. This will be queued to execute in the pending callbacks phase.
poll
The poll phase has two main functions:

Calculating how long it should block and poll for I/O, then
Processing events in the poll queue.

When the event loop enters the poll phase and there are no timers
scheduled, one of two things will happen:


If the poll queue is not empty, the event loop will iterate
through its queue of callbacks executing them synchronously until
either the queue has been exhausted, or the system-dependent hard limit
is reached.


If the poll queue is empty, one of two more things will
happen:


If scripts have been scheduled by setImmediate(), the event loop
will end the poll phase and continue to the check phase to
execute those scheduled scripts.


If scripts have not been scheduled by setImmediate(), the
event loop will wait for callbacks to be added to the queue, then
execute them immediately.




Once the poll queue is empty the event loop will check for timers
whose time thresholds have been reached. If one or more timers are
ready, the event loop will wrap back to the timers phase to execute
those timers' callbacks.
check
This phase allows the event loop to execute callbacks immediately after the
poll phase has completed. If the poll phase becomes idle and
scripts have been queued with setImmediate(), the event loop may
continue to the check phase rather than waiting.
setImmediate() is actually a special timer that runs in a separate
phase of the event loop. It uses a libuv API that schedules callbacks to
execute after the poll phase has completed.
Generally, as the code is executed, the event loop will eventually hit
the poll phase where it will wait for an incoming connection, request,
etc. However, if a callback has been scheduled with setImmediate()
and the poll phase becomes idle, it will end and continue to the
check phase rather than waiting for poll events.
close callbacks
If a socket or handle is closed abruptly (e.g. socket.destroy()), the
'close' event will be emitted in this phase. Otherwise it will be
emitted via process.nextTick().
setImmediate() vs setTimeout()
setImmediate() and setTimeout() are similar, but behave in different
ways depending on when they are called.

setImmediate() is designed to execute a script once the
current poll phase completes.
setTimeout() schedules a script to be run after a minimum threshold
in ms has elapsed.

The order in which the timers are executed will vary depending on the
context in which they are called. If both are called from within the
main module, then timing will be bound by the performance of the process
(which can be impacted by other applications running on the machine).
For example, if we run the following script which is not within an I/O
cycle (i.e. the main module), the order in which the two timers are
executed is non-deterministic, as it is bound by the performance of the
process:
JSBASH// timeout_vs_immediate.js
setTimeout(() => {
  console.log('timeout');
}, 0);

setImmediate(() => {
  console.log('immediate');
});
JavaScriptCopy to clipboardHowever, if you move the two calls within an I/O cycle, the immediate
callback is always executed first:
JSBASH// timeout_vs_immediate.js
const fs = require('node:fs');

fs.readFile(__filename, () => {
  setTimeout(() => {
    console.log('timeout');
  }, 0);
  setImmediate(() => {
    console.log('immediate');
  });
});
JavaScriptCopy to clipboardThe main advantage to using setImmediate() over setTimeout() is
setImmediate() will always be executed before any timers if scheduled
within an I/O cycle, independently of how many timers are present.
process.nextTick()
Understanding process.nextTick()
You may have noticed that process.nextTick() was not displayed in the
diagram, even though it's a part of the asynchronous API. This is because
process.nextTick() is not technically part of the event loop. Instead,
the nextTickQueue will be processed after the current operation is
completed, regardless of the current phase of the event loop. Here,
an operation is defined as a transition from the
underlying C/C++ handler, and handling the JavaScript that needs to be
executed.
Looking back at our diagram, any time you call process.nextTick() in a
given phase, all callbacks passed to process.nextTick() will be
resolved before the event loop continues. This can create some bad
situations because it allows you to "starve" your I/O by making
recursive process.nextTick() calls, which prevents the event loop
from reaching the poll phase.
Why would that be allowed?
Why would something like this be included in Node.js? Part of it is a
design philosophy where an API should always be asynchronous even where
it doesn't have to be. Take this code snippet for example:
function apiCall(arg, callback) {
  if (typeof arg !== 'string')
    return process.nextTick(
      callback,
      new TypeError('argument should be string')
    );
}
JavaScriptCopy to clipboard
The snippet does an argument check and if it's not correct, it will pass
the error to the callback. The API updated fairly recently to allow
passing arguments to process.nextTick() allowing it to take any
arguments passed after the callback to be propagated as the arguments to
the callback so you don't have to nest functions.
What we're doing is passing an error back to the user but only after
we have allowed the rest of the user's code to execute. By using
process.nextTick() we guarantee that apiCall() always runs its
callback after the rest of the user's code and before the event loop
is allowed to proceed. To achieve this, the JS call stack is allowed to
unwind then immediately execute the provided callback which allows a
person to make recursive calls to process.nextTick() without reaching a
RangeError: Maximum call stack size exceeded from v8.
This philosophy can lead to some potentially problematic situations.
Take this snippet for example:
let bar;

// this has an asynchronous signature, but calls callback synchronously
function someAsyncApiCall(callback) {
  callback();
}

// the callback is called before `someAsyncApiCall` completes.
someAsyncApiCall(() => {
  // since someAsyncApiCall hasn't completed, bar hasn't been assigned any value
  console.log('bar', bar); // undefined
});

bar = 1;
JavaScriptCopy to clipboard
The user defines someAsyncApiCall() to have an asynchronous signature,
but it actually operates synchronously. When it is called, the callback
provided to someAsyncApiCall() is called in the same phase of the
event loop because someAsyncApiCall() doesn't actually do anything
asynchronously. As a result, the callback tries to reference bar even
though it may not have that variable in scope yet, because the script has not
been able to run to completion.
By placing the callback in a process.nextTick(), the script still has the
ability to run to completion, allowing all the variables, functions,
etc., to be initialized prior to the callback being called. It also has
the advantage of not allowing the event loop to continue. It may be
useful for the user to be alerted to an error before the event loop is
allowed to continue. Here is the previous example using process.nextTick():
let bar;

function someAsyncApiCall(callback) {
  process.nextTick(callback);
}

someAsyncApiCall(() => {
  console.log('bar', bar); // 1
});

bar = 1;
JavaScriptCopy to clipboard
Here's another real world example:
const server = net.createServer(() => {}).listen(8080);

server.on('listening', () => {});
JavaScriptCopy to clipboard
When only a port is passed, the port is bound immediately. So, the
'listening' callback could be called immediately. The problem is that the
.on('listening') callback will not have been set by that time.
To get around this, the 'listening' event is queued in a nextTick()
to allow the script to run to completion. This allows the user to set
any event handlers they want.
process.nextTick() vs setImmediate()
We have two calls that are similar as far as users are concerned, but
their names are confusing.

process.nextTick() fires immediately on the same phase
setImmediate() fires on the following iteration or 'tick' of the
event loop

In essence, the names should be swapped. process.nextTick() fires more
immediately than setImmediate(), but this is an artifact of the past
which is unlikely to change. Making this switch would break a large
percentage of the packages on npm. Every day more new modules are being
added, which means every day we wait, more potential breakages occur.
While they are confusing, the names themselves won't change.

We recommend developers use setImmediate() in all cases because it's
easier to reason about.

Why use process.nextTick()?
There are two main reasons:


Allow users to handle errors, cleanup any then unneeded resources, or
perhaps try the request again before the event loop continues.


At times it's necessary to allow a callback to run after the call
stack has unwound but before the event loop continues.


One example is to match the user's expectations. Simple example:
const server = net.createServer();
server.on('connection', conn => {});

server.listen(8080);
server.on('listening', () => {});
JavaScriptCopy to clipboard
Say that listen() is run at the beginning of the event loop, but the
listening callback is placed in a setImmediate(). Unless a
hostname is passed, binding to the port will happen immediately. For
the event loop to proceed, it must hit the poll phase, which means
there is a non-zero chance that a connection could have been received
allowing the connection event to be fired before the listening event.
Another example is extending an EventEmitter and emitting an
event from within the constructor:
const EventEmitter = require('node:events');

class MyEmitter extends EventEmitter {
  constructor() {
    super();
    this.emit('event');
  }
}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
JavaScriptCopy to clipboard
You can't emit an event from the constructor immediately
because the script will not have processed to the point where the user
assigns a callback to that event. So, within the constructor itself,
you can use process.nextTick() to set a callback to emit the event
after the constructor has finished, which provides the expected results:
const EventEmitter = require('node:events');

class MyEmitter extends EventEmitter {
  constructor() {
    super();

    // use nextTick to emit the event once a handler is assigned
    process.nextTick(() => {
      this.emit('event');
    });
  }
}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
JavaScriptCopy to clipboardPrevDiscover JavaScript TimersNextThe Node.js Event Emitter\n\n\n\nThe Node.js Event emitter
If you worked with JavaScript in the browser, you know how much of the interaction of the user is handled through events: mouse clicks, keyboard button presses, reacting to mouse movements, and so on.
On the backend side, Node.js offers us the option to build a similar system using the events module.
This module, in particular, offers the EventEmitter class, which we'll use to handle our events.
You initialize that using
CJSMJSconst EventEmitter = require('node:events');

const eventEmitter = new EventEmitter();
JavaScriptCopy to clipboardThis object exposes, among many others, the on and emit methods.

emit is used to trigger an event
on is used to add a callback function that's going to be executed when the event is triggered

For example, let's create a start event, and as a matter of providing a sample, we react to that by just logging to the console:
eventEmitter.on('start', () => {
  console.log('started');
});
JavaScriptCopy to clipboard
When we run
eventEmitter.emit('start');
JavaScriptCopy to clipboard
the event handler function is triggered, and we get the console log.
You can pass arguments to the event handler by passing them as additional arguments to emit():
eventEmitter.on('start', number => {
  console.log(`started ${number}`);
});

eventEmitter.emit('start', 23);
JavaScriptCopy to clipboard
Multiple arguments:
eventEmitter.on('start', (start, end) => {
  console.log(`started from ${start} to ${end}`);
});

eventEmitter.emit('start', 1, 100);
JavaScriptCopy to clipboard
The EventEmitter object also exposes several other methods to interact with events, like

once(): add a one-time listener
removeListener() / off(): remove an event listener from an event
removeAllListeners(): remove all listeners for an event

You can read more about these methods in the official documentation.PrevThe Node.js Event LoopNextUnderstanding process.nextTick()\n\n\n\nUnderstanding process.nextTick()
As you try to understand the Node.js event loop, one important part of it is process.nextTick().
Every time the runtime calls back into JavaScript for an event, we call it a tick.
When we pass a function to process.nextTick(), we instruct the engine to invoke this function immediately after the current operation completes, before moving to the next phase in the event loop:
process.nextTick(() => {
  // do something
});
JavaScriptCopy to clipboard
The event loop is busy processing the current function code. When this operation ends, the JS engine runs all the functions passed to nextTick calls during that operation.
It's the way we can tell the JS engine to process a function asynchronously (after the current function), but as soon as possible, not queue it.
Calling setTimeout(() => {}, 0) will execute the function at the end of next tick, much later than when using nextTick() which prioritizes the call and executes it just before the beginning of the next tick.
Use nextTick() when you want to make sure that in the next event loop iteration that code is already executed.
An Example of the order of events:
console.log('Hello => number 1');

setImmediate(() => {
  console.log('Running before the timeout => number 3');
});

setTimeout(() => {
  console.log('The timeout running last => number 4');
}, 0);

process.nextTick(() => {
  console.log('Running at next tick => number 2');
});
JavaScriptCopy to clipboard
Example output:
Hello => number 1
Running at next tick => number 2
Running before the timeout => number 3
The timeout running last => number 4
ShellCopy to clipboard
The exact output may differ from run to run.PrevThe Node.js Event EmitterNextUnderstanding setImmediate()\n\n\n\nUnderstanding setImmediate()
When you want to execute some piece of code asynchronously, but as soon as possible, one option is to use the setImmediate() function provided by Node.js:
setImmediate(() => {
  // run something
});
JavaScriptCopy to clipboard
Any function passed as the setImmediate() argument is a callback that's executed in the next iteration of the event loop.
How is setImmediate() different from setTimeout(() => {}, 0) (passing a 0ms timeout), and from process.nextTick() and Promise.then()?
A function passed to process.nextTick() is going to be executed on the current iteration of the event loop, after the current operation ends. This means it will always execute before setTimeout and setImmediate.
A setTimeout() callback with a 0ms delay is very similar to setImmediate(). The execution order will depend on various factors, but they will be both run in the next iteration of the event loop.
A process.nextTick callback is added to process.nextTick queue. A Promise.then() callback is added to promises microtask queue. A setTimeout, setImmediate callback is added to macrotask queue.
Event loop executes tasks in process.nextTick queue first, and then executes promises microtask queue, and then executes macrotask queue.
Here is an example to show the order between setImmediate(), process.nextTick() and Promise.then():
const baz = () => console.log('baz');
const foo = () => console.log('foo');
const zoo = () => console.log('zoo');

const start = () => {
  console.log('start');
  setImmediate(baz);
  new Promise((resolve, reject) => {
    resolve('bar');
  }).then(resolve => {
    console.log(resolve);
    process.nextTick(zoo);
  });
  process.nextTick(foo);
};

start();

// start foo bar zoo baz
JavaScriptCopy to clipboard
This code will first call start(), then call foo() in process.nextTick queue. After that, it will handle promises microtask queue, which prints bar and adds zoo() in process.nextTick queue at the same time. Then it will call zoo() which has just been added. In the end, the baz() in macrotask queue is called.
The principle aforementioned holds true in CommonJS cases, but keep in mind in ES Modules, e.g. mjs files, the execution order will be different:
// start bar foo zoo baz
JavaScriptCopy to clipboard
This is because the ES Module being loaded is wrapped as an asynchronous operation, and thus the entire script is actually already in the promises microtask queue. So when the promise is immediately resolved, its callback is appended to the microtask queue. Node.js will attempt to clear the queue until moving to any other queue, and hence you will see it outputs bar first.PrevUnderstanding process.nextTick()NextDon't Block the Event Loop\n\n\n\nDon't Block the Event Loop (or the Worker Pool)
Should you read this guide?
If you're writing anything more complicated than a brief command-line script, reading this should help you write higher-performance, more-secure applications.
This document is written with Node.js servers in mind, but the concepts apply to complex Node.js applications as well.
Where OS-specific details vary, this document is Linux-centric.
Summary
Node.js runs JavaScript code in the Event Loop (initialization and callbacks), and offers a Worker Pool to handle expensive tasks like file I/O.
Node.js scales well, sometimes better than more heavyweight approaches like Apache.
The secret to the scalability of Node.js is that it uses a small number of threads to handle many clients.
If Node.js can make do with fewer threads, then it can spend more of your system's time and memory working on clients rather than on paying space and time overheads for threads (memory, context-switching).
But because Node.js has only a few threads, you must structure your application to use them wisely.
Here's a good rule of thumb for keeping your Node.js server speedy:
Node.js is fast when the work associated with each client at any given time is "small".
This applies to callbacks on the Event Loop and tasks on the Worker Pool.
Why should I avoid blocking the Event Loop and the Worker Pool?
Node.js uses a small number of threads to handle many clients.
In Node.js there are two types of threads: one Event Loop (aka the main loop, main thread, event thread, etc.), and a pool of k Workers in a Worker Pool (aka the threadpool).
If a thread is taking a long time to execute a callback (Event Loop) or a task (Worker), we call it "blocked".
While a thread is blocked working on behalf of one client, it cannot handle requests from any other clients.
This provides two motivations for blocking neither the Event Loop nor the Worker Pool:

Performance: If you regularly perform heavyweight activity on either type of thread, the throughput (requests/second) of your server will suffer.
Security: If it is possible that for certain input one of your threads might block, a malicious client could submit this "evil input", make your threads block, and keep them from working on other clients. This would be a Denial of Service attack.

A quick review of Node
Node.js uses the Event-Driven Architecture: it has an Event Loop for orchestration and a Worker Pool for expensive tasks.
What code runs on the Event Loop?
When they begin, Node.js applications first complete an initialization phase, require'ing modules and registering callbacks for events.
Node.js applications then enter the Event Loop, responding to incoming client requests by executing the appropriate callback.
This callback executes synchronously, and may register asynchronous requests to continue processing after it completes.
The callbacks for these asynchronous requests will also be executed on the Event Loop.
The Event Loop will also fulfill the non-blocking asynchronous requests made by its callbacks, e.g., network I/O.
In summary, the Event Loop executes the JavaScript callbacks registered for events, and is also responsible for fulfilling non-blocking asynchronous requests like network I/O.
What code runs on the Worker Pool?
The Worker Pool of Node.js is implemented in libuv (docs), which exposes a general task submission API.
Node.js uses the Worker Pool to handle "expensive" tasks.
This includes I/O for which an operating system does not provide a non-blocking version, as well as particularly CPU-intensive tasks.
These are the Node.js module APIs that make use of this Worker Pool:

I/O-intensive

DNS: dns.lookup(), dns.lookupService().
File System: All file system APIs except fs.FSWatcher() and those that are explicitly synchronous use libuv's threadpool.


CPU-intensive

Crypto: crypto.pbkdf2(), crypto.scrypt(), crypto.randomBytes(), crypto.randomFill(), crypto.generateKeyPair().
Zlib: All zlib APIs except those that are explicitly synchronous use libuv's threadpool.



In many Node.js applications, these APIs are the only sources of tasks for the Worker Pool. Applications and modules that use a C++ add-on can submit other tasks to the Worker Pool.
For the sake of completeness, we note that when you call one of these APIs from a callback on the Event Loop, the Event Loop pays some minor setup costs as it enters the Node.js C++ bindings for that API and submits a task to the Worker Pool.
These costs are negligible compared to the overall cost of the task, which is why the Event Loop is offloading it.
When submitting one of these tasks to the Worker Pool, Node.js provides a pointer to the corresponding C++ function in the Node.js C++ bindings.
How does Node.js decide what code to run next?
Abstractly, the Event Loop and the Worker Pool maintain queues for pending events and pending tasks, respectively.
In truth, the Event Loop does not actually maintain a queue.
Instead, it has a collection of file descriptors that it asks the operating system to monitor, using a mechanism like epoll (Linux), kqueue (OSX), event ports (Solaris), or IOCP (Windows).
These file descriptors correspond to network sockets, any files it is watching, and so on.
When the operating system says that one of these file descriptors is ready, the Event Loop translates it to the appropriate event and invokes the callback(s) associated with that event.
You can learn more about this process here.
In contrast, the Worker Pool uses a real queue whose entries are tasks to be processed.
A Worker pops a task from this queue and works on it, and when finished the Worker raises an "At least one task is finished" event for the Event Loop.
What does this mean for application design?
In a one-thread-per-client system like Apache, each pending client is assigned its own thread.
If a thread handling one client blocks, the operating system will interrupt it and give another client a turn.
The operating system thus ensures that clients that require a small amount of work are not penalized by clients that require more work.
Because Node.js handles many clients with few threads, if a thread blocks handling one client's request, then pending client requests may not get a turn until the thread finishes its callback or task.
The fair treatment of clients is thus the responsibility of your application.
This means that you shouldn't do too much work for any client in any single callback or task.
This is part of why Node.js can scale well, but it also means that you are responsible for ensuring fair scheduling.
The next sections talk about how to ensure fair scheduling for the Event Loop and for the Worker Pool.
Don't block the Event Loop
The Event Loop notices each new client connection and orchestrates the generation of a response.
All incoming requests and outgoing responses pass through the Event Loop.
This means that if the Event Loop spends too long at any point, all current and new clients will not get a turn.
You should make sure you never block the Event Loop.
In other words, each of your JavaScript callbacks should complete quickly.
This of course also applies to your await's, your Promise.then's, and so on.
A good way to ensure this is to reason about the "computational complexity" of your callbacks.
If your callback takes a constant number of steps no matter what its arguments are, then you'll always give every pending client a fair turn.
If your callback takes a different number of steps depending on its arguments, then you should think about how long the arguments might be.
Example 1: A constant-time callback.
app.get('/constant-time', (req, res) => {
  res.sendStatus(200);
});
JavaScriptCopy to clipboard
Example 2: An O(n) callback. This callback will run quickly for small n and more slowly for large n.
app.get('/countToN', (req, res) => {
  let n = req.query.n;

  // n iterations before giving someone else a turn
  for (let i = 0; i < n; i++) {
    console.log(`Iter ${i}`);
  }

  res.sendStatus(200);
});
JavaScriptCopy to clipboard
Example 3: An O(n^2) callback. This callback will still run quickly for small n, but for large n it will run much more slowly than the previous O(n) example.
app.get('/countToN2', (req, res) => {
  let n = req.query.n;

  // n^2 iterations before giving someone else a turn
  for (let i = 0; i < n; i++) {
    for (let j = 0; j < n; j++) {
      console.log(`Iter ${i}.${j}`);
    }
  }

  res.sendStatus(200);
});
JavaScriptCopy to clipboard
How careful should you be?
Node.js uses the Google V8 engine for JavaScript, which is quite fast for many common operations.
Exceptions to this rule are regexps and JSON operations, discussed below.
However, for complex tasks you should consider bounding the input and rejecting inputs that are too long.
That way, even if your callback has large complexity, by bounding the input you ensure the callback cannot take more than the worst-case time on the longest acceptable input.
You can then evaluate the worst-case cost of this callback and determine whether its running time is acceptable in your context.
Blocking the Event Loop: REDOS
One common way to block the Event Loop disastrously is by using a "vulnerable" regular expression.
Avoiding vulnerable regular expressions
A regular expression (regexp) matches an input string against a pattern.
We usually think of a regexp match as requiring a single pass through the input string --- O(n) time where n is the length of the input string.
In many cases, a single pass is indeed all it takes.
Unfortunately, in some cases the regexp match might require an exponential number of trips through the input string --- O(2^n) time.
An exponential number of trips means that if the engine requires x trips to determine a match, it will need 2*x trips if we add only one more character to the input string.
Since the number of trips is linearly related to the time required, the effect of this evaluation will be to block the Event Loop.
A vulnerable regular expression is one on which your regular expression engine might take exponential time, exposing you to REDOS on "evil input".
Whether or not your regular expression pattern is vulnerable (i.e. the regexp engine might take exponential time on it) is actually a difficult question to answer, and varies depending on whether you're using Perl, Python, Ruby, Java, JavaScript, etc., but here are some rules of thumb that apply across all of these languages:

Avoid nested quantifiers like (a+)*. V8's regexp engine can handle some of these quickly, but others are vulnerable.
Avoid OR's with overlapping clauses, like (a|a)*. Again, these are sometimes-fast.
Avoid using backreferences, like (a.*) \1. No regexp engine can guarantee evaluating these in linear time.
If you're doing a simple string match, use indexOf or the local equivalent. It will be cheaper and will never take more than O(n).

If you aren't sure whether your regular expression is vulnerable, remember that Node.js generally doesn't have trouble reporting a match even for a vulnerable regexp and a long input string.
The exponential behavior is triggered when there is a mismatch but Node.js can't be certain until it tries many paths through the input string.
A REDOS example
Here is an example vulnerable regexp exposing its server to REDOS:
app.get('/redos-me', (req, res) => {
  let filePath = req.query.filePath;

  // REDOS
  if (filePath.match(/(\/.+)+$/)) {
    console.log('valid path');
  } else {
    console.log('invalid path');
  }

  res.sendStatus(200);
});
JavaScriptCopy to clipboard
The vulnerable regexp in this example is a (bad!) way to check for a valid path on Linux.
It matches strings that are a sequence of "/"-delimited names, like "/a/b/c".
It is dangerous because it violates rule 1: it has a doubly-nested quantifier.
If a client queries with filePath ///.../\n (100 /'s followed by a newline character that the regexp's "." won't match), then the Event Loop will take effectively forever, blocking the Event Loop.
This client's REDOS attack causes all other clients not to get a turn until the regexp match finishes.
For this reason, you should be leery of using complex regular expressions to validate user input.
Anti-REDOS Resources
There are some tools to check your regexps for safety, like

safe-regex
rxxr2.

However, neither of these will catch all vulnerable regexps.
Another approach is to use a different regexp engine.
You could use the node-re2 module, which uses Google's blazing-fast RE2 regexp engine.
But be warned, RE2 is not 100% compatible with V8's regexps, so check for regressions if you swap in the node-re2 module to handle your regexps.
And particularly complicated regexps are not supported by node-re2.
If you're trying to match something "obvious", like a URL or a file path, find an example in a regexp library or use an npm module, e.g. ip-regex.
Blocking the Event Loop: Node.js core modules
Several Node.js core modules have synchronous expensive APIs, including:

Encryption
Compression
File system
Child process

These APIs are expensive, because they involve significant computation (encryption, compression), require I/O (file I/O), or potentially both (child process). These APIs are intended for scripting convenience, but are not intended for use in the server context. If you execute them on the Event Loop, they will take far longer to complete than a typical JavaScript instruction, blocking the Event Loop.
In a server, you should not use the following synchronous APIs from these modules:

Encryption:

crypto.randomBytes (synchronous version)
crypto.randomFillSync
crypto.pbkdf2Sync
You should also be careful about providing large input to the encryption and decryption routines.


Compression:

zlib.inflateSync
zlib.deflateSync


File system:

Do not use the synchronous file system APIs. For example, if the file you access is in a distributed file system like NFS, access times can vary widely.


Child process:

child_process.spawnSync
child_process.execSync
child_process.execFileSync



This list is reasonably complete as of Node.js v9.
Blocking the Event Loop: JSON DOS
JSON.parse and JSON.stringify are other potentially expensive operations.
While these are O(n) in the length of the input, for large n they can take surprisingly long.
If your server manipulates JSON objects, particularly those from a client, you should be cautious about the size of the objects or strings you work with on the Event Loop.
Example: JSON blocking. We create an object obj of size 2^21 and JSON.stringify it, run indexOf on the string, and then JSON.parse it. The JSON.stringify'd string is 50MB. It takes 0.7 seconds to stringify the object, 0.03 seconds to indexOf on the 50MB string, and 1.3 seconds to parse the string.
let obj = { a: 1 };
let niter = 20;

let before, str, pos, res, took;

for (let i = 0; i < niter; i++) {
  obj = { obj1: obj, obj2: obj }; // Doubles in size each iter
}

before = process.hrtime();
str = JSON.stringify(obj);
took = process.hrtime(before);
console.log('JSON.stringify took ' + took);

before = process.hrtime();
pos = str.indexOf('nomatch');
took = process.hrtime(before);
console.log('Pure indexof took ' + took);

before = process.hrtime();
res = JSON.parse(str);
took = process.hrtime(before);
console.log('JSON.parse took ' + took);
JavaScriptCopy to clipboard
There are npm modules that offer asynchronous JSON APIs. See for example:

JSONStream, which has stream APIs.
Big-Friendly JSON, which has stream APIs as well as asynchronous versions of the standard JSON APIs using the partitioning-on-the-Event-Loop paradigm outlined below.

Complex calculations without blocking the Event Loop
Suppose you want to do complex calculations in JavaScript without blocking the Event Loop.
You have two options: partitioning or offloading.
Partitioning
You could partition your calculations so that each runs on the Event Loop but regularly yields (gives turns to) other pending events.
In JavaScript it's easy to save the state of an ongoing task in a closure, as shown in example 2 below.
For a simple example, suppose you want to compute the average of the numbers 1 to n.
Example 1: Un-partitioned average, costs O(n)
for (let i = 0; i < n; i++) sum += i;
let avg = sum / n;
console.log('avg: ' + avg);
JavaScriptCopy to clipboard
Example 2: Partitioned average, each of the n asynchronous steps costs O(1).
function asyncAvg(n, avgCB) {
  // Save ongoing sum in JS closure.
  let sum = 0;
  function help(i, cb) {
    sum += i;
    if (i == n) {
      cb(sum);
      return;
    }

    // "Asynchronous recursion".
    // Schedule next operation asynchronously.
    setImmediate(help.bind(null, i + 1, cb));
  }

  // Start the helper, with CB to call avgCB.
  help(1, function (sum) {
    let avg = sum / n;
    avgCB(avg);
  });
}

asyncAvg(n, function (avg) {
  console.log('avg of 1-n: ' + avg);
});
JavaScriptCopy to clipboard
You can apply this principle to array iterations and so forth.
Offloading
If you need to do something more complex, partitioning is not a good option.
This is because partitioning uses only the Event Loop, and you won't benefit from multiple cores almost certainly available on your machine.
Remember, the Event Loop should orchestrate client requests, not fulfill them itself.
For a complicated task, move the work off of the Event Loop onto a Worker Pool.
How to offload
You have two options for a destination Worker Pool to which to offload work.

You can use the built-in Node.js Worker Pool by developing a C++ addon. On older versions of Node, build your C++ addon using NAN, and on newer versions use N-API. node-webworker-threads offers a JavaScript-only way to access the Node.js Worker Pool.
You can create and manage your own Worker Pool dedicated to computation rather than the Node.js I/O-themed Worker Pool. The most straightforward ways to do this is using Child Process or Cluster.

You should not simply create a Child Process for every client.
You can receive client requests more quickly than you can create and manage children, and your server might become a fork bomb.
Downside of offloading
The downside of the offloading approach is that it incurs overhead in the form of communication costs.
Only the Event Loop is allowed to see the "namespace" (JavaScript state) of your application.
From a Worker, you cannot manipulate a JavaScript object in the Event Loop's namespace.
Instead, you have to serialize and deserialize any objects you wish to share.
Then the Worker can operate on its own copy of these object(s) and return the modified object (or a "patch") to the Event Loop.
For serialization concerns, see the section on JSON DOS.
Some suggestions for offloading
You may wish to distinguish between CPU-intensive and I/O-intensive tasks because they have markedly different characteristics.
A CPU-intensive task only makes progress when its Worker is scheduled, and the Worker must be scheduled onto one of your machine's logical cores.
If you have 4 logical cores and 5 Workers, one of these Workers cannot make progress.
As a result, you are paying overhead (memory and scheduling costs) for this Worker and getting no return for it.
I/O-intensive tasks involve querying an external service provider (DNS, file system, etc.) and waiting for its response.
While a Worker with an I/O-intensive task is waiting for its response, it has nothing else to do and can be de-scheduled by the operating system, giving another Worker a chance to submit their request.
Thus, I/O-intensive tasks will be making progress even while the associated thread is not running.
External service providers like databases and file systems have been highly optimized to handle many pending requests concurrently.
For example, a file system will examine a large set of pending write and read requests to merge conflicting updates and to retrieve files in an optimal order.
If you rely on only one Worker Pool, e.g. the Node.js Worker Pool, then the differing characteristics of CPU-bound and I/O-bound work may harm your application's performance.
For this reason, you might wish to maintain a separate Computation Worker Pool.
Offloading: conclusions
For simple tasks, like iterating over the elements of an arbitrarily long array, partitioning might be a good option.
If your computation is more complex, offloading is a better approach: the communication costs, i.e. the overhead of passing serialized objects between the Event Loop and the Worker Pool, are offset by the benefit of using multiple cores.
However, if your server relies heavily on complex calculations, you should think about whether Node.js is really a good fit. Node.js excels for I/O-bound work, but for expensive computation it might not be the best option.
If you take the offloading approach, see the section on not blocking the Worker Pool.
Don't block the Worker Pool
Node.js has a Worker Pool composed of k Workers.
If you are using the Offloading paradigm discussed above, you might have a separate Computational Worker Pool, to which the same principles apply.
In either case, let us assume that k is much smaller than the number of clients you might be handling concurrently.
This is in keeping with the "one thread for many clients" philosophy of Node.js, the secret to its scalability.
As discussed above, each Worker completes its current Task before proceeding to the next one on the Worker Pool queue.
Now, there will be variation in the cost of the Tasks required to handle your clients' requests.
Some Tasks can be completed quickly (e.g. reading short or cached files, or producing a small number of random bytes), and others will take longer (e.g reading larger or uncached files, or generating more random bytes).
Your goal should be to minimize the variation in Task times, and you should use Task partitioning to accomplish this.
Minimizing the variation in Task times
If a Worker's current Task is much more expensive than other Tasks, then it will be unavailable to work on other pending Tasks.
In other words, each relatively long Task effectively decreases the size of the Worker Pool by one until it is completed.
This is undesirable because, up to a point, the more Workers in the Worker Pool, the greater the Worker Pool throughput (tasks/second) and thus the greater the server throughput (client requests/second).
One client with a relatively expensive Task will decrease the throughput of the Worker Pool, in turn decreasing the throughput of the server.
To avoid this, you should try to minimize variation in the length of Tasks you submit to the Worker Pool.
While it is appropriate to treat the external systems accessed by your I/O requests (DB, FS, etc.) as black boxes, you should be aware of the relative cost of these I/O requests, and should avoid submitting requests you can expect to be particularly long.
Two examples should illustrate the possible variation in task times.
Variation example: Long-running file system reads
Suppose your server must read files in order to handle some client requests.
After consulting the Node.js File system APIs, you opted to use fs.readFile() for simplicity.
However, fs.readFile() before v10 was not partitioned: it submitted a single fs.read() Task spanning the entire file.
If you read shorter files for some users and longer files for others, fs.readFile() may introduce significant variation in Task lengths, to the detriment of Worker Pool throughput.
For a worst-case scenario, suppose an attacker can convince your server to read an arbitrary file (this is a directory traversal vulnerability).
If your server is running Linux, the attacker can name an extremely slow file: /dev/random.
For all practical purposes, /dev/random is infinitely slow, and every Worker asked to read from /dev/random will never finish that Task.
An attacker then submits k requests, one for each Worker, and no other client requests that use the Worker Pool will make progress.
Variation example: Long-running crypto operations
Suppose your server generates cryptographically secure random bytes using crypto.randomBytes().
crypto.randomBytes() is not partitioned: it creates a single randomBytes() Task to generate as many bytes as you requested.
If you create fewer bytes for some users and more bytes for others, crypto.randomBytes() is another source of variation in Task lengths.
Task partitioning
Tasks with variable time costs can harm the throughput of the Worker Pool.
To minimize variation in Task times, as far as possible you should partition each Task into comparable-cost sub-Tasks.
When each sub-Task completes it should submit the next sub-Task, and when the final sub-Task completes it should notify the submitter.
To continue the fs.readFile() example, you should instead use fs.read() (manual partitioning) or ReadStream (automatically partitioned).
The same principle applies to CPU-bound tasks; the asyncAvg example might be inappropriate for the Event Loop, but it is well suited to the Worker Pool.
When you partition a Task into sub-Tasks, shorter Tasks expand into a small number of sub-Tasks, and longer Tasks expand into a larger number of sub-Tasks.
Between each sub-Task of a longer Task, the Worker to which it was assigned can work on a sub-Task from another, shorter, Task, thus improving the overall Task throughput of the Worker Pool.
Note that the number of sub-Tasks completed is not a useful metric for the throughput of the Worker Pool.
Instead, concern yourself with the number of Tasks completed.
Avoiding Task partitioning
Recall that the purpose of Task partitioning is to minimize the variation in Task times.
If you can distinguish between shorter Tasks and longer Tasks (e.g. summing an array vs. sorting an array), you could create one Worker Pool for each class of Task.
Routing shorter Tasks and longer Tasks to separate Worker Pools is another way to minimize Task time variation.
In favor of this approach, partitioning Tasks incurs overhead (the costs of creating a Worker Pool Task representation and of manipulating the Worker Pool queue), and avoiding partitioning saves you the costs of additional trips to the Worker Pool.
It also keeps you from making mistakes in partitioning your Tasks.
The downside of this approach is that Workers in all of these Worker Pools will incur space and time overheads and will compete with each other for CPU time.
Remember that each CPU-bound Task makes progress only while it is scheduled.
As a result, you should only consider this approach after careful analysis.
Worker Pool: conclusions
Whether you use only the Node.js Worker Pool or maintain separate Worker Pool(s), you should optimize the Task throughput of your Pool(s).
To do this, minimize the variation in Task times by using Task partitioning.
The risks of npm modules
While the Node.js core modules offer building blocks for a wide variety of applications, sometimes something more is needed. Node.js developers benefit tremendously from the npm ecosystem, with hundreds of thousands of modules offering functionality to accelerate your development process.
Remember, however, that the majority of these modules are written by third-party developers and are generally released with only best-effort guarantees. A developer using an npm module should be concerned about two things, though the latter is frequently forgotten.

Does it honor its APIs?
Might its APIs block the Event Loop or a Worker?
Many modules make no effort to indicate the cost of their APIs, to the detriment of the community.

For simple APIs you can estimate the cost of the APIs; the cost of string manipulation isn't hard to fathom.
But in many cases it's unclear how much an API might cost.
If you are calling an API that might do something expensive, double-check the cost. Ask the developers to document it, or examine the source code yourself (and submit a PR documenting the cost).
Remember, even if the API is asynchronous, you don't know how much time it might spend on a Worker or on the Event Loop in each of its partitions.
For example, suppose in the asyncAvg example given above, each call to the helper function summed half of the numbers rather than one of them.
Then this function would still be asynchronous, but the cost of each partition would be O(n), not O(1), making it much less safe to use for arbitrary values of n.
Conclusion
Node.js has two types of threads: one Event Loop and k Workers.
The Event Loop is responsible for JavaScript callbacks and non-blocking I/O, and a Worker executes tasks corresponding to C++ code that completes an asynchronous request, including blocking I/O and CPU-intensive work.
Both types of threads work on no more than one activity at a time.
If any callback or task takes a long time, the thread running it becomes blocked.
If your application makes blocking callbacks or tasks, this can lead to degraded throughput (clients/second) at best, and complete denial of service at worst.
To write a high-throughput, more DoS-proof web server, you must ensure that on benign and on malicious input, neither your Event Loop nor your Workers will block.PrevUnderstanding setImmediate()NextNode.js file stats\n\n\n\nNode.js file stats
Every file comes with a set of details that we can inspect using Node.js. In particular, using the stat() method provided by the fs module.
You call it passing a file path, and once Node.js gets the file details it will call the callback function you pass, with 2 parameters: an error message, and the file stats:
CJSMJSconst fs = require('node:fs');

fs.stat('/Users/joe/test.txt', (err, stats) => {
  if (err) {
    console.error(err);
  }
  // we have access to the file stats in `stats`
});
JavaScriptCopy to clipboardNode.js also provides a sync method, which blocks the thread until the file stats are ready:
CJSMJSconst fs = require('node:fs');

try {
  const stats = fs.statSync('/Users/joe/test.txt');
} catch (err) {
  console.error(err);
}
JavaScriptCopy to clipboardThe file information is included in the stats variable. What kind of information can we extract using the stats?
A lot, including:

if the file is a directory or a file, using stats.isFile() and stats.isDirectory()
if the file is a symbolic link using stats.isSymbolicLink()
the file size in bytes using stats.size.

There are other advanced methods, but the bulk of what you'll use in your day-to-day programming is this.
CJSMJSconst fs = require('node:fs');

fs.stat('/Users/joe/test.txt', (err, stats) => {
  if (err) {
    console.error(err);
    return;
  }

  stats.isFile(); // true
  stats.isDirectory(); // false
  stats.isSymbolicLink(); // false
  stats.size; // 1024000 //= 1MB
});
JavaScriptCopy to clipboardYou can also use promise-based fsPromises.stat() method offered by the fs/promises module if you like:
CJSMJSconst fs = require('node:fs/promises');

async function example() {
  try {
    const stats = await fs.stat('/Users/joe/test.txt');
    stats.isFile(); // true
    stats.isDirectory(); // false
    stats.isSymbolicLink(); // false
    stats.size; // 1024000 //= 1MB
  } catch (err) {
    console.log(err);
  }
}
example();
JavaScriptCopy to clipboardYou can read more about the fs module in the official documentation.PrevDon't Block the Event LoopNextNode.js File Paths\n\n\n\nNode.js File Paths
Every file in the system has a path. On Linux and macOS, a path might look like: /users/joe/file.txt while Windows computers are different, and have a structure such as: C:\users\joe\file.txt
You need to pay attention when using paths in your applications, as this difference must be taken into account.
You include this module in your files using const path = require('node:path'); and you can start using its methods.
Getting information out of a path
Given a path, you can extract information out of it using those methods:

dirname: gets the parent folder of a file
basename: gets the filename part
extname: gets the file extension

Example
CJSMJSconst path = require('node:path');

const notes = '/users/joe/notes.txt';

path.dirname(notes); // /users/joe
path.basename(notes); // notes.txt
path.extname(notes); // .txt
JavaScriptCopy to clipboardYou can get the file name without the extension by specifying a second argument to basename:
path.basename(notes, path.extname(notes)); // notes
JavaScriptCopy to clipboard
Working with paths
You can join two or more parts of a path by using path.join():
const name = 'joe';
path.join('/', 'users', name, 'notes.txt'); // '/users/joe/notes.txt'
JavaScriptCopy to clipboard
You can get the absolute path calculation of a relative path using path.resolve():
path.resolve('joe.txt'); // '/Users/joe/joe.txt' if run from my home folder
JavaScriptCopy to clipboard
In this case Node.js will simply append /joe.txt to the current working directory. If you specify a second parameter folder, resolve will use the first as a base for the second:
path.resolve('tmp', 'joe.txt'); // '/Users/joe/tmp/joe.txt' if run from my home folder
JavaScriptCopy to clipboard
If the first parameter starts with a slash, that means it's an absolute path:
path.resolve('/etc', 'joe.txt'); // '/etc/joe.txt'
JavaScriptCopy to clipboard
path.normalize() is another useful function, that will try and calculate the actual path, when it contains relative specifiers like . or .., or double slashes:
path.normalize('/users/joe/..//test.txt'); // '/users/test.txt'
JavaScriptCopy to clipboard
Neither resolve nor normalize will check if the path exists. They just calculate a path based on the information they got.PrevNode.js file statsNextWorking with file descriptors in Node.js\n\n\n\nWorking with file descriptors in Node.js
Before you're able to interact with a file that sits in your filesystem, you must get a file descriptor.
A file descriptor is a reference to an open file, a number (fd) returned by opening the file using the open() method offered by the fs module. This number (fd) uniquely identifies an open file in operating system:
CJSMJSconst fs = require('node:fs');

fs.open('/Users/joe/test.txt', 'r', (err, fd) => {
  // fd is our file descriptor
});
JavaScriptCopy to clipboardNotice the r we used as the second parameter to the fs.open() call.
That flag means we open the file for reading.
Other flags you'll commonly use are:
FlagDescriptionFile gets created if it doesn't existr+This flag opens the file for reading and writing❌w+This flag opens the file for reading and writing and it also positions the stream at the beginning of the file✅aThis flag opens the file for writing and it also positions the stream at the end of the file✅a+This flag opens the file for reading and writing and it also positions the stream at the end of the file✅
You can also open the file by using the fs.openSync method, which returns the file descriptor, instead of providing it in a callback:
CJSMJSconst fs = require('node:fs');

try {
  const fd = fs.openSync('/Users/joe/test.txt', 'r');
} catch (err) {
  console.error(err);
}
JavaScriptCopy to clipboardOnce you get the file descriptor, in whatever way you choose, you can perform all the operations that require it, like calling fs.close() and many other operations that interact with the filesystem.
You can also open the file by using the promise-based fsPromises.open method offered by the fs/promises module.
The fs/promises module is available starting only from Node.js v14. Before v14, after v10, you can use require('fs').promises instead. Before v10, after v8, you can use util.promisify to convert fs methods into promise-based methods.
CJSMJSconst fs = require('node:fs/promises');
// Or const fs = require('fs').promises before v14.
async function example() {
  let filehandle;
  try {
    filehandle = await fs.open('/Users/joe/test.txt', 'r');
    console.log(filehandle.fd);
    console.log(await filehandle.readFile({ encoding: 'utf8' }));
  } finally {
    if (filehandle) await filehandle.close();
  }
}
example();
JavaScriptCopy to clipboardHere is an example of util.promisify:
CJSMJSconst fs = require('node:fs');
const util = require('node:util');

async function example() {
  const open = util.promisify(fs.open);
  const fd = await open('/Users/joe/test.txt', 'r');
}
example();
JavaScriptCopy to clipboardTo see more details about the fs/promises module, please check fs/promises API.PrevNode.js File PathsNextReading files with Node.js\n\n\n\nReading files with Node.js
The simplest way to read a file in Node.js is to use the fs.readFile() method, passing it the file path, encoding and a callback function that will be called with the file data (and the error):
CJSMJSconst fs = require('node:fs');

fs.readFile('/Users/joe/test.txt', 'utf8', (err, data) => {
  if (err) {
    console.error(err);
    return;
  }
  console.log(data);
});
JavaScriptCopy to clipboardAlternatively, you can use the synchronous version fs.readFileSync():
CJSMJSconst fs = require('node:fs');

try {
  const data = fs.readFileSync('/Users/joe/test.txt', 'utf8');
  console.log(data);
} catch (err) {
  console.error(err);
}
JavaScriptCopy to clipboardYou can also use the promise-based fsPromises.readFile() method offered by the fs/promises module:
CJSMJSconst fs = require('node:fs/promises');

async function example() {
  try {
    const data = await fs.readFile('/Users/joe/test.txt', { encoding: 'utf8' });
    console.log(data);
  } catch (err) {
    console.error(err);
  }
}
example();
JavaScriptCopy to clipboardAll three of fs.readFile(), fs.readFileSync() and fsPromises.readFile() read the full content of the file in memory before returning the data.
This means that big files are going to have a major impact on your memory consumption and speed of execution of the program.
In this case, a better option is to read the file content using streams.
import fs from 'fs';
import path from 'path';
import { pipeline } from 'node:stream/promises';

const fileUrl = 'https://www.gutenberg.org/files/2701/2701-0.txt';
const outputFilePath = path.join(process.cwd(), 'moby.md');

async function downloadFile(url, outputPath) {
  const response = await fetch(url);

  if (!response.ok || !response.body) {
    throw new Error(`Failed to fetch ${url}. Status: ${response.status}`);
  }

  const fileStream = fs.createWriteStream(outputPath);
  console.log(`Downloading file from ${url} to ${outputPath}`);

  await pipeline(response.body, fileStream);
  console.log('File downloaded successfully');
}

async function readFile(filePath) {
  const readStream = fs.createReadStream(filePath, { encoding: 'utf8' });

  try {
    for await (const chunk of readStream) {
      console.log('--- File chunk start ---');
      console.log(chunk);
      console.log('--- File chunk end ---');
    }
    console.log('Finished reading the file.');
  } catch (error) {
    console.error(`Error reading file: ${error.message}`);
  }
}

try {
  await downloadFile(fileUrl, outputFilePath);
  await readFile(outputFilePath);
} catch (error) {
  console.error(`Error: ${error.message}`);
}
JavaScriptCopy to clipboardPrevWorking with file descriptors in Node.jsNextWriting files with Node.js\n\n\n\nWriting files with Node.js
Writing a file
The easiest way to write to files in Node.js is to use the fs.writeFile() API.
const fs = require('node:fs');

const content = 'Some content!';

fs.writeFile('/Users/joe/test.txt', content, err => {
  if (err) {
    console.error(err);
  } else {
    // file written successfully
  }
});
JavaScriptCopy to clipboard
Writing a file synchronously
Alternatively, you can use the synchronous version fs.writeFileSync():
const fs = require('node:fs');

const content = 'Some content!';

try {
  fs.writeFileSync('/Users/joe/test.txt', content);
  // file written successfully
} catch (err) {
  console.error(err);
}
JavaScriptCopy to clipboard
You can also use the promise-based fsPromises.writeFile() method offered by the fs/promises module:
const fs = require('node:fs/promises');

async function example() {
  try {
    const content = 'Some content!';
    await fs.writeFile('/Users/joe/test.txt', content);
  } catch (err) {
    console.log(err);
  }
}

example();
JavaScriptCopy to clipboard
By default, this API will replace the contents of the file if it does already exist.
You can modify the default by specifying a flag:
fs.writeFile('/Users/joe/test.txt', content, { flag: 'a+' }, err => {});
JavaScriptCopy to clipboard
The flags you'll likely use are
FlagDescriptionFile gets created if it doesn't existr+This flag opens the file for reading and writing❌w+This flag opens the file for reading and writing and it also positions the stream at the beginning of the file✅aThis flag opens the file for writing and it also positions the stream at the end of the file✅a+This flag opens the file for reading and writing and it also positions the stream at the end of the file✅

You can find more information about the flags in the fs documentation.

Appending content to a file
Appending to files is handy when you don't want to overwrite a file with new content, but rather add to it.
Examples
A handy method to append content to the end of a file is fs.appendFile() (and its fs.appendFileSync() counterpart):
const fs = require('node:fs');

const content = 'Some content!';

fs.appendFile('file.log', content, err => {
  if (err) {
    console.error(err);
  } else {
    // done!
  }
});
JavaScriptCopy to clipboard
Example with Promises
Here is a fsPromises.appendFile() example:
const fs = require('node:fs/promises');

async function example() {
  try {
    const content = 'Some content!';
    await fs.appendFile('/Users/joe/test.txt', content);
  } catch (err) {
    console.log(err);
  }
}

example();
JavaScriptCopy to clipboardPrevReading files with Node.jsNextWorking with folders in Node.js\n\n\n\nWorking with folders in Node.js
The Node.js fs core module provides many handy methods you can use to work with folders.
Check if a folder exists
Use fs.access() (and its promise-based fsPromises.access() counterpart) to check if the folder exists and Node.js can access it with its permissions.
Create a new folder
Use fs.mkdir() or fs.mkdirSync() or fsPromises.mkdir() to create a new folder.
CJSMJSconst fs = require('node:fs');

const folderName = '/Users/joe/test';

try {
  if (!fs.existsSync(folderName)) {
    fs.mkdirSync(folderName);
  }
} catch (err) {
  console.error(err);
}
JavaScriptCopy to clipboardRead the content of a directory
Use fs.readdir() or fs.readdirSync() or fsPromises.readdir() to read the contents of a directory.
This piece of code reads the content of a folder, both files and subfolders, and returns their relative path:
CJSMJSconst fs = require('node:fs');

const folderPath = '/Users/joe';

fs.readdirSync(folderPath);
JavaScriptCopy to clipboardYou can get the full path:
fs.readdirSync(folderPath).map(fileName => {
  return path.join(folderPath, fileName);
});
JavaScriptCopy to clipboard
You can also filter the results to only return the files, and exclude the folders:
CJSMJSconst fs = require('node:fs');

const isFile = fileName => {
  return fs.lstatSync(fileName).isFile();
};

fs.readdirSync(folderPath)
  .map(fileName => {
    return path.join(folderPath, fileName);
  })
  .filter(isFile);
JavaScriptCopy to clipboardRename a folder
Use fs.rename() or fs.renameSync() or fsPromises.rename() to rename folder. The first parameter is the current path, the second the new path:
CJSMJSconst fs = require('node:fs');

fs.rename('/Users/joe', '/Users/roger', err => {
  if (err) {
    console.error(err);
  }
  // done
});
JavaScriptCopy to clipboardfs.renameSync() is the synchronous version:
CJSMJSconst fs = require('node:fs');

try {
  fs.renameSync('/Users/joe', '/Users/roger');
} catch (err) {
  console.error(err);
}
JavaScriptCopy to clipboardfsPromises.rename() is the promise-based version:
CJSMJSconst fs = require('node:fs/promises');

async function example() {
  try {
    await fs.rename('/Users/joe', '/Users/roger');
  } catch (err) {
    console.log(err);
  }
}
example();
JavaScriptCopy to clipboardRemove a folder
Use fs.rmdir() or fs.rmdirSync() or fsPromises.rmdir() to remove a folder.
CJSMJSconst fs = require('node:fs');

fs.rmdir(dir, err => {
  if (err) {
    throw err;
  }

  console.log(`${dir} is deleted!`);
});
JavaScriptCopy to clipboardTo remove a folder that has contents use fs.rm() with the option { recursive: true } to recursively remove the contents.
{ recursive: true, force: true } makes it so that exceptions will be ignored if the folder does not exist.
CJSMJSconst fs = require('node:fs');

fs.rm(dir, { recursive: true, force: true }, err => {
  if (err) {
    throw err;
  }

  console.log(`${dir} is deleted!`);
});
JavaScriptCopy to clipboardPrevWriting files with Node.jsNextHow to work with Different Filesystems\n\n\n\nHow to Work with Different Filesystems
Node.js exposes many features of the filesystem. But not all filesystems are alike.
The following are suggested best practices to keep your code simple and safe
when working with different filesystems.
Filesystem Behavior
Before you can work with a filesystem, you need to know how it behaves.
Different filesystems behave differently and have more or less features than
others: case sensitivity, case insensitivity, case preservation, Unicode form
preservation, timestamp resolution, extended attributes, inodes, Unix
permissions, alternate data streams etc.
Be wary of inferring filesystem behavior from process.platform. For example,
do not assume that because your program is running on Darwin that you are
therefore working on a case-insensitive filesystem (HFS+), as the user may be
using a case-sensitive filesystem (HFSX). Similarly, do not assume that because
your program is running on Linux that you are therefore working on a filesystem
which supports Unix permissions and inodes, as you may be on a particular
external drive, USB or network drive which does not.
The operating system may not make it easy to infer filesystem behavior, but all
is not lost. Instead of keeping a list of every known filesystem and behavior
(which is always going to be incomplete), you can probe the filesystem to see
how it actually behaves. The presence or absence of certain features which are
easy to probe, are often enough to infer the behavior of other features which
are more difficult to probe.
Remember that some users may have different filesystems mounted at various paths
in the working tree.
Avoid a Lowest Common Denominator Approach
You might be tempted to make your program act like a lowest common denominator
filesystem, by normalizing all filenames to uppercase, normalizing all filenames
to NFC Unicode form, and normalizing all file timestamps to say 1-second
resolution. This would be the lowest common denominator approach.
Do not do this. You would only be able to interact safely with a filesystem
which has the exact same lowest common denominator characteristics in every
respect. You would be unable to work with more advanced filesystems in the way
that users expect, and you would run into filename or timestamp collisions. You
would most certainly lose and corrupt user data through a series of complicated
dependent events, and you would create bugs that would be difficult if not
impossible to solve.
What happens when you later need to support a filesystem that only has 2-second
or 24-hour timestamp resolution? What happens when the Unicode standard advances
to include a slightly different normalization algorithm (as has happened in the
past)?
A lowest common denominator approach would tend to try to create a portable
program by using only "portable" system calls. This leads to programs that are
leaky and not in fact portable.
Adopt a Superset Approach
Make the best use of each platform you support by adopting a superset approach.
For example, a portable backup program should sync btimes (the created time of a
file or folder) correctly between Windows systems, and should not destroy or
alter btimes, even though btimes are not supported on Linux systems. The same
portable backup program should sync Unix permissions correctly between Linux
systems, and should not destroy or alter Unix permissions, even though Unix
permissions are not supported on Windows systems.
Handle different filesystems by making your program act like a more advanced
filesystem. Support a superset of all possible features: case-sensitivity,
case-preservation, Unicode form sensitivity, Unicode form preservation, Unix
permissions, high-resolution nanosecond timestamps, extended attributes etc.
Once you have case-preservation in your program, you can always implement
case-insensitivity if you need to interact with a case-insensitive filesystem.
But if you forego case-preservation in your program, you cannot interact safely
with a case-preserving filesystem. The same is true for Unicode form
preservation and timestamp resolution preservation.
If a filesystem provides you with a filename in a mix of lowercase and
uppercase, then keep the filename in the exact case given. If a filesystem
provides you with a filename in mixed Unicode form or NFC or NFD (or NFKC or
NFKD), then keep the filename in the exact byte sequence given. If a filesystem
provides you with a millisecond timestamp, then keep the timestamp in
millisecond resolution.
When you work with a lesser filesystem, you can always downsample appropriately,
with comparison functions as required by the behavior of the filesystem on which
your program is running. If you know that the filesystem does not support Unix
permissions, then you should not expect to read the same Unix permissions you
write. If you know that the filesystem does not preserve case, then you should
be prepared to see ABC in a directory listing when your program creates abc.
But if you know that the filesystem does preserve case, then you should consider
ABC to be a different filename to abc, when detecting file renames or if the
filesystem is case-sensitive.
Case Preservation
You may create a directory called test/abc and be surprised to see sometimes
that fs.readdir('test') returns ['ABC']. This is not a bug in Node. Node
returns the filename as the filesystem stores it, and not all filesystems
support case-preservation. Some filesystems convert all filenames to uppercase
(or lowercase).
Unicode Form Preservation
Case preservation and Unicode form preservation are similar concepts. To
understand why Unicode form should be preserved , make sure that you first
understand why case should be preserved. Unicode form preservation is just as
simple when understood correctly.
Unicode can encode the same characters using several different byte sequences.
Several strings may look the same, but have different byte sequences. When
working with UTF-8 strings, be careful that your expectations are in line with
how Unicode works. Just as you would not expect all UTF-8 characters to encode
to a single byte, you should not expect several UTF-8 strings that look the same
to the human eye to have the same byte representation. This may be an
expectation that you can have of ASCII, but not of UTF-8.
You may create a directory called test/café (NFC Unicode form with byte
sequence <63 61 66 c3 a9> and string.length === 5) and be surprised to see
sometimes that fs.readdir('test') returns ['café'] (NFD Unicode form with
byte sequence <63 61 66 65 cc 81> and string.length === 6). This is not a
bug in Node. Node.js returns the filename as the filesystem stores it, and not
all filesystems support Unicode form preservation.
HFS+, for example, will normalize all filenames to a form almost always the same
as NFD form. Do not expect HFS+ to behave the same as NTFS or EXT4 and
vice-versa. Do not try to change data permanently through normalization as a
leaky abstraction to paper over Unicode differences between filesystems. This
would create problems without solving any. Rather, preserve Unicode form and use
normalization as a comparison function only.
Unicode Form Insensitivity
Unicode form insensitivity and Unicode form preservation are two different
filesystem behaviors often mistaken for each other. Just as case-insensitivity
has sometimes been incorrectly implemented by permanently normalizing filenames
to uppercase when storing and transmitting filenames, so Unicode form
insensitivity has sometimes been incorrectly implemented by permanently
normalizing filenames to a certain Unicode form (NFD in the case of HFS+) when
storing and transmitting filenames. It is possible and much better to implement
Unicode form insensitivity without sacrificing Unicode form preservation, by
using Unicode normalization for comparison only.
Comparing Different Unicode Forms
Node.js provides string.normalize('NFC' / 'NFD') which you can use to normalize a
UTF-8 string to either NFC or NFD. You should never store the output from this
function but only use it as part of a comparison function to test whether two
UTF-8 strings would look the same to the user.
You can use string1.normalize('NFC') === string2.normalize('NFC') or
string1.normalize('NFD') === string2.normalize('NFD') as your comparison
function. Which form you use does not matter.
Normalization is fast but you may want to use a cache as input to your
comparison function to avoid normalizing the same string many times over. If the
string is not present in the cache then normalize it and cache it. Be careful
not to store or persist the cache, use it only as a cache.
Note that using normalize() requires that your version of Node.js include ICU
(otherwise normalize() will just return the original string). If you download
the latest version of Node.js from the website then it will include ICU.
Timestamp Resolution
You may set the mtime (the modified time) of a file to 1444291759414
(millisecond resolution) and be surprised to see sometimes that fs.stat
returns the new mtime as 1444291759000 (1-second resolution) or
1444291758000 (2-second resolution). This is not a bug in Node. Node.js returns
the timestamp as the filesystem stores it, and not all filesystems support
nanosecond, millisecond or 1-second timestamp resolution. Some filesystems even
have very coarse resolution for the atime timestamp in particular, e.g. 24 hours
for some FAT filesystems.
Do Not Corrupt Filenames and Timestamps Through Normalization
Filenames and timestamps are user data. Just as you would never automatically
rewrite user file data to uppercase the data or normalize CRLF to LF
line-endings, so you should never change, interfere or corrupt filenames or
timestamps through case / Unicode form / timestamp normalization. Normalization
should only ever be used for comparison, never for altering data.
Normalization is effectively a lossy hash code. You can use it to test for
certain kinds of equivalence (e.g. do several strings look the same even though
they have different byte sequences) but you can never use it as a substitute for
the actual data. Your program should pass on filename and timestamp data as is.
Your program can create new data in NFC (or in any combination of Unicode form
it prefers) or with a lowercase or uppercase filename, or with a 2-second
resolution timestamp, but your program should not corrupt existing user data by
imposing case / Unicode form / timestamp normalization. Rather, adopt a superset
approach and preserve case, Unicode form and timestamp resolution in your
program. That way, you will be able to interact safely with filesystems which do
the same.
Use Normalization Comparison Functions Appropriately
Make sure that you use case / Unicode form / timestamp comparison functions
appropriately. Do not use a case-insensitive filename comparison function if you
are working on a case-sensitive filesystem. Do not use a Unicode form
insensitive comparison function if you are working on a Unicode form sensitive
filesystem (e.g. NTFS and most Linux filesystems which preserve both NFC and NFD
or mixed Unicode forms). Do not compare timestamps at 2-second resolution if you
are working on a nanosecond timestamp resolution filesystem.
Be Prepared for Slight Differences in Comparison Functions
Be careful that your comparison functions match those of the filesystem (or
probe the filesystem if possible to see how it would actually compare).
Case-insensitivity for example is more complex than a simple toLowerCase()
comparison. In fact, toUpperCase() is usually better than toLowerCase()
(since it handles certain foreign language characters differently). But better
still would be to probe the filesystem since every filesystem has its own case
comparison table baked in.
As an example, Apple's HFS+ normalizes filenames to NFD form but this NFD form
is actually an older version of the current NFD form and may sometimes be
slightly different from the latest Unicode standard's NFD form. Do not expect
HFS+ NFD to be exactly the same as Unicode NFD all the time.PrevWorking with folders in Node.jsNextRun Node.js scripts from the command line\n\n\n\nRun Node.js scripts from the command line
The usual way to run a Node.js program is to run the globally available node command (once you install Node.js) and pass the name of the file you want to execute.
If your main Node.js application file is app.js, you can call it by typing:
node app.js
ShellCopy to clipboard
Above, you are explicitly telling the shell to run your script with node. You can also embed this information into your JavaScript file with a "shebang" line. The "shebang" is the first line in the file, and tells the OS which interpreter to use for running the script. Below is the first line of JavaScript:
#!/usr/bin/node
JavaScriptCopy to clipboard
Above, we are explicitly giving the absolute path of interpreter. Not all operating systems have node in the bin folder, but all should have env. You can tell the OS to run env with node as parameter:
#!/usr/bin/env node

// your javascript code
JavaScriptCopy to clipboard
To use a shebang, your file should have executable permission. You can give app.js the executable permission by running:
chmod u+x app.js
ShellCopy to clipboard
While running the command, make sure you are in the same directory which contains the app.js file.
Pass string as argument to node instead of file path
To execute a string as argument you can use -e, --eval "script". Evaluate the following argument as JavaScript. The modules which are predefined in the REPL can also be used in script.
On Windows, using cmd.exe a single quote will not work correctly because it only recognizes double " for quoting. In Powershell or Git bash, both ' and " are usable.
node -e "console.log(123)"
ShellCopy to clipboard
Restart the application automatically
As of Node.js V16, there is a built-in option to automatically restart the application when a file changes. This is useful for development purposes.
To use this feature, you need to pass the --watch flag to Node.js.
node --watch app.js
ShellCopy to clipboard
So when you change the file, the application will restart automatically.
Read the --watch flag documentation.
Run a task with Node.js
Node.js provides a built-in task runner that allows you to execute specific commands defined in your package.json file. This can be particularly useful for automating repetitive tasks such as running tests, building your project, or linting your code.
Using the --run flag
The --run flag allows you to run a specified command from the scripts section of your package.json file. For example, if you have the following package.json:
{
  "type": "module",
  "scripts": {
    "start": "node app.js",
    "dev": "node --run -- --watch",
    "test": "node --test"
  }
}
JSONCopy to clipboard
You can run the test script using the --run flag:
node --run test
ShellCopy to clipboard
Passing arguments to the command
Let's explain the dev key in the scripts object of the package.json file.
The syntax -- --another-argument is used to pass arguments to the command. In this case, the --watch argument is passed to the dev script.
node --run dev
ShellCopy to clipboard
Environment variables
The --run flag sets specific environment variables that can be useful for your scripts:

NODE_RUN_SCRIPT_NAME: The name of the script being run.
NODE_RUN_PACKAGE_JSON_PATH: The path to the package.json file being processed.

Intentional limitations
The Node.js task runner is intentionally more limited compared to other task runners like npm run or yarn run. It focuses on performance and simplicity, omitting features like running pre or post scripts. This makes it suitable for straightforward tasks but may not cover all use cases.PrevHow to work with Different FilesystemsNextHow to read environment variables from Node.js\n\n\n\nHow to read environment variables from Node.js
The process core module of Node.js provides the env property which hosts all the environment variables that were set at the moment the process was started.
The below code runs app.js and set USER_ID and USER_KEY.
USER_ID=239482 USER_KEY=foobar node app.js
ShellCopy to clipboard
That will pass the user USER_ID as 239482 and the USER_KEY as foobar. This is suitable for testing, however for production, you will probably be configuring some bash scripts to export variables.

Note: process does not need to be imported, it is a global object in Node.js.

Here is an example that accesses the USER_ID and USER_KEY environment variables, which we set in above code.
process.env.USER_ID; // "239482"
process.env.USER_KEY; // "foobar"
JavaScriptCopy to clipboard
In the same way you can access any custom environment variable you set.
Node.js 20 introduced experimental support for .env files.
Now, you can use the --env-file flag to specify an environment file when running your Node.js application. Here's an example .env file and how to access its variables using process.env.
# .env file
PORT=3000
ShellCopy to clipboard
In your js file
process.env.PORT; // "3000"
JavaScriptCopy to clipboard
Run app.js file with environment variables set in .env file.
node --env-file=.env app.js
ShellCopy to clipboard
This command loads all the environment variables from the .env file, making them available to the application on process.env
Also, you can pass multiple --env-file arguments. Subsequent files override pre-existing variables defined in previous files.
node --env-file=.env --env-file=.development.env app.js
ShellCopy to clipboard

Note: if the same variable is defined in the environment and in the file, the value from the environment takes precedence.

In case you want to optionally read from a .env file, it's possible to avoid
throwing an error if the file is missing using the --env-file-if-exists flag.
node --env-file-if-exists=.env app.js
ShellCopy to clipboardPrevRun Node.js scripts from the command lineNextHow to use the Node.js REPL\n\n\n\nHow to use the Node.js REPL
What is the Node.js REPL?
Node.js comes with a built-in REPL (Read-Eval-Print Loop) environment that allows you to execute JavaScript code interactively. The REPL is accessible through the terminal and is a great way to test out small pieces of code.
How to use the Node.js REPL
The node command is the one we use to run our Node.js scripts:
node script.js
ShellCopy to clipboard
If we run the node command without any script to execute or without any arguments, we start a REPL session:
node
ShellCopy to clipboard

Note: REPL stands for Read Evaluate Print Loop, and it is a programming language environment (basically a console window) that takes single expression as user input and returns the result back to the console after execution. The REPL session provides a convenient way to quickly test simple JavaScript code.

If you try it now in your terminal, this is what happens:
❯ node
>
ShellCopy to clipboard
The command stays in idle mode and waits for us to enter something.

Tip: if you are unsure how to open your terminal, google "How to open terminal on your-operating-system".

The REPL is waiting for us to enter some JavaScript code, to be more precise.
Start simple and enter
> console.log('test')
test
undefined
>
Shell SessionCopy to clipboard
The first value, test, is the output we told the console to print, then we get undefined which is the return value of running console.log().
Node read this line of code, evaluated it, printed the result, and then went back to waiting for more lines of code. Node will loop through these three steps for every piece of code we execute in the REPL until we exit the session. That is where the REPL got its name.
Node automatically prints the result of any line of JavaScript code without the need to instruct it to do so. For example, type in the following line and press enter:
> 5 === '5'
false
>
Shell SessionCopy to clipboard
Note the difference in the outputs of the above two lines. The Node REPL printed undefined after executing console.log(), while on the other hand, it just printed the result of 5 === '5'. You need to keep in mind that the former is just a statement in JavaScript, and the latter is an expression.
In some cases, the code you want to test might need multiple lines. For example, say you want to define a function that generates a random number, in the REPL session type in the following line and press enter:
function generateRandom() {
...
Shell SessionCopy to clipboard
The Node REPL is smart enough to determine that you are not done writing your code yet, and it will go into a multi-line mode for you to type in more code. Now finish your function definition and press enter:
function generateRandom() {
...return Math.random()
}
undefined
Shell SessionCopy to clipboard
The _ special variable
If after some code you type _, that is going to print the result of the last operation.
The Up arrow key
If you press the up arrow key, you will get access to the history of the previous lines of code executed in the current, and even previous REPL sessions.
Dot commands
The REPL has some special commands, all starting with a dot .. They are

.help: shows the dot commands help
.editor: enables editor mode, to write multiline JavaScript code with ease. Once you are in this mode, enter ctrl-D to run the code you wrote.
.break: when inputting a multi-line expression, entering the .break command will abort further input. Same as pressing ctrl-C.
.clear: resets the REPL context to an empty object and clears any multi-line expression currently being input.
.load: loads a JavaScript file, relative to the current working directory
.save: saves all you entered in the REPL session to a file (specify the filename)
.exit: exits the repl (same as pressing ctrl-C two times)

The REPL knows when you are typing a multi-line statement without the need to invoke .editor.
For example if you start typing an iteration like this:
[1, 2, 3].forEach(num => {
Shell SessionCopy to clipboard
and you press enter, the REPL will go to a new line that starts with 3 dots, indicating you can now continue to work on that block.
... console.log(num)
... })
Shell SessionCopy to clipboard
If you type .break at the end of a line, the multiline mode will stop and the statement will not be executed.
Run REPL from JavaScript file
We can import the REPL in a JavaScript file using repl.
CJSMJSconst repl = require('node:repl');
JavaScriptCopy to clipboardUsing the repl variable we can perform various operations.
To start the REPL command prompt, type in the following line
repl.start();
JavaScriptCopy to clipboard
Run the file in the command line.
BASHCONSOLEnode repl.js
ShellCopy to clipboardYou can pass a string which shows when the REPL starts. The default is '> ' (with a trailing space), but we can define custom prompt.
// a Unix style prompt
const local = repl.start('$ ');
JavaScriptCopy to clipboard
You can display a message while exiting the REPL
local.on('exit', () => {
  console.log('exiting repl');
  process.exit();
});
JavaScriptCopy to clipboard
You can read more about the REPL module in the repl documentation.PrevHow to read environment variables from Node.jsNextOutput to the command line using Node.js\n\n\n\nOutput to the command line using Node.js
Basic output using the console module
Node.js provides a console module which provides tons of very useful ways to interact with the command line.
It is basically the same as the console object you find in the browser.
The most basic and most used method is console.log(), which prints the string you pass to it to the console.
If you pass an object, it will render it as a string.
You can pass multiple variables to console.log, for example:
const x = 'x';
const y = 'y';

console.log(x, y);
JavaScriptCopy to clipboard
and Node.js will print both.
We can also format pretty phrases by passing variables and a format specifier.
For example:
console.log('My %s has %d ears', 'cat', 2);
JavaScriptCopy to clipboard

%s format a variable as a string
%d format a variable as a number
%i format a variable as its integer part only
%o format a variable as an object

Example:
console.log('%o', Number);
JavaScriptCopy to clipboard
Clear the console
console.clear() clears the console (the behavior might depend on the console used)
Counting elements
console.count() is a handy method.
Take this code:
const x = 1;
const y = 2;
const z = 3;

console.count(
  'The value of x is ' + x + ' and has been checked .. how many times?'
);

console.count(
  'The value of x is ' + x + ' and has been checked .. how many times?'
);

console.count(
  'The value of y is ' + y + ' and has been checked .. how many times?'
);
JavaScriptCopy to clipboard
What happens is that console.count() will count the number of times a string is printed, and print the count next to it:
You can just count apples and oranges:
const oranges = ['orange', 'orange'];
const apples = ['just one apple'];

oranges.forEach(fruit => {
  console.count(fruit);
});
apples.forEach(fruit => {
  console.count(fruit);
});
JavaScriptCopy to clipboard
Reset counting
The console.countReset() method resets counter used with console.count().
We will use the apples and orange example to demonstrate this.
const oranges = ['orange', 'orange'];
const apples = ['just one apple'];

oranges.forEach(fruit => {
  console.count(fruit);
});
apples.forEach(fruit => {
  console.count(fruit);
});

console.countReset('orange');

oranges.forEach(fruit => {
  console.count(fruit);
});
JavaScriptCopy to clipboard
Notice how the call to console.countReset('orange') resets the value counter to zero.
Print the stack trace
There might be cases where it's useful to print the call stack trace of a function, maybe to answer the question how did you reach that part of the code?
You can do so using console.trace():
const function2 = () => console.trace();
const function1 = () => function2();
function1();
JavaScriptCopy to clipboard
This will print the stack trace. This is what's printed if we try this in the Node.js REPL:
Trace
    at function2 (repl:1:33)
    at function1 (repl:1:25)
    at repl:1:1
    at ContextifyScript.Script.runInThisContext (vm.js:44:33)
    at REPLServer.defaultEval (repl.js:239:29)
    at bound (domain.js:301:14)
    at REPLServer.runBound [as eval] (domain.js:314:12)
    at REPLServer.onLine (repl.js:440:10)
    at emitOne (events.js:120:20)
    at REPLServer.emit (events.js:210:7)
ShellCopy to clipboard
Calculate the time spent
You can easily calculate how much time a function takes to run, using time() and timeEnd()
const doSomething = () => console.log('test');
const measureDoingSomething = () => {
  console.time('doSomething()');
  // do something, and measure the time it takes
  doSomething();
  console.timeEnd('doSomething()');
};
measureDoingSomething();
JavaScriptCopy to clipboard
stdout and stderr
As we saw console.log is great for printing messages in the Console. This is what's called the standard output, or stdout.
console.error prints to the stderr stream.
It will not appear in the console, but it will appear in the error log.
Color the output

NOTE
This part of the resource is designed with version 22.11 which notes styleText as ‘Active development’.

In many cases, you will be tempted to paste certain text to get a nice output at the terminal.
There is a styleText function provided by the node:util module. Let's discover how to use it.
First of all, you need to import the styleText function from the node:util module:
MJSCJSimport { styleText } from 'node:util';
JavaScriptCopy to clipboardThen, you can use it to style your text:
console.log(
  styleText(['red'], 'This is red text ') +
    styleText(['green', 'bold'], 'and this is green bold text ') +
    'this is normal text'
);
JavaScriptCopy to clipboard
The first argument is an array of styles, and the second argument is the text you want to style. We invite you to read the docsPrevHow to use the Node.js REPLNextAccept input from the command line in Node.js\n\n\n\nAccept input from the command line in Node.js
How to make a Node.js CLI program interactive?
Node.js since version 7 provides the readline module to perform exactly this: get input from a readable stream such as the process.stdin stream, which during the execution of a Node.js program is the terminal input, one line at a time.
CJSMJSconst readline = require('node:readline');

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

rl.question(`What's your name?`, name => {
  console.log(`Hi ${name}!`);
  rl.close();
});
JavaScriptCopy to clipboardThis piece of code asks the user's name, and once the text is entered and the user presses enter, we send a greeting.
The question() method shows the first parameter (a question) and waits for the user input. It calls the callback function once enter is pressed.
In this callback function, we close the readline interface.
readline offers several other methods, please check them out on the package documentation linked above.
If you need to require a password, it's best not to echo it back, but instead show a * symbol.PrevOutput to the command line using Node.jsNextPublishing a package\n\n\n\nPublishing a package
All the provided package.json configurations (not specifically marked “does not work”) work in Node.js 12.22.x (v12 latest, the oldest supported line) and 17.2.0 (current latest at the time)1, and for grins, with webpack 5.53.0 and 5.63.0 respectively. These are available: JakobJingleheimer/nodejs-module-config-examples.
For curious cats, How did we get here and Down the rabbit-hole provide background and deeper explanations.
Pick your fix
There are 2 main options, which cover almost all use-cases:

Write source code and publish in CJS (you use require()); CJS is consumable by both CJS and ESM (in all versions of node). Skip to CJS source and distribution.
Write source code and publish in ESM (you use import, and don't use top-level await); ESM is consumable by both ESM and CJS (in node 22.x and 23.x; see require() an ES Module). Skip to ESM source and distribution.

It's generally best to publish only 1 format, either CJS or ESM. Not both. Publishing multiple formats can result in the dual-package hazard, as well as other drawbacks.
There are other options available, mostly for historical purposes.
You as a package author writeConsumers of your package write their code inYour optionsCJS source code using require()ESM: consumers import your packageCJS source and only ESM distributionCJS & ESM: consumers either require() or import your packageCJS source and both CJS & ESM distributionESM source code using importCJS: consumers require() your package (and you use top-level await)ESM source with only CJS distributionCJS & ESM: consumers either require() or import your packageESM source and both CJS & ESM distribution
CJS source and distribution
The most minimal configuration may be only "name". But the less arcane, the better: Essentially just declare the package’s exports via the "exports" field/field-set.
Working example: cjs-with-cjs-distro
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "cjs-source-and-distribution"
  // "main": "./index.js"
}
JSONCopy to clipboardNote that packageJson.exports["."] = filepath is shorthand for packageJson.exports["."].default = filepath
ESM source and distribution
Simple, tried, and true.
Note that since Node.js v23.0.0, it is possible to require static ESM (code that does not use top-level await). See Loading ECMAScript modules using require() for details.
This is almost exactly the same as the CJS-CJS configuration above with 1 small difference: the "type" field.
Working example: esm-with-esm-distro
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "esm-source-and-distribution",
  "type": "module"
  // "main": "./index.js"
}
JSONCopy to clipboardNote that ESM now is “backwards” compatible with CJS: a CJS module now can require() an ES Module without a flag as of 23.0.0 and 22.12.0.
CJS source and only ESM distribution
This takes a small bit of finesse but is also pretty straight-forward. This may be the choice pick of older projects targetting newer standards, or authors who merely prefer CJS but are publishing for a different environment.
Working example: cjs-with-esm-distro
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "cjs-source-with-esm-distribution",
  "main": "./dist/index.mjs"
}
JSONCopy to clipboardThe .mjs file extension is a trump-card: it will override any other configuration and the file will be treated as ESM. Using this file extension is necessary because packageJson.exports.import does NOT signify that the file is ESM (contrary to common, if not universal, misperception), only that it is the file to be used when the package is imported (ESM can import CJS. See Gotchas below).
CJS source and both CJS & ESM distribution
In order to directly supply both audiences (so that your distribution works "natively" in either), you have a few options:
Attach named exports directly onto exports
Classic but takes some sophistication and finesse. This means adding properties onto the existing module.exports (instead of re-assigning module.exports as a whole).
Working example: cjs-with-dual-distro (properties)
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "cjs-source-with-esm-via-properties-distribution",
  "main": "./dist/cjs/index.js"
}
JSONCopy to clipboardPros:

Smaller package weight
Easy and simple (probably least effort if you don't mind keeping to a minor syntax stipulation)
Precludes the Dual-Package Hazard

Cons:

Requires very specific syntax (either in source code and/or bundler gymnastics).

Sometimes, a CJS module may re-assign module.exports to something else (be it an object or a function) like this:
const someObject = {
  foo() {},
  bar() {},
  qux() {},
};

module.exports = someObject;
JavaScriptCopy to clipboard
Node.js detects the named exports in CJS via static analysis that look for certain patterns, which the example above evades. To make the named exports detectable, do this:
module.exports.foo = function foo() {};
module.exports.bar = function bar() {};
module.exports.qux = function qux() {};
JavaScriptCopy to clipboard
Use a simple ESM wrapper
Complicated setup and difficult to get the balance right.
Working example: cjs-with-dual-distro (wrapper)
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "cjs-with-wrapper-dual-distro",
  "exports": {
    ".": {
      "import": "./dist/esm/wrapper.mjs",
      "require": "./dist/cjs/index.js",
      "default": "./dist/cjs/index.js"
    }
  }
}
JSONCopy to clipboardPros:

Smaller package weight

Cons:

Likely requires complicated bundler gymnastics (we could not find any existing option to automate this in Webpack).

When the CJS output from the bundler evades the named exports detection in Node.js, a ESM wrapper can be used to explicitly re-export the known named exports for ESM consumers.
When CJS exports an object (which gets aliased to ESM's default), you can save references to all the members of the object locally in the wrapper, and then re-export them so the ESM consumer can access all of them by name.
import cjs from '../cjs/index.js';

const { a, b, c /* … */ } = cjs;

export { a, b, c /* … */ };
JavaScriptCopy to clipboard
However, this does break live bindings: a reassignment to cjs.a will not reflect in esmWrapper.a.
Two full distributions
Chuck in a bunch of stuff and hope for the best. This is probably the most common and easiest of the CJS to CJS & ESM options, but you pay for it. This is rarely a good idea.
Working example: cjs-with-dual-distro (double)
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "cjs-with-full-dual-distro",
  "exports": {
    ".": {
      "import": "./dist/esm/index.mjs",
      "require": "./dist/cjs/index.js",
      "default": "./dist/cjs/index.js"
    }
  }
}
JSONCopy to clipboardPros:

Simple bundler configuration

Cons:

Larger package weight (basically double)
Vulnerable to the Dual-Package Hazard

Alternatively, you can use "default" and "node" keys, which are less counter-intuitive: Node.js will always choose the "node" option (which always works), and non-Node.js tooling will choose "default" when configured to target something other than node. This precludes the dual-package hazard.
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "cjs-with-alt-full-dual-distro",
  "exports": {
    ".": {
      "node": "./dist/cjs/index.js",
      "default": "./dist/esm/index.mjs"
    }
  }
}
JSONCopy to clipboardESM source with only CJS distribution
We're not in Kansas anymore, Toto.
The configurations (there are 2 options) are nearly the same as ESM source and both CJS & ESM distribution, just exclude packageJson.exports.import.
💡 Using "type": "module"2 paired with the .cjs file extension (for commonjs files) yields best results. For more information on why, see Down the rabbit-hole and Gotchas below.
Working example: esm-with-cjs-distro
ESM source and both CJS & ESM distribution
When source code is written in non-JavaScript (ex TypeScript), options can be limited due to needing to use file extension(s) specific to that language (ex .ts) and there may be no .mjs equivalent.
Similar to CJS source and both CJS & ESM distribution, you have the same options.
Publish only a CJS distribution with property exports
Tricky to make and needs good ingredients.
This option is almost identical to the CJS source with CJS & ESM distribution's property exports above. The only difference is in package.json: "type": "module".
Only some build tools support generating this output. Rollup produces compatible output out of the box when targetting commonjs. Webpack as of v5.66.0+ does with the new commonjs-static output type, (prior to this, no commonjs options produces compatible output). It is not currently possible with esbuild (which produces a non-static exports).
The working example below was created prior to Webpack's recent release, so it uses Rollup (I'll get around to adding a Webpack option too).
These examples assume javascript files within use the extension .js; "type" in package.json controls how those are interpreted:
"type":"commonjs" + .js → cjs
"type":"module" + .js → mjs
If your files explicitly all use .cjs and/or .mjs file extensions (none use .js), "type" is superfluous.
Working example: esm-with-cjs-distro
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "esm-with-cjs-distribution",
  "type": "module",
  "main": "./dist/index.cjs"
}
JSONCopy to clipboard💡 Using "type": "module"2 paired with the .cjs file extension (for commonjs files) yields best results. For more information on why, see Down the rabbit-hole and Gotchas below.
Publish a CJS distribution with an ESM wrapper
There's a lot going on here, and this is usually not the best.
This is also almost identical to the CJS source and dual distribution using an ESM wrapper, but with subtle differences "type": "module" and some .cjs file extenions in package.json.
Working example: esm-with-dual-distro (wrapper)
Minimal package.jsonAdvanced (verbose) package.json{
  "name": "esm-with-cjs-and-esm-wrapper-distribution",
  "type": "module",
  "exports": {
    ".": {
      "import": "./dist/esm/wrapper.js",
      "require": "./dist/cjs/index.cjs",
      "default": "./dist/cjs/index.cjs"
    }
  }
}
JSONCopy to clipboard💡 Using "type": "module"2 paired with the .cjs file extension (for commonjs files) yields best results. For more information on why, see Down the rabbit-hole and Gotchas below.
Publish both full CJS & ESM distributions
Chuck in a bunch of stuff (with a surprise) and hope for the best. This is probably the most common and easiest of the ESM to CJS & ESM options, but you pay for it. This is rarely a good idea.
In terms of package configuration, there are a few options that differ mostly in personal preference.
Mark the whole package as ESM and specifically mark the CJS exports as CJS via the .cjs file extension
This option has the least burden on development/developer experience.
This also means that whatever build tooling must produce the distribution file with a .cjs file extension. This might necessitate chaining multiple build tools or adding a subsequent step to move/rename the file to have the .cjs file extension (ex mv ./dist/index.js ./dist/index.cjs). This can be worked around by adding a subsequent step to move/rename those outputted files (ex Rollup or a simple shell script).
Support for the .cjs file extension was added in 12.0.0, and using it will cause ESM to properly recognised a file as commonjs (import { foo } from './foo.cjs' works). However, require() does not auto-resolve .cjs like it does for .js, so file extension cannot be omitted as is commonplace in commonjs: require('./foo') will fail, but require('./foo.cjs') works. Using it in your package's exports has no drawbacks: packageJson.exports (and packageJson.main) requires a file extension regardless, and consumers reference your package by the "name" field of your package.json (so they're blissfully unaware).
Working example: esm-with-dual-distro
Minimal import & require package.jsonAdvanced (verbose) import & require package.json{
  "type": "module",
  "exports": {
    ".": {
      "import": "./dist/esm/index.js",
      "require": "./dist/index.cjs"
    }
  }
}
JSONCopy to clipboardAlternatively, you can use "default" and "node" keys, which are less counter-intuitive: Node.js will always choose the "node" option (which always works), and non-Node.js tooling will choose "default" when configured to target something other than node. This precludes the dual-package hazard.
Minimal default & node package.jsonAdvanced (verbose) default & node package.json{
  "type": "module",
  "exports": {
    ".": {
      "node": "./dist/index.cjs",
      "default": "./dist/esm/index.js"
    }
  }
}
JSONCopy to clipboard💡 Using "type": "module"2 paired with the .cjs file extension (for commonjs files) yields best results. For more information on why, see Down the rabbit-hole and Gotchas below.
Use the .mjs (or equivalent) file extension for all source code files
The configuration for this is the same as CJS source and both CJS & ESM distribution.
Non-JavaScript source code: The non-JavaScript language’s own configuration needs to recognise/specify that the input files are ESM.
Node.js before 12.22.x
🛑 You should not do this: Versions of Node.js prior to 12.x are End of Life and are now vulnerable to serious security exploits.
If you're a security researcher needing to investigate Node.js prior to v12.22.x, feel free to contact us for help configuring.
General notes
Syntax detection is not a replacement for proper package configuration; syntax detection is not fool-proof and it has significant performance cost.
When using "exports" in package.json, it is generally a good idea to include "./package.json": "./package.json" so that it can be imported (module.findPackageJSON is not affected by this limitation, but import may be more convenient).
"exports" can be advisable over "main" because it prevents external access to internal code (so you can be relatively sure users are not depending on things they shouldn't). If you don't need that, "main" is simpler and may be a better option for you.
The "engines" field provides both a human-friendly and a machine-friendly indication of which version(s) of Node.js the package is compatible. Depending on the package manager used, an exception may be thrown causing the installation to fail when the consumer is using an incompatible version of Node.js (which can be very helpful to consumers). Including this field will save a lot of headache for consumers with an older version of Node.js who cannot use the package.
Down the rabbit-hole
Specifically in relation to Node.js, there are 4 problems to solve:


Determining format of source code files (author running her/his own code)


Determining format of distribution files (code consumers will receive)


Publicising distribution code for when it is require()’d (consumer expects CJS)


Publicising distribution code for when it is import’d (consumer probably wants ESM)


⚠️ The first 2 are independent of the last 2.
The method of loading does NOT determine the format the file is interpreted as:

package.json’s exports.require ≠ CJS. require() does NOT and cannot blindly interpret the file as CJS; for instance, require('foo.json') correctly interprets the file as JSON, not CJS. The module containing the require() call of course must be CJS, but what it is loading is not necessarily also CJS.
package.json’s exports.import ≠ ESM. import similarly does NOT and cannot blindly interpret the file as ESM; import can load CJS, JSON, and WASM, as well as ESM. The module containing the import statement of course must be ESM, but what it is loading is not necessarily also ESM.

So when you see configuration options citing or named with require or import, resist the urge to assume they are for determining CJS vs ES Modules.
⚠️ Adding an "exports" field/field-set to a package’s configuration effectively blocks deep pathing into the package for anything not explicitly listed in the exports’ subpathing. This means it can be a breaking change.
⚠️ Consider carefully whether to distribute both CJS and ESM: It creates the potential for the Dual Package Hazard (especially if misconfigured and the consumer tries to get clever). This can lead to an extremely confusing bug in consuming projects, especially when your package is not perfectly configured. Consumers can even be blind-sided by an intermediary package that uses the "other" format of your package (eg consumer uses the ESM distribution, and some other package the consumer is also using itself uses the CJS distribution). If your package is in any way stateful, consuming both the CJS and ESM distributions will result in parallel states (which is almost surely unintentional).
The dual-package hazard
When an application is using a package that provides both CommonJS and ES module sources, there is a risk of certain bugs if both instances of the package get loaded. This potential comes from the fact that the pkgInstance created by const pkgInstance = require('pkg') is not the same as the pkgInstance created by import pkgInstance from 'pkg' (or an alternative main path like 'pkg/module'). This is the “dual package hazard”, where two instances of the same package can be loaded within the same runtime environment. While it is unlikely that an application or package would intentionally load both instances directly, it is common for an application to load one copy while a dependency of the application loads the other copy. This hazard can happen because Node.js supports intermixing CommonJS and ES modules, and can lead to unexpected and confusing behavior.
If the package main export is a constructor, an instanceof comparison of instances created by the two copies returns false, and if the export is an object, properties added to one (like pkgInstance.foo = 3) are not present on the other. This differs from how import and require statements work in all-CommonJS or all-ES module environments, respectively, and therefore is surprising to users. It also differs from the behavior users are familiar with when using transpilation via tools like Babel or esm.
How did we get here
CommonJS (CJS) was created long before ECMAScript Modules (ESM), back when JavaScript was still adolescent—CJS and jQuery were created just 3 years apart. CJS is not an official (TC39) standard and is supported by a limited few platforms (most notably, Node.js). ESM as a standard has been incoming for several years; it is currently supported by all major platforms (browsers, Deno, Node.js, etc), meaning it will run pretty much everywhere. As it became clear ESM would effectively succeed CJS (which is still very popular and widespread), many attempted to adopt early on, often before a particular aspect of the ESM specification was finalised. Because of this, those changed over time as better information became available (often informed by learnings/experiences of those eager beavers), going from best-guess to the aligning with the specification.
An additional complication is bundlers, which historically managed much of this territory. However, much of what we previously needed bundle(r)s to manage is now native functionality; yet bundlers are still (and likely always will be) necessary for some things. Unfortunately, functionality bundlers no-longer need to provide is deeply ingrained in older bundlers’ implementations, so they can at times be too helpful, and in some cases, anti-pattern (bundling a library is often not recommended by bundler authors themselves). The hows and whys of that are an article unto itself.
Gotchas
The package.json's "type" field changes the .js file extension to mean either commonjs or ES module respectively. It is very common in dual/mixed packages (that contain both CJS and ESM) to use this field incorrectly.
{
  "type": "module",
  "main": "./dist/CJS/index.js",
  "exports": {
    ".": {
      "import": "./dist/esm/index.js",
      "require": "./dist/cjs/index.js",
      "default": "./dist/cjs/index.js"
    },
    "./package.json": "./package.json"
  }
}
JSONCopy to clipboard
This does not work because "type": "module" causes packageJson.main, packageJson.exports["."].require, and packageJson.exports["."].default to get interpreted as ESM (but they’re actually CJS).
Excluding "type": "module" produces the opposite problem:
{
  "main": "./dist/CJS/index.js",
  "exports": {
    ".": {
      "import": "./dist/esm/index.js",
      "require": "./dist/cjs/index.js",
      "default": "./dist/cjs/index.js"
    },
    "./package.json": "./package.json"
  }
}
JSONCopy to clipboard
This does not work because packageJson.exports["."].import will get interpreted as CJS (but it’s actually ESM).
Footnotes


There was a bug in Node.js v13.0–13.6 where packageJson.exports["."] had to be an array with verbose config options as the first item (as an object) and the “default” as the second item (as a string). See nodejs/modules#446. ↩


The "type" field in package.json changes what the .js file extension means, similar to to an HTML script element’s type attribute. ↩ ↩2 ↩3 ↩4


PrevAccept input from the command line in Node.jsNextHow to publish a Node-API package\n\n\n\nHow to publish a Node-API version of a package alongside a non-Node-API version
The following steps are illustrated using the package iotivity-node:

First, publish the non-Node-API version:

Update the version in package.json. For iotivity-node, the version
becomes 1.2.0-2.
Go through the release checklist (ensure tests/demos/docs are OK)
npm publish


Then, publish the Node-API version:

Update the version in package.json. In the case of iotivity-node,
the version becomes 1.2.0-3. For versioning, we recommend following
the pre-release version scheme as described by
semver.org e.g. 1.2.0-napi.
Go through the release checklist (ensure tests/demos/docs are OK)
npm publish --tag n-api



In this example, tagging the release with n-api has ensured that, although
version 1.2.0-3 is later than the non-Node-API published version (1.2.0-2), it
will not be installed if someone chooses to install iotivity-node by simply
running npm install iotivity-node. This will install the non-Node-API version
by default. The user will have to run npm install iotivity-node@n-api to
receive the Node-API version. For more information on using tags with npm check
out "Using dist-tags".
How to introduce a dependency on a Node-API version of a package
To add the Node-API version of iotivity-node as a dependency, the package.json
will look like this:
"dependencies": {
  "iotivity-node": "n-api"
}
JSONCopy to clipboard

As explained in
"Using dist-tags", unlike regular versions, tagged versions cannot be
addressed by version ranges such as "^2.0.0" inside package.json. The
reason for this is that the tag refers to exactly one version. So, if the
package maintainer chooses to tag a later version of the package using the
same tag, npm update will receive the later version. This should be acceptable
version other than the latest published, the package.json dependency will
have to refer to the exact version like the following:

"dependencies": {
  "iotivity-node": "1.2.0-3"
}
JSONCopy to clipboardPrevPublishing a packageNextAnatomy of an HTTP Transaction\n\n\n\n